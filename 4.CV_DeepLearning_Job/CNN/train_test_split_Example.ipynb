{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"train_test_split_Example.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ZVC4itlLdW6b","executionInfo":{"status":"ok","timestamp":1607233346944,"user_tz":-540,"elapsed":1331,"user":{"displayName":"남중구","photoUrl":"","userId":"02914767085172164696"}}},"source":["# Confer : https://towardsdatascience.com/step-by-step-guide-to-using-pretrained-models-in-keras-c9097b647b29"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"3ZXZL5qVhe5b","executionInfo":{"status":"ok","timestamp":1607233346945,"user_tz":-540,"elapsed":1327,"user":{"displayName":"남중구","photoUrl":"","userId":"02914767085172164696"}}},"source":["# ImageMagic Install\n","!x=$(dpkg -l|grep imagemagick);[ ${#x} -eq 0 ]&&sudo apt install -y imagemagick\n","\n","# Mount Google Drive\n","from google.colab import drive\n","isMount=!df |grep /content/drive\n","if len(isMount)<1: drive.mount('/content/drive')\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cudECGk_hfbF","executionInfo":{"status":"ok","timestamp":1607233351815,"user_tz":-540,"elapsed":6191,"user":{"displayName":"남중구","photoUrl":"","userId":"02914767085172164696"}},"outputId":"fcee4c4f-e484-4b95-a258-725e4f1e3164"},"source":["%%bash\n","[ ! -f /content/drive/MyDrive/Lec_Capture/_data/flower_photos_300x200_small.tar  ]&&wget https://raw.githubusercontent.com/Finfra/AI_Vision/master/data/flower_photos_300x200_small.tar -O /content/drive/MyDrive/Lec_Capture/_data/flower_photos_300x200_small.tar \n","tar xf /content/drive/MyDrive/Lec_Capture/_data/flower_photos_300x200_small.tar\n","find ./flower_photos_300x200_small|grep jpg|xargs -i -t convert {} -quiet -resize 224x224\\! -quality 100 -colorspace RGB -type truecolor {} 2>> /tmp/log\n","find ./flower_photos_300x200_small|grep jpg|head -n 10|xargs -i -t identify {} 2>>/tmp/log"],"execution_count":3,"outputs":[{"output_type":"stream","text":["./flower_photos_300x200_small/daisy/14221848160_7f0a37c395.jpg JPEG 224x224 224x224+0+0 8-bit sRGB 95.8KB 0.000u 0:00.000\n","./flower_photos_300x200_small/daisy/19280272025_57de24e940_m.jpg JPEG 224x224 224x224+0+0 8-bit sRGB 45.9KB 0.000u 0:00.000\n","./flower_photos_300x200_small/daisy/483886997_27ee798327.jpg JPEG 224x224 224x224+0+0 8-bit sRGB 63.9KB 0.000u 0:00.000\n","./flower_photos_300x200_small/daisy/14600779226_7bbc288d40_m.jpg JPEG 224x224 224x224+0+0 8-bit sRGB 76.2KB 0.000u 0:00.009\n","./flower_photos_300x200_small/daisy/3780380240_ef9ec1b737_m.jpg JPEG 224x224 224x224+0+0 8-bit sRGB 53.6KB 0.000u 0:00.000\n","./flower_photos_300x200_small/daisy/2454280135_ac3aa75cdc_n.jpg JPEG 224x224 224x224+0+0 8-bit sRGB 76.8KB 0.000u 0:00.000\n","./flower_photos_300x200_small/daisy/154332674_453cea64f4.jpg JPEG 224x224 224x224+0+0 8-bit sRGB 70KB 0.000u 0:00.000\n","./flower_photos_300x200_small/daisy/3704305945_a80e60e2f6_m.jpg JPEG 224x224 224x224+0+0 8-bit sRGB 85.9KB 0.000u 0:00.000\n","./flower_photos_300x200_small/daisy/5794835_d15905c7c8_n.jpg JPEG 224x224 224x224+0+0 8-bit sRGB 58.3KB 0.000u 0:00.000\n","./flower_photos_300x200_small/daisy/3717746329_53f515c6a6_m.jpg JPEG 224x224 224x224+0+0 8-bit sRGB 50KB 0.000u 0:00.000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5ct64W32dW6b","executionInfo":{"status":"ok","timestamp":1607233353239,"user_tz":-540,"elapsed":7611,"user":{"displayName":"남중구","photoUrl":"","userId":"02914767085172164696"}}},"source":["import tensorflow as tf\n","from tensorflow.python import keras\n","from tensorflow.keras import datasets, layers, models ,Input, Model"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BKjYG11KdW6b","executionInfo":{"status":"ok","timestamp":1607233360664,"user_tz":-540,"elapsed":15031,"user":{"displayName":"남중구","photoUrl":"","userId":"02914767085172164696"}},"outputId":"7ae41943-bb3f-4dda-cb9f-db951fda725c"},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","from tensorflow.keras import datasets, layers, models, regularizers\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from os import listdir\n","from os.path import isfile, join\n","from pylab import *\n","from numpy import *\n","\n","def getFolder(thePath,isFile=True):\n","    return [f for f in listdir(thePath) if isFile == isfile(join(thePath, f)) ]\n","\n","\n","def getImagesAndLabels(tPath):\n","    labels=getFolder(tPath,False)\n","    encoder={w: i for i, w in enumerate(labels)}\n","    decoder={i: w  for i, w in enumerate(labels)}\n","\n","    \n","    tImages,tLabels=None,None\n","\n","    for label in labels:\n","        imgFolder=join(tPath,label)\n","        files= [f for f in listdir(imgFolder) if isfile(join(imgFolder, f))]\n","        for file in files:\n","            imageFile=join(imgFolder,file)\n","            img=np.array([imread(imageFile)])/255.\n","            if tImages is None:\n","                tImages, tLabels =img, np.array([encoder[label]],ndmin=1)\n","            else:\n","#                 print(tImages.shape,img.shape,imageFile)\n","                tImages = np.vstack( (tImages,img) )\n","                tLabels = np.append(tLabels,np.array([encoder[label]]) ,axis=0) \n","        print(label,tImages.shape)                 \n","    return (tImages,tLabels,encoder,decoder)\n","\n","    \n","\n","from sklearn.model_selection import train_test_split\n","basePath='/content/flower_photos_300x200_small'\n","imgs,labels,encoder,decoder=getImagesAndLabels(basePath)\n","\n","class_cnt=len(encoder.keys())\n","\n","train_images,test_images,train_labels,test_labels=train_test_split(imgs,labels,test_size=0.3333, random_state=99)\n","\n","\n","imgShape=train_images[0].shape\n","img_width,img_hight,color_count=imgShape\n","train_images = train_images.reshape((-1,img_width,img_hight,color_count ))\n","test_images = test_images.reshape((-1, img_width,img_hight,color_count ))\n","\n","print(\"Shape of Train_images = \",train_images.shape)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["daisy (100, 224, 224, 3)\n","tulips (200, 224, 224, 3)\n","Shape of Train_images =  (133, 224, 224, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3CfX8wlgdW6c","executionInfo":{"status":"ok","timestamp":1607233364435,"user_tz":-540,"elapsed":18798,"user":{"displayName":"남중구","photoUrl":"","userId":"02914767085172164696"}},"outputId":"1de4defd-aa98-4087-d9d1-224bb7916317"},"source":["from tensorflow.python.keras.applications.vgg16 import VGG16\n","\n","\n","model=keras.models.Sequential()\n","model.add(VGG16(weights='imagenet'))\n","# model.summary()\n","\n","inp=Input(shape=(224,224,3))\n","out=VGG16(weights='imagenet')(inp)\n","model=Model(inputs=inp,outputs=out)\n","model.summary()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Model: \"functional_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","vgg16 (Functional)           (None, 1000)              138357544 \n","=================================================================\n","Total params: 138,357,544\n","Trainable params: 138,357,544\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WJSaxHHndW6c","executionInfo":{"status":"ok","timestamp":1607233369337,"user_tz":-540,"elapsed":23695,"user":{"displayName":"남중구","photoUrl":"","userId":"02914767085172164696"}},"outputId":"ecb405b8-bb93-4199-b974-dd33266b9ecd"},"source":["model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.fit(train_images, train_labels, epochs=1,batch_size=10)"],"execution_count":7,"outputs":[{"output_type":"stream","text":[" 2/14 [===>..........................] - ETA: 0s - loss: 930.9653 - accuracy: 0.3000  WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0214s vs `on_train_batch_end` time: 0.0351s). Check your callbacks.\n","14/14 [==============================] - 1s 75ms/step - loss: 158.4393 - accuracy: 0.5113\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f29dc2df208>"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V4WOPoRBdW6d","executionInfo":{"status":"ok","timestamp":1607233369917,"user_tz":-540,"elapsed":24271,"user":{"displayName":"남중구","photoUrl":"","userId":"02914767085172164696"}},"outputId":"0aca7870-f448-4436-c33a-aa30fc4e0853"},"source":["score = model.evaluate(test_images, test_labels, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Test loss: 0.8201956748962402\n","Test accuracy: 0.49253731966018677\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_mgiqsZrdW6d","executionInfo":{"status":"ok","timestamp":1607233369918,"user_tz":-540,"elapsed":24268,"user":{"displayName":"남중구","photoUrl":"","userId":"02914767085172164696"}}},"source":[""],"execution_count":8,"outputs":[]}]}