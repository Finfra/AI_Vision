{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Example From Flowers by Keras (Color Version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "from tensorflow.keras import datasets, layers, models, regularizers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pylab import *\n",
    "from numpy import *\n",
    "\n",
    "def getFolder(thePath,isFile=True):\n",
    "    return [f for f in listdir(thePath) if isFile == isfile(join(thePath, f)) ]\n",
    "\n",
    "\n",
    "def getImagesAndLabels(tPath):\n",
    "    labels=getFolder(tPath,False)\n",
    "    encoder={w: i for i, w in enumerate(labels)}\n",
    "    decoder={i: w  for i, w in enumerate(labels)}\n",
    "\n",
    "    \n",
    "    tImages,tLabels=None,None\n",
    "\n",
    "    for label in labels:\n",
    "        imgFolder=join(tPath,label)\n",
    "        files= [f for f in listdir(imgFolder) if isfile(join(imgFolder, f))]\n",
    "        for file in files:\n",
    "            imageFile=join(imgFolder,file)\n",
    "            img=np.array([imread(imageFile)])/255.\n",
    "            if tImages is None:\n",
    "                tImages, tLabels =img, np.array([encoder[label]],ndmin=1)\n",
    "            else:\n",
    "#                 print(tImages.shape,img.shape,imageFile)\n",
    "                tImages = np.vstack( (tImages,img) )\n",
    "                tLabels = np.append(tLabels,np.array([encoder[label]]) ,axis=0) \n",
    "        print(label,tImages.shape)                 \n",
    "    return (tImages,tLabels,encoder,decoder)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./flower_photos/daisy/5885826924_38fdc6bcaa_n.jpg JPEG 300x224 300x224+0+0 8-bit sRGB 91.3KB 0.000u 0:00.000\n",
      "./flower_photos/daisy/12701063955_4840594ea6_n.jpg JPEG 300x224 300x224+0+0 8-bit sRGB 137KB 0.000u 0:00.000\n",
      "./flower_photos/daisy/5997702776_c7bc37aa6b_n.jpg JPEG 300x224 300x224+0+0 8-bit sRGB 81.7KB 0.000u 0:00.000\n",
      "./flower_photos/daisy/5673728_71b8cb57eb.jpg JPEG 300x224 300x224+0+0 8-bit sRGB 77.7KB 0.000u 0:00.000\n",
      "./flower_photos/daisy/11834945233_a53b7a92ac_m.jpg JPEG 300x224 300x224+0+0 8-bit sRGB 77KB 0.000u 0:00.000\n",
      "./flower_photos/daisy/9204730092_a7f2182347.jpg JPEG 300x224 300x224+0+0 8-bit sRGB 108KB 0.000u 0:00.000\n",
      "./flower_photos/daisy/7066602021_2647457985_m.jpg JPEG 300x224 300x224+0+0 8-bit sRGB 111KB 0.000u 0:00.000\n",
      "./flower_photos/daisy/43474673_7bb4465a86.jpg JPEG 300x224 300x224+0+0 8-bit sRGB 76.6KB 0.000u 0:00.000\n",
      "./flower_photos/daisy/5876455546_32049e5585.jpg JPEG 300x224 300x224+0+0 8-bit sRGB 64.6KB 0.000u 0:00.000\n",
      "./flower_photos/daisy/512177035_70afc925c8.jpg JPEG 300x224 300x224+0+0 8-bit sRGB 86.2KB 0.000u 0:00.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n",
      "E: 잠금 파일 /var/lib/dpkg/lock-frontend 파일을 열 수 없습니다 - open (13: 허가 거부)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "identify ./flower_photos/daisy/5885826924_38fdc6bcaa_n.jpg \n",
      "identify ./flower_photos/daisy/12701063955_4840594ea6_n.jpg \n",
      "identify ./flower_photos/daisy/5997702776_c7bc37aa6b_n.jpg \n",
      "identify ./flower_photos/daisy/5673728_71b8cb57eb.jpg \n",
      "identify ./flower_photos/daisy/11834945233_a53b7a92ac_m.jpg \n",
      "identify ./flower_photos/daisy/9204730092_a7f2182347.jpg \n",
      "identify ./flower_photos/daisy/7066602021_2647457985_m.jpg \n",
      "identify ./flower_photos/daisy/43474673_7bb4465a86.jpg \n",
      "identify ./flower_photos/daisy/5876455546_32049e5585.jpg \n",
      "identify ./flower_photos/daisy/512177035_70afc925c8.jpg \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "x=$(dpkg -l|grep imagemagick);[ ${#x} -eq 0 ]&&sudo apt install -y imagemagick\n",
    "[ ! -f ./flower_photos.tgz ]&&wget http://download.tensorflow.org/example_images/flower_photos.tgz ; tar xzf ./flower_photos.tgz \n",
    "find ./flower_photos|grep jpg|xargs -i -t convert {} -quiet -resize 300x224\\! -quality 100 -colorspace RGB -type truecolor {} 2>> /tmp/log\n",
    "find ./flower_photos|grep jpg|head -n 10|xargs -i -t identify {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daisy (633, 224, 300, 3)\n",
      "tulips (1432, 224, 300, 3)\n",
      "dandelion (2330, 224, 300, 3)\n",
      "roses (2971, 224, 300, 3)\n",
      "sunflowers (3670, 224, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "basePath='./flower_photos'\n",
    "imgs,labels,encoder,decoder=getImagesAndLabels(basePath)\n",
    "\n",
    "class_cnt=len(encoder.keys())\n",
    "\n",
    "train_images,test_images,train_labels,test_labels=train_test_split(imgs,labels,test_size=0.3333, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train_images =  (2446, 224, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "imgShape=train_images[0].shape\n",
    "img_width,img_hight,color_count=imgShape\n",
    "train_images = train_images.reshape((-1,img_width,img_hight,color_count ))\n",
    "test_images = test_images.reshape((-1, img_width,img_hight,color_count ))\n",
    "\n",
    "print(\"Shape of Train_images = \",train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /prj/nowage/.virtualenvs/p3t1/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(128, (11, 11), activation='relu',padding='same',kernel_regularizer=regularizers.l2(0.02), input_shape=imgShape))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Conv2D(64, (7, 7), activation='relu',padding='same',kernel_regularizer=regularizers.l2(0.02)))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.MaxPooling2D((4, 4)))\n",
    "\n",
    "model.add(layers.Conv2D(4, (3, 3), activation='relu',padding='same',kernel_regularizer=regularizers.l2(0.02)))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='sigmoid',kernel_regularizer=regularizers.l2(0.02)))\n",
    "model.add(layers.Dense(class_cnt, activation='softmax'))\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2446 samples\n",
      "Epoch 1/50\n",
      "2446/2446 [==============================] - 107s 44ms/sample - loss: 2.9514 - acc: 0.3684\n",
      "Epoch 2/50\n",
      "2446/2446 [==============================] - 103s 42ms/sample - loss: 1.6785 - acc: 0.5012\n",
      "Epoch 3/50\n",
      "2446/2446 [==============================] - 103s 42ms/sample - loss: 1.4727 - acc: 0.5384\n",
      "Epoch 4/50\n",
      "2446/2446 [==============================] - 103s 42ms/sample - loss: 1.3461 - acc: 0.5670\n",
      "Epoch 5/50\n",
      "2446/2446 [==============================] - 103s 42ms/sample - loss: 1.2850 - acc: 0.5732\n",
      "Epoch 6/50\n",
      "2446/2446 [==============================] - 103s 42ms/sample - loss: 1.2236 - acc: 0.5998\n",
      "Epoch 7/50\n",
      "2446/2446 [==============================] - 103s 42ms/sample - loss: 1.1904 - acc: 0.6132\n",
      "Epoch 8/50\n",
      "2446/2446 [==============================] - 103s 42ms/sample - loss: 1.1502 - acc: 0.6382\n",
      "Epoch 9/50\n",
      "2446/2446 [==============================] - 103s 42ms/sample - loss: 1.1280 - acc: 0.6374\n",
      "Epoch 10/50\n",
      "2446/2446 [==============================] - 103s 42ms/sample - loss: 1.1045 - acc: 0.6586\n",
      "Epoch 11/50\n",
      "2446/2446 [==============================] - 103s 42ms/sample - loss: 1.1021 - acc: 0.6594\n",
      "Epoch 12/50\n",
      "2446/2446 [==============================] - 103s 42ms/sample - loss: 1.0989 - acc: 0.6660\n",
      "Epoch 13/50\n",
      "2446/2446 [==============================] - 103s 42ms/sample - loss: 1.0617 - acc: 0.6627\n",
      "Epoch 14/50\n",
      "2446/2446 [==============================] - 103s 42ms/sample - loss: 1.0640 - acc: 0.6697\n",
      "Epoch 15/50\n",
      "2446/2446 [==============================] - 103s 42ms/sample - loss: 1.0573 - acc: 0.6738\n",
      "Epoch 16/50\n",
      "2446/2446 [==============================] - 103s 42ms/sample - loss: 1.0484 - acc: 0.6832\n",
      "Epoch 17/50\n",
      "2446/2446 [==============================] - 103s 42ms/sample - loss: 1.0175 - acc: 0.7069\n",
      "Epoch 18/50\n",
      "2446/2446 [==============================] - 103s 42ms/sample - loss: 1.0126 - acc: 0.7044\n",
      "Epoch 19/50\n",
      "2446/2446 [==============================] - 103s 42ms/sample - loss: 1.0050 - acc: 0.7073\n",
      "Epoch 20/50\n",
      "2446/2446 [==============================] - 103s 42ms/sample - loss: 0.9852 - acc: 0.7175\n",
      "Epoch 21/50\n",
      "2446/2446 [==============================] - 103s 42ms/sample - loss: 0.9756 - acc: 0.7334\n",
      "Epoch 22/50\n",
      "2446/2446 [==============================] - 103s 42ms/sample - loss: 0.9678 - acc: 0.7294\n",
      "Epoch 23/50\n",
      "2446/2446 [==============================] - 103s 42ms/sample - loss: 0.9440 - acc: 0.7428\n",
      "Epoch 24/50\n",
      "2446/2446 [==============================] - 103s 42ms/sample - loss: 0.9529 - acc: 0.7355\n",
      "Epoch 25/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.9107 - acc: 0.7559\n",
      "Epoch 26/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.9111 - acc: 0.7653\n",
      "Epoch 27/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.9007 - acc: 0.7686\n",
      "Epoch 28/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.8618 - acc: 0.8029\n",
      "Epoch 29/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.8489 - acc: 0.8034\n",
      "Epoch 30/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.8363 - acc: 0.8074\n",
      "Epoch 31/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.8194 - acc: 0.8217\n",
      "Epoch 32/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.8165 - acc: 0.8217\n",
      "Epoch 33/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.7975 - acc: 0.8348\n",
      "Epoch 34/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.7693 - acc: 0.8504\n",
      "Epoch 35/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.7756 - acc: 0.8483\n",
      "Epoch 36/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.7646 - acc: 0.8565\n",
      "Epoch 37/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.7433 - acc: 0.8643\n",
      "Epoch 38/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.7307 - acc: 0.8679\n",
      "Epoch 39/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.7060 - acc: 0.8880\n",
      "Epoch 40/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.6967 - acc: 0.8876\n",
      "Epoch 41/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.6915 - acc: 0.8913\n",
      "Epoch 42/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.6784 - acc: 0.8851\n",
      "Epoch 43/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.6565 - acc: 0.9105\n",
      "Epoch 44/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.6505 - acc: 0.9064\n",
      "Epoch 45/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.6334 - acc: 0.9158\n",
      "Epoch 46/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.6197 - acc: 0.9178\n",
      "Epoch 47/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.6346 - acc: 0.9117\n",
      "Epoch 48/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.6122 - acc: 0.9195\n",
      "Epoch 49/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.5867 - acc: 0.9321\n",
      "Epoch 50/50\n",
      "2446/2446 [==============================] - 104s 42ms/sample - loss: 0.6138 - acc: 0.9215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0cd24cb4e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(lr=0.0002),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=50,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.5334567493862576\n",
      "Test accuracy: 0.5416667\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reularization 구혀해 보세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
