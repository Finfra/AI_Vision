{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageColorization.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9exYVgtqDmGE"
      },
      "source": [
        "# 흑백이미지 복원\n",
        "## ALGORITHMIA의 Colorize Photos\n",
        "* On-line App : https://demos.algorithmia.com/colorize-photos\n",
        "* The project is also available at GitHub here -> https://github.com/shubham0204/ImageColorization\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FER-2sf5Yghu"
      },
      "source": [
        "# 1) Importing the libraries\n",
        "We import [TensorFlow](https://www.tensorflow.org/), [Numpy](http://www.numpy.org/) and [scikit-image](https://scikit-image.org/) module for playing around with images. Printing out the TensorFlow version is a good practice to see that everything is working fine. ( See [Colorizer.py](https://github.com/shubham0204/ImageColorization/blob/master/Colorizer.py) on GitHub )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvqkjy-uNnpe"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.activations import *\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import models\n",
        "from skimage.io import imshow , imsave\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "print( tf.VERSION ) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZmrwCOnPuup"
      },
      "source": [
        "%cd /content/\n",
        "%rm -rf ImageColorization\n",
        "!git clone https://github.com/shubham0204/ImageColorization\n",
        "%cd /content/ImageColorization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LV9qJFLlZKMv"
      },
      "source": [
        "# 2) Loading the data\n",
        "We load the data which is stored in .npy files using the `np.load` method. We print out the shapes of the training and testing data.\n",
        "\n",
        "\n",
        "*   To convert your own images to .npy files, refer to the GitHub project and see the [Parser.py ](https://github.com/shubham0204/ImageColorization/blob/master/Parser.py)file.\n",
        "*   For sample data, download the three files from the [sample_data directory](https://github.com/shubham0204/ImageColorization/tree/master/sample_data) of the GitHub project.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQzxwItfQFes"
      },
      "source": [
        "!find .|grep model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHh6w4VRRFtx"
      },
      "source": [
        "\n",
        "X = np.load( './sample_data/X.npy' ) \n",
        "Y = np.load( './sample_data/Y.npy' ) \n",
        "test_X = np.load( './sample_data/test_X.npy' ) \n",
        "\n",
        "print( X.shape ,Y.shape ) \n",
        "print( test_X.shape ) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw2QjFXPRYCc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(X[0].reshape( (64,64))  ,cmap='gray')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qemg-ahRY0G"
      },
      "source": [
        "plt.imshow(Y[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3qQrVizZg-d"
      },
      "source": [
        "# 3) Defining the model\n",
        "We define our Convolutional Auto Encoder model using the Keras [Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential).\n",
        "\n",
        "\n",
        "*   We use a low dropout rate of 0.3,\n",
        "*   `DIMEN` is the dimension of the image which acts as an input to the model. In our case, it is 64 or the image has dimensions of 64px * 64px.\n",
        "\n",
        "We compile the model to use the Adam optimizer with a learning rate of 0.0001. The loss function is mean squared error and we output the `mae` or mean absolute error of the model during training. ( See [Colorizer.py](https://github.com/shubham0204/ImageColorization/blob/master/Colorizer.py) on GitHub )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6PMbuWKQhzA"
      },
      "source": [
        "\n",
        "dropout_rate = 0.5\n",
        "DIMEN = 64\n",
        "kernel_size = ( 4 , 4 )\n",
        "\n",
        "NEURAL_SCHEMA = [\n",
        "\n",
        "    Conv2D( 32 , input_shape=( DIMEN , DIMEN , 1 ) , kernel_size=kernel_size , strides=1,activation=relu),\n",
        "    Dropout( dropout_rate ) ,\n",
        "    Conv2D( 64, kernel_size=kernel_size, strides=1, activation=relu),\n",
        "    Dropout(dropout_rate),\n",
        "    Conv2D( 128, kernel_size=kernel_size, strides=1, activation=relu) ,\n",
        "    Dropout(dropout_rate),\n",
        "    Conv2D( 256, kernel_size=kernel_size, strides=1, activation=relu),\n",
        "    Dropout(dropout_rate),\n",
        "    Conv2DTranspose( 128, kernel_size=kernel_size, strides=1, activation=relu),\n",
        "    Dropout(dropout_rate),\n",
        "    Conv2DTranspose( 64, kernel_size=kernel_size, strides=1, activation=relu),\n",
        "    Dropout(dropout_rate),\n",
        "    Conv2DTranspose( 32, kernel_size=kernel_size, strides=1, activation=relu),\n",
        "    Dropout(dropout_rate),\n",
        "    Conv2DTranspose( 3, kernel_size=kernel_size, strides=1, activation=tanh ),\n",
        "\n",
        "]\n",
        "\n",
        "model = tf.keras.Sequential( NEURAL_SCHEMA )\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(0.0001),\n",
        "    loss=losses.mean_squared_error,\n",
        "    metrics=['mae'],\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtWauJ_oa91F"
      },
      "source": [
        "# 4) Training the model\n",
        "We train the model over the training dataset using the `fit()` method.  ( See [Colorizer.py](https://github.com/shubham0204/ImageColorization/blob/master/Colorizer.py) on GitHub )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsiYdr5yEiVr"
      },
      "source": [
        "**Note : If required, load the model which was trained earlier or use the model located in the [models](https://github.com/shubham0204/ImageColorization/tree/master/models) directory on GitHub.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr9XCkZbEi0S"
      },
      "source": [
        "\n",
        "model = models.load_model( './models/final_model.h5' ) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BENB4VEVRakX"
      },
      "source": [
        "\n",
        "model.fit(\n",
        "    X, \n",
        "    Y, \n",
        "    batch_size=3 , \n",
        "    epochs=500\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeyH6qRrct1v"
      },
      "source": [
        "We save the model to export it or download it to our local machine using `model.save()` method. **Tip : To use it on an Android or iOS device, use [this notebook](https://colab.research.google.com/drive/1IUIn9ffk5ICKujqPyuGaHL2irQ9Wmtpm) to convert the model.h5 to a [TensorFlow Lite](https://www.tensorflow.org/lite) model ( .tflite ).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9rObwqpcslp"
      },
      "source": [
        "\n",
        "model.save( 'model.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KpZXzxfboy5"
      },
      "source": [
        "# 5) Colorizing the images\n",
        "\n",
        "\n",
        "\n",
        "1.   We take the grayscale images and feed them to our model\n",
        "2.   To avoid negative values, we perform a operation to convert all negative values to 0.\n",
        "3.   We multiply the values by 255 ( the images used for training were normalised ).\n",
        "4.   Convert the values to a image array using `imsave( )` method.\n",
        "\n",
        "( See [MainFile.py ](https://github.com/shubham0204/ImageColorization/blob/master/MainFile.py)on GitHub )\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCY8ZIkARpLx"
      },
      "source": [
        "\n",
        "values = model.predict( test_X )\n",
        "values = np.maximum( values , 0 )\n",
        "\n",
        "for i in range( 6 ):\n",
        "    image_final = ( values[i] * 255).astype( np.uint8 )\n",
        "    imsave( '{}.png'.format( i + 1 ) , image_final  )\n",
        "    imshow( image_final )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNOJYJ9dRqhs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}