{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder on Iris Dataset \n",
    "* Source : https://www.kaggle.com/shivam1600/autoencoder-on-iris-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Data\n",
    "data = pd.read_csv(\"../../data/iris.csv\")\n",
    "data.head()\n",
    "x_train, x_test, y_train, y_test = train_test_split(data[['Sepal.Length', 'Sepal.Width',\n",
    "                                                          'Petal.Length', 'Petal.Width']],\n",
    "                                                    data['Species'],test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 30        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 30        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 28        \n",
      "=================================================================\n",
      "Total params: 138\n",
      "Trainable params: 138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim1 = 6\n",
    "encoding_dim2 = 4\n",
    "encoding_dim3 = 2\n",
    "input_dim = 4\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(input_dim,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim1)(input_img)\n",
    "encoded = Dense(encoding_dim2)(encoded)\n",
    "encoded = Dense(encoding_dim3)(encoded)\n",
    "\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(encoding_dim2)(encoded)\n",
    "decoded = Dense(encoding_dim1)(decoded)\n",
    "decoded = Dense(input_dim)(decoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "#encoder = decoder_layer = autoencoder.layers[3]\n",
    "\n",
    "# create a placeholder for an encoded (2-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim3,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "\n",
    "decoder_layer = autoencoder.layers[-3](encoded_input)\n",
    "decoder_layer = autoencoder.layers[-2](decoder_layer)\n",
    "decoder_layer = autoencoder.layers[-1](decoder_layer)\n",
    "\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer)\n",
    "opt=RMSprop(lr=0.001)\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer=opt)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/333\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 81.4218 - val_loss: 71.4730\n",
      "Epoch 2/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 67.3217 - val_loss: 63.6495\n",
      "Epoch 3/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 60.0022 - val_loss: 57.6189\n",
      "Epoch 4/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 54.3452 - val_loss: 52.6915\n",
      "Epoch 5/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 49.7625 - val_loss: 48.9540\n",
      "Epoch 6/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 46.2586 - val_loss: 45.7862\n",
      "Epoch 7/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 43.2720 - val_loss: 42.9266\n",
      "Epoch 8/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 40.5531 - val_loss: 40.1213\n",
      "Epoch 9/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 37.9496 - val_loss: 38.0662\n",
      "Epoch 10/333\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 35.9826 - val_loss: 35.8748\n",
      "Epoch 11/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 33.9457 - val_loss: 34.2354\n",
      "Epoch 12/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 32.3733 - val_loss: 32.4413\n",
      "Epoch 13/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 30.6909 - val_loss: 30.9456\n",
      "Epoch 14/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 29.2806 - val_loss: 29.5937\n",
      "Epoch 15/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 27.9956 - val_loss: 28.2467\n",
      "Epoch 16/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 26.7203 - val_loss: 26.9875\n",
      "Epoch 17/333\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 25.5409 - val_loss: 25.9378\n",
      "Epoch 18/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 24.5332 - val_loss: 24.7685\n",
      "Epoch 19/333\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 23.4293 - val_loss: 23.7223\n",
      "Epoch 20/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 22.4301 - val_loss: 22.6361\n",
      "Epoch 21/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 21.4048 - val_loss: 21.6648\n",
      "Epoch 22/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 20.4883 - val_loss: 20.7981\n",
      "Epoch 23/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 19.6682 - val_loss: 19.9823\n",
      "Epoch 24/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 18.8893 - val_loss: 19.1313\n",
      "Epoch 25/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 18.0854 - val_loss: 18.3607\n",
      "Epoch 26/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 17.3625 - val_loss: 17.7024\n",
      "Epoch 27/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 16.7409 - val_loss: 17.0745\n",
      "Epoch 28/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 16.1491 - val_loss: 16.4794\n",
      "Epoch 29/333\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 15.5870 - val_loss: 15.8902\n",
      "Epoch 30/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 15.0318 - val_loss: 15.3189\n",
      "Epoch 31/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 14.4925 - val_loss: 14.7583\n",
      "Epoch 32/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 13.9618 - val_loss: 14.1930\n",
      "Epoch 33/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 13.4285 - val_loss: 13.6710\n",
      "Epoch 34/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 12.9388 - val_loss: 13.1935\n",
      "Epoch 35/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 12.4851 - val_loss: 12.6760\n",
      "Epoch 36/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 12.0038 - val_loss: 12.2501\n",
      "Epoch 37/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 11.6070 - val_loss: 11.8224\n",
      "Epoch 38/333\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 11.2077 - val_loss: 11.3819\n",
      "Epoch 39/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 10.7954 - val_loss: 10.9148\n",
      "Epoch 40/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 10.3586 - val_loss: 10.4869\n",
      "Epoch 41/333\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 9.9620 - val_loss: 10.0766\n",
      "Epoch 42/333\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 9.5834 - val_loss: 9.6469\n",
      "Epoch 43/333\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 9.1786 - val_loss: 9.1667\n",
      "Epoch 44/333\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 8.7301 - val_loss: 8.7186\n",
      "Epoch 45/333\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 8.3106 - val_loss: 8.2759\n",
      "Epoch 46/333\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 7.8993 - val_loss: 7.7990\n",
      "Epoch 47/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 7.4580 - val_loss: 7.3490\n",
      "Epoch 48/333\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 7.0480 - val_loss: 6.9102\n",
      "Epoch 49/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 6.6451 - val_loss: 6.4431\n",
      "Epoch 50/333\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 6.2124 - val_loss: 5.9918\n",
      "Epoch 51/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 5.7932 - val_loss: 5.5468\n",
      "Epoch 52/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 5.3840 - val_loss: 5.1070\n",
      "Epoch 53/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 4.9740 - val_loss: 4.6459\n",
      "Epoch 54/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 4.5465 - val_loss: 4.2392\n",
      "Epoch 55/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 4.1718 - val_loss: 3.8940\n",
      "Epoch 56/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 3.8535 - val_loss: 3.5216\n",
      "Epoch 57/333\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 3.4987 - val_loss: 3.1300\n",
      "Epoch 58/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 3.1275 - val_loss: 2.7885\n",
      "Epoch 59/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.8070 - val_loss: 2.4830\n",
      "Epoch 60/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.5211 - val_loss: 2.2193\n",
      "Epoch 61/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.2703 - val_loss: 1.9493\n",
      "Epoch 62/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0079 - val_loss: 1.7252\n",
      "Epoch 63/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.7933 - val_loss: 1.5432\n",
      "Epoch 64/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6231 - val_loss: 1.3734\n",
      "Epoch 65/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.4495 - val_loss: 1.2213\n",
      "Epoch 66/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.2982 - val_loss: 1.1093\n",
      "Epoch 67/333\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.1915 - val_loss: 1.0247\n",
      "Epoch 68/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.1093 - val_loss: 0.9504\n",
      "Epoch 69/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.0294 - val_loss: 0.8754\n",
      "Epoch 70/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.9428 - val_loss: 0.8142\n",
      "Epoch 71/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.8782 - val_loss: 0.7794\n",
      "Epoch 72/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.8411 - val_loss: 0.7403\n",
      "Epoch 73/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.7847 - val_loss: 0.7062\n",
      "Epoch 74/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.7495 - val_loss: 0.6868\n",
      "Epoch 75/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.7238 - val_loss: 0.6816\n",
      "Epoch 76/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6991 - val_loss: 0.6632\n",
      "Epoch 77/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6765 - val_loss: 0.6518\n",
      "Epoch 78/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.6650 - val_loss: 0.6463\n",
      "Epoch 79/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6567 - val_loss: 0.6512\n",
      "Epoch 80/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6501 - val_loss: 0.6618\n",
      "Epoch 81/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6481 - val_loss: 0.6349\n",
      "Epoch 82/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6350 - val_loss: 0.6322\n",
      "Epoch 83/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6297 - val_loss: 0.6249\n",
      "Epoch 84/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6317 - val_loss: 0.6256\n",
      "Epoch 85/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6320 - val_loss: 0.6256\n",
      "Epoch 86/333\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6176 - val_loss: 0.6108\n",
      "Epoch 87/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.6168 - val_loss: 0.6101\n",
      "Epoch 88/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6209 - val_loss: 0.6189\n",
      "Epoch 89/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.6057 - val_loss: 0.6147\n",
      "Epoch 90/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6040 - val_loss: 0.6361\n",
      "Epoch 91/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6112 - val_loss: 0.6269\n",
      "Epoch 92/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6039 - val_loss: 0.5991\n",
      "Epoch 93/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5923 - val_loss: 0.5853\n",
      "Epoch 94/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5925 - val_loss: 0.5969\n",
      "Epoch 95/333\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5875 - val_loss: 0.5862\n",
      "Epoch 96/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5853 - val_loss: 0.5857\n",
      "Epoch 97/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6014 - val_loss: 0.5811\n",
      "Epoch 98/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5778 - val_loss: 0.5831\n",
      "Epoch 99/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5761 - val_loss: 0.5868\n",
      "Epoch 100/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5749 - val_loss: 0.6124\n",
      "Epoch 101/333\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5857 - val_loss: 0.6219\n",
      "Epoch 102/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5841 - val_loss: 0.5764\n",
      "Epoch 103/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5675 - val_loss: 0.5696\n",
      "Epoch 104/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5756 - val_loss: 0.5613\n",
      "Epoch 105/333\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5769 - val_loss: 0.5615\n",
      "Epoch 106/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5629 - val_loss: 0.5774\n",
      "Epoch 107/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5625 - val_loss: 0.6109\n",
      "Epoch 108/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5721 - val_loss: 0.5802\n",
      "Epoch 109/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5592 - val_loss: 0.5662\n",
      "Epoch 110/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5556 - val_loss: 0.5580\n",
      "Epoch 111/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5573 - val_loss: 0.5648\n",
      "Epoch 112/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5539 - val_loss: 0.5578\n",
      "Epoch 113/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5520 - val_loss: 0.5721\n",
      "Epoch 114/333\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5720 - val_loss: 0.5491\n",
      "Epoch 115/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5523 - val_loss: 0.5729\n",
      "Epoch 116/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5496 - val_loss: 0.5759\n",
      "Epoch 117/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5483 - val_loss: 0.5496\n",
      "Epoch 118/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5495 - val_loss: 0.5601\n",
      "Epoch 119/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5460 - val_loss: 0.5797\n",
      "Epoch 120/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5481 - val_loss: 0.5587\n",
      "Epoch 121/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5425 - val_loss: 0.5661\n",
      "Epoch 122/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5414 - val_loss: 0.5454\n",
      "Epoch 123/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5398 - val_loss: 0.5540\n",
      "Epoch 124/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5375 - val_loss: 0.5641\n",
      "Epoch 125/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5427 - val_loss: 0.5926\n",
      "Epoch 126/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5555 - val_loss: 0.5982\n",
      "Epoch 127/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5570 - val_loss: 0.5861\n",
      "Epoch 128/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5467 - val_loss: 0.5478\n",
      "Epoch 129/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5317 - val_loss: 0.5497\n",
      "Epoch 130/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5301 - val_loss: 0.5461\n",
      "Epoch 131/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5282 - val_loss: 0.5320\n",
      "Epoch 132/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5322 - val_loss: 0.5718\n",
      "Epoch 133/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5341 - val_loss: 0.5442\n",
      "Epoch 134/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5336 - val_loss: 0.5510\n",
      "Epoch 135/333\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5285 - val_loss: 0.5316\n",
      "Epoch 136/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5262 - val_loss: 0.5346\n",
      "Epoch 137/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5243 - val_loss: 0.5326\n",
      "Epoch 138/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5288 - val_loss: 0.5357\n",
      "Epoch 139/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5285 - val_loss: 0.5360\n",
      "Epoch 140/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5211 - val_loss: 0.5322\n",
      "Epoch 141/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5176 - val_loss: 0.5338\n",
      "Epoch 142/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5177 - val_loss: 0.5558\n",
      "Epoch 143/333\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5206 - val_loss: 0.5221\n",
      "Epoch 144/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5196 - val_loss: 0.5199\n",
      "Epoch 145/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5201 - val_loss: 0.5208\n",
      "Epoch 146/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5119 - val_loss: 0.5192\n",
      "Epoch 147/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5141 - val_loss: 0.5502\n",
      "Epoch 148/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5144 - val_loss: 0.5452\n",
      "Epoch 149/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5141 - val_loss: 0.5179\n",
      "Epoch 150/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5051 - val_loss: 0.5525\n",
      "Epoch 151/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5109 - val_loss: 0.5136\n",
      "Epoch 152/333\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5051 - val_loss: 0.5134\n",
      "Epoch 153/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5074 - val_loss: 0.5218\n",
      "Epoch 154/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5000 - val_loss: 0.5114\n",
      "Epoch 155/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5020 - val_loss: 0.5123\n",
      "Epoch 156/333\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4961 - val_loss: 0.5052\n",
      "Epoch 157/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4963 - val_loss: 0.5498\n",
      "Epoch 158/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5051 - val_loss: 0.5030\n",
      "Epoch 159/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4949 - val_loss: 0.5084\n",
      "Epoch 160/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4973 - val_loss: 0.5121\n",
      "Epoch 161/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5004 - val_loss: 0.4969\n",
      "Epoch 162/333\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4907 - val_loss: 0.5073\n",
      "Epoch 163/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4856 - val_loss: 0.4941\n",
      "Epoch 164/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4904 - val_loss: 0.4906\n",
      "Epoch 165/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4898 - val_loss: 0.4870\n",
      "Epoch 166/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4873 - val_loss: 0.5007\n",
      "Epoch 167/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4905 - val_loss: 0.4911\n",
      "Epoch 168/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4867 - val_loss: 0.4959\n",
      "Epoch 169/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4810 - val_loss: 0.5062\n",
      "Epoch 170/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4786 - val_loss: 0.5307\n",
      "Epoch 171/333\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4825 - val_loss: 0.4804\n",
      "Epoch 172/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4753 - val_loss: 0.4813\n",
      "Epoch 173/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4717 - val_loss: 0.4970\n",
      "Epoch 174/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4781 - val_loss: 0.4749\n",
      "Epoch 175/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4771 - val_loss: 0.4763\n",
      "Epoch 176/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4647 - val_loss: 0.4739\n",
      "Epoch 177/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4634 - val_loss: 0.4867\n",
      "Epoch 178/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4615 - val_loss: 0.4702\n",
      "Epoch 179/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4612 - val_loss: 0.4652\n",
      "Epoch 180/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4670 - val_loss: 0.4607\n",
      "Epoch 181/333\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4600 - val_loss: 0.4643\n",
      "Epoch 182/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4534 - val_loss: 0.4762\n",
      "Epoch 183/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4535 - val_loss: 0.4785\n",
      "Epoch 184/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4546 - val_loss: 0.4696\n",
      "Epoch 185/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4529 - val_loss: 0.4808\n",
      "Epoch 186/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4496 - val_loss: 0.4614\n",
      "Epoch 187/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4404 - val_loss: 0.4714\n",
      "Epoch 188/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4401 - val_loss: 0.4444\n",
      "Epoch 189/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4418 - val_loss: 0.4475\n",
      "Epoch 190/333\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4442 - val_loss: 0.4703\n",
      "Epoch 191/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4344 - val_loss: 0.4392\n",
      "Epoch 192/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4352 - val_loss: 0.4617\n",
      "Epoch 193/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4300 - val_loss: 0.4444\n",
      "Epoch 194/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4255 - val_loss: 0.4414\n",
      "Epoch 195/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4266 - val_loss: 0.4550\n",
      "Epoch 196/333\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4264 - val_loss: 0.4515\n",
      "Epoch 197/333\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4237 - val_loss: 0.4305\n",
      "Epoch 198/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4163 - val_loss: 0.4385\n",
      "Epoch 199/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4164 - val_loss: 0.4204\n",
      "Epoch 200/333\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4230 - val_loss: 0.4227\n",
      "Epoch 201/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4073 - val_loss: 0.4240\n",
      "Epoch 202/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4042 - val_loss: 0.4246\n",
      "Epoch 203/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4023 - val_loss: 0.4230\n",
      "Epoch 204/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4040 - val_loss: 0.4081\n",
      "Epoch 205/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3981 - val_loss: 0.4227\n",
      "Epoch 206/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3981 - val_loss: 0.4011\n",
      "Epoch 207/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3909 - val_loss: 0.4392\n",
      "Epoch 208/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3999 - val_loss: 0.4297\n",
      "Epoch 209/333\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3912 - val_loss: 0.3910\n",
      "Epoch 210/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3834 - val_loss: 0.3914\n",
      "Epoch 211/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3770 - val_loss: 0.3940\n",
      "Epoch 212/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3752 - val_loss: 0.3787\n",
      "Epoch 213/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3788 - val_loss: 0.3751\n",
      "Epoch 214/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3754 - val_loss: 0.3762\n",
      "Epoch 215/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3680 - val_loss: 0.4070\n",
      "Epoch 216/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3685 - val_loss: 0.3725\n",
      "Epoch 217/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3579 - val_loss: 0.3630\n",
      "Epoch 218/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3600 - val_loss: 0.3650\n",
      "Epoch 219/333\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3573 - val_loss: 0.3843\n",
      "Epoch 220/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3537 - val_loss: 0.3586\n",
      "Epoch 221/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3506 - val_loss: 0.3573\n",
      "Epoch 222/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3526 - val_loss: 0.3528\n",
      "Epoch 223/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3542 - val_loss: 0.3482\n",
      "Epoch 224/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3380 - val_loss: 0.3589\n",
      "Epoch 225/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3350 - val_loss: 0.3649\n",
      "Epoch 226/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3357 - val_loss: 0.3566\n",
      "Epoch 227/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3329 - val_loss: 0.3560\n",
      "Epoch 228/333\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3326 - val_loss: 0.3300\n",
      "Epoch 229/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3295 - val_loss: 0.3279\n",
      "Epoch 230/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3178 - val_loss: 0.3257\n",
      "Epoch 231/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3120 - val_loss: 0.3186\n",
      "Epoch 232/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3134 - val_loss: 0.3199\n",
      "Epoch 233/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3063 - val_loss: 0.3372\n",
      "Epoch 234/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3064 - val_loss: 0.3531\n",
      "Epoch 235/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3112 - val_loss: 0.3081\n",
      "Epoch 236/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2925 - val_loss: 0.3327\n",
      "Epoch 237/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2973 - val_loss: 0.3094\n",
      "Epoch 238/333\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2881 - val_loss: 0.3004\n",
      "Epoch 239/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2821 - val_loss: 0.2995\n",
      "Epoch 240/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2795 - val_loss: 0.3340\n",
      "Epoch 241/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2919 - val_loss: 0.2907\n",
      "Epoch 242/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2777 - val_loss: 0.3136\n",
      "Epoch 243/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2760 - val_loss: 0.2778\n",
      "Epoch 244/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2656 - val_loss: 0.2932\n",
      "Epoch 245/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2654 - val_loss: 0.2987\n",
      "Epoch 246/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2663 - val_loss: 0.2894\n",
      "Epoch 247/333\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2613 - val_loss: 0.2788\n",
      "Epoch 248/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2550 - val_loss: 0.2805\n",
      "Epoch 249/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2617 - val_loss: 0.2544\n",
      "Epoch 250/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2479 - val_loss: 0.2522\n",
      "Epoch 251/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2455 - val_loss: 0.2458\n",
      "Epoch 252/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2394 - val_loss: 0.2495\n",
      "Epoch 253/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2336 - val_loss: 0.2408\n",
      "Epoch 254/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2513 - val_loss: 0.2337\n",
      "Epoch 255/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2396 - val_loss: 0.2283\n",
      "Epoch 256/333\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2312 - val_loss: 0.2378\n",
      "Epoch 257/333\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2233 - val_loss: 0.2471\n",
      "Epoch 258/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2241 - val_loss: 0.2190\n",
      "Epoch 259/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2165 - val_loss: 0.2179\n",
      "Epoch 260/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2132 - val_loss: 0.2374\n",
      "Epoch 261/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2128 - val_loss: 0.2509\n",
      "Epoch 262/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2156 - val_loss: 0.2221\n",
      "Epoch 263/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2085 - val_loss: 0.2238\n",
      "Epoch 264/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2059 - val_loss: 0.2103\n",
      "Epoch 265/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1969 - val_loss: 0.2030\n",
      "Epoch 266/333\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1924 - val_loss: 0.2077\n",
      "Epoch 267/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1917 - val_loss: 0.2035\n",
      "Epoch 268/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1882 - val_loss: 0.1943\n",
      "Epoch 269/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1911 - val_loss: 0.1972\n",
      "Epoch 270/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1850 - val_loss: 0.1848\n",
      "Epoch 271/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1772 - val_loss: 0.1971\n",
      "Epoch 272/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1804 - val_loss: 0.1809\n",
      "Epoch 273/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1694 - val_loss: 0.1832\n",
      "Epoch 274/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1665 - val_loss: 0.1849\n",
      "Epoch 275/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1664 - val_loss: 0.2055\n",
      "Epoch 276/333\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1753 - val_loss: 0.1856\n",
      "Epoch 277/333\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1641 - val_loss: 0.1783\n",
      "Epoch 278/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1572 - val_loss: 0.1588\n",
      "Epoch 279/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1500 - val_loss: 0.1732\n",
      "Epoch 280/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1519 - val_loss: 0.1624\n",
      "Epoch 281/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1471 - val_loss: 0.1499\n",
      "Epoch 282/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1449 - val_loss: 0.1513\n",
      "Epoch 283/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1397 - val_loss: 0.1427\n",
      "Epoch 284/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1369 - val_loss: 0.1615\n",
      "Epoch 285/333\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1388 - val_loss: 0.1424\n",
      "Epoch 286/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1307 - val_loss: 0.1313\n",
      "Epoch 287/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1370 - val_loss: 0.1349\n",
      "Epoch 288/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1321 - val_loss: 0.1233\n",
      "Epoch 289/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1285 - val_loss: 0.1202\n",
      "Epoch 290/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1178 - val_loss: 0.1314\n",
      "Epoch 291/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1194 - val_loss: 0.1359\n",
      "Epoch 292/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1198 - val_loss: 0.1412\n",
      "Epoch 293/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1203 - val_loss: 0.1286\n",
      "Epoch 294/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1160 - val_loss: 0.1317\n",
      "Epoch 295/333\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1127 - val_loss: 0.1122\n",
      "Epoch 296/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1045 - val_loss: 0.1024\n",
      "Epoch 297/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1065 - val_loss: 0.1058\n",
      "Epoch 298/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1059 - val_loss: 0.0985\n",
      "Epoch 299/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0986 - val_loss: 0.1072\n",
      "Epoch 300/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0961 - val_loss: 0.0964\n",
      "Epoch 301/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1008 - val_loss: 0.0935\n",
      "Epoch 302/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1003 - val_loss: 0.1030\n",
      "Epoch 303/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0935 - val_loss: 0.0981\n",
      "Epoch 304/333\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0902 - val_loss: 0.1022\n",
      "Epoch 305/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0904 - val_loss: 0.0956\n",
      "Epoch 306/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0865 - val_loss: 0.0966\n",
      "Epoch 307/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0853 - val_loss: 0.1007\n",
      "Epoch 308/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0882 - val_loss: 0.0843\n",
      "Epoch 309/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0820 - val_loss: 0.0804\n",
      "Epoch 310/333\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0783 - val_loss: 0.0940\n",
      "Epoch 311/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0822 - val_loss: 0.0902\n",
      "Epoch 312/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0788 - val_loss: 0.0923\n",
      "Epoch 313/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0788 - val_loss: 0.0791\n",
      "Epoch 314/333\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0718 - val_loss: 0.0730\n",
      "Epoch 315/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0703 - val_loss: 0.0908\n",
      "Epoch 316/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0762 - val_loss: 0.0659\n",
      "Epoch 317/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0675 - val_loss: 0.0707\n",
      "Epoch 318/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0685 - val_loss: 0.0695\n",
      "Epoch 319/333\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0668 - val_loss: 0.0591\n",
      "Epoch 320/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0618 - val_loss: 0.0591\n",
      "Epoch 321/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0656 - val_loss: 0.0558\n",
      "Epoch 322/333\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0632 - val_loss: 0.0534\n",
      "Epoch 323/333\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0601 - val_loss: 0.0685\n",
      "Epoch 324/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0738 - val_loss: 0.0515\n",
      "Epoch 325/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0557 - val_loss: 0.0520\n",
      "Epoch 326/333\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0560 - val_loss: 0.0581\n",
      "Epoch 327/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0547 - val_loss: 0.0627\n",
      "Epoch 328/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0569 - val_loss: 0.0576\n",
      "Epoch 329/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0558 - val_loss: 0.0812\n",
      "Epoch 330/333\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0659 - val_loss: 0.0522\n",
      "Epoch 331/333\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0505 - val_loss: 0.0604\n",
      "Epoch 332/333\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0540 - val_loss: 0.0668\n",
      "Epoch 333/333\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0585 - val_loss: 0.0663\n",
      "Original Datapoints :\n",
      "     Sepal.Length  Sepal.Width  Petal.Length  Petal.Width\n",
      "14            5.8          4.0           1.2          0.2\n",
      "98            5.1          2.5           3.0          1.1\n",
      "75            6.6          3.0           4.4          1.4\n",
      "16            5.4          3.9           1.3          0.4\n",
      "131           7.9          3.8           6.4          2.0\n",
      "56            6.3          3.3           4.7          1.6\n",
      "141           6.9          3.1           5.1          2.3\n",
      "44            5.1          3.8           1.9          0.4\n",
      "29            4.7          3.2           1.6          0.2\n",
      "120           6.9          3.2           5.7          2.3\n",
      "94            5.6          2.7           4.2          1.3\n",
      "5             5.4          3.9           1.7          0.4\n",
      "102           7.1          3.0           5.9          2.1\n",
      "51            6.4          3.2           4.5          1.5\n",
      "78            6.0          2.9           4.5          1.5\n",
      "Reconstructed Datapoints :\n",
      "[[5.5337424  3.5545511  1.2007012  0.72328347]\n",
      " [5.0998435  2.7452855  3.0526652  1.0172057 ]\n",
      " [6.247005   2.9669697  4.434534   1.6066856 ]\n",
      " [5.343359   3.4228985  1.281894   0.69304544]\n",
      " [7.4577813  3.0927935  6.2470737  2.305917  ]\n",
      " [6.2113104  2.9012518  4.5840836  1.6302547 ]\n",
      " [6.801068   2.9879816  5.3836694  1.9527149 ]\n",
      " [5.135807   3.194212   1.6491822  0.7207617 ]\n",
      " [4.6737094  3.013461   1.3919103  0.54847234]\n",
      " [6.8236322  2.8796663  5.7796893  2.0445962 ]\n",
      " [5.527655   2.6764202  4.0640635  1.3450181 ]\n",
      " [5.3427434  3.3369308  1.5621797  0.7539001 ]\n",
      " [6.8209977  2.8321977  5.93024    2.0767028 ]\n",
      " [6.210454   2.9419932  4.449145   1.600667  ]\n",
      " [5.895804   2.7746181  4.418971   1.514916  ]]\n"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=333,\n",
    "                batch_size=123,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "               callbacks=[])\n",
    "\n",
    "# encode and decode some data points\n",
    "# note that we take them from the *test* set\n",
    "encoded_datapoints = encoder.predict(x_test)\n",
    "decoded_datapoints = decoder.predict(encoded_datapoints)\n",
    "\n",
    "print('Original Datapoints :')\n",
    "print(x_test)\n",
    "print('Reconstructed Datapoints :')\n",
    "print(decoded_datapoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Encoded Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset = encoder.predict(x_test[['Sepal.Length', 'Sepal.Width',\n",
    "                                        'Petal.Length', 'Petal.Width']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rc('axes', unicode_minus=False)\n",
    "plt.scatter(encoded_dataset[:,0], encoded_dataset[:,1], c=y_test.astype('category').cat.codes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoded Dataset(reconstruncted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoded_dataset=decoder.predict(encoded_dataset)\n",
    "plt.scatter(decoded_dataset[:,2], decoded_dataset[:,3], c=y_test.astype('category').cat.codes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orignal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_test['Petal.Length'], x_test['Petal.Width'],c=y_test.astype('category').cat.codes)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
