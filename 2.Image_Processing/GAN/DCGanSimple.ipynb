{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DCGanSimple.ipynb","provenance":[{"file_id":"https://github.com/keras-team/keras-io/blob/master/examples/generative/ipynb/dcgan_overriding_train_step.ipynb","timestamp":1606877303975}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"RE4APM3NWbcp"},"source":["# GAN overriding `Model.train_step`\n","* Source : https://keras.io/examples/generative/dcgan_overriding_train_step/\n","\n","**Author:** [fchollet](https://twitter.com/fchollet)<br>\n","**Date created:** 2019/04/29<br>\n","**Last modified:** 2020/04/29<br>\n","**Description:** A simple DCGAN trained using `fit()` by overriding `train_step`."]},{"cell_type":"markdown","metadata":{"id":"Q_Eo7ZVJWbcq"},"source":["## Setup"]},{"cell_type":"code","metadata":{"id":"DekunSMmWbcq","executionInfo":{"status":"ok","timestamp":1606897842408,"user_tz":-540,"elapsed":2841,"user":{"displayName":"남중구","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdjUdzM516IqW5OZZ8t6jU96Fd8d5gitHsvgLBeA=s64","userId":"04014122822541888792"}}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import numpy as np"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hbGIPRiKWbcq"},"source":["## Prepare MNIST data"]},{"cell_type":"code","metadata":{"id":"tDAzpbWuWbcq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606897848464,"user_tz":-540,"elapsed":8893,"user":{"displayName":"남중구","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdjUdzM516IqW5OZZ8t6jU96Fd8d5gitHsvgLBeA=s64","userId":"04014122822541888792"}},"outputId":"940e2ac7-dd38-4a75-c432-9471336563aa"},"source":["# We use both the training & test MNIST digits.\n","batch_size = 32\n","(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n","all_digits = np.concatenate([x_train, x_test])\n","all_digits = all_digits.astype(\"float32\") / 255\n","all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n","dataset = tf.data.Dataset.from_tensor_slices(all_digits)\n","dataset = dataset.shuffle(buffer_size=1024).batch(batch_size).prefetch(32)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZYHeI9msWbcq"},"source":["## Create the discriminator\n","\n","It maps 28x28 digits to a binary classification score."]},{"cell_type":"code","metadata":{"id":"0o-FKh2qWbcq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606897848465,"user_tz":-540,"elapsed":8881,"user":{"displayName":"남중구","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdjUdzM516IqW5OZZ8t6jU96Fd8d5gitHsvgLBeA=s64","userId":"04014122822541888792"}},"outputId":"fcae2f2b-bbc1-430d-e3ad-bcd717b92afa"},"source":["discriminator = keras.Sequential(\n","    [\n","        keras.Input(shape=(28, 28, 1)),\n","        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.GlobalMaxPooling2D(),\n","        layers.Dense(1),\n","    ],\n","    name=\"discriminator\",\n",")\n","\n","discriminator.summary()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Model: \"discriminator\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 14, 14, 64)        640       \n","_________________________________________________________________\n","leaky_re_lu (LeakyReLU)      (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 7, 7, 128)         73856     \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","global_max_pooling2d (Global (None, 128)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 1)                 129       \n","=================================================================\n","Total params: 74,625\n","Trainable params: 74,625\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"at4C5JFbWbcq"},"source":["## Create the generator\n","\n","It mirrors the discriminator, replacing `Conv2D` layers with `Conv2DTranspose` layers."]},{"cell_type":"code","metadata":{"id":"t5MxTaxJWbcq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606897848466,"user_tz":-540,"elapsed":8872,"user":{"displayName":"남중구","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdjUdzM516IqW5OZZ8t6jU96Fd8d5gitHsvgLBeA=s64","userId":"04014122822541888792"}},"outputId":"cdc77006-0bd2-425e-999f-64369446b8b4"},"source":["latent_dim = 128\n","\n","generator = keras.Sequential(\n","    [\n","        keras.Input(shape=(latent_dim,)),\n","        # We want to generate 128 coefficients to reshape into a 7x7x128 map\n","        layers.Dense(7 * 7 * 128),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Reshape((7, 7, 128)),\n","        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n","    ],\n","    name=\"generator\",\n",")\n","\n","generator.summary()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Model: \"generator\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 6272)              809088    \n","_________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)    (None, 6272)              0         \n","_________________________________________________________________\n","reshape (Reshape)            (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","conv2d_transpose (Conv2DTran (None, 14, 14, 128)       262272    \n","_________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 128)       0         \n","_________________________________________________________________\n","conv2d_transpose_1 (Conv2DTr (None, 28, 28, 128)       262272    \n","_________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)    (None, 28, 28, 128)       0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 28, 28, 1)         6273      \n","=================================================================\n","Total params: 1,339,905\n","Trainable params: 1,339,905\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WGgHHBxHWbcq"},"source":["## Override `train_step`"]},{"cell_type":"code","metadata":{"id":"Spscbl7HWbcq","executionInfo":{"status":"ok","timestamp":1606897848466,"user_tz":-540,"elapsed":8870,"user":{"displayName":"남중구","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdjUdzM516IqW5OZZ8t6jU96Fd8d5gitHsvgLBeA=s64","userId":"04014122822541888792"}}},"source":["\n","class GAN(keras.Model):\n","    def __init__(self, discriminator, generator, latent_dim):\n","        super(GAN, self).__init__()\n","        self.discriminator = discriminator\n","        self.generator = generator\n","        self.latent_dim = latent_dim\n","\n","    def compile(self, d_optimizer, g_optimizer, loss_fn):\n","        super(GAN, self).compile()\n","        self.d_optimizer = d_optimizer\n","        self.g_optimizer = g_optimizer\n","        self.loss_fn = loss_fn\n","\n","    def train_step(self, real_images):\n","        if isinstance(real_images, tuple):\n","            real_images = real_images[0]\n","        # Sample random points in the latent space\n","        batch_size = tf.shape(real_images)[0]\n","        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n","\n","        # Decode them to fake images\n","        generated_images = self.generator(random_latent_vectors)\n","\n","        # Combine them with real images\n","        combined_images = tf.concat([generated_images, real_images], axis=0)\n","\n","        # Assemble labels discriminating real from fake images\n","        labels = tf.concat(\n","            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n","        )\n","        # Add random noise to the labels - important trick!\n","        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n","\n","        # Train the discriminator\n","        with tf.GradientTape() as tape:\n","            predictions = self.discriminator(combined_images)\n","            d_loss = self.loss_fn(labels, predictions)\n","        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n","        self.d_optimizer.apply_gradients(\n","            zip(grads, self.discriminator.trainable_weights)\n","        )\n","\n","        # Sample random points in the latent space\n","        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n","\n","        # Assemble labels that say \"all real images\"\n","        misleading_labels = tf.zeros((batch_size, 1))\n","\n","        # Train the generator (note that we should *not* update the weights\n","        # of the discriminator)!\n","        with tf.GradientTape() as tape:\n","            predictions = self.discriminator(self.generator(random_latent_vectors))\n","            g_loss = self.loss_fn(misleading_labels, predictions)\n","        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n","        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n","        return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0j_JCQoQWbcq"},"source":["## Create a callback that periodically saves generated images"]},{"cell_type":"code","metadata":{"id":"ZPlNMZvrWbcq","executionInfo":{"status":"ok","timestamp":1606897848467,"user_tz":-540,"elapsed":8870,"user":{"displayName":"남중구","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdjUdzM516IqW5OZZ8t6jU96Fd8d5gitHsvgLBeA=s64","userId":"04014122822541888792"}}},"source":["\n","class GANMonitor(keras.callbacks.Callback):\n","    def __init__(self, num_img=3, latent_dim=128):\n","        self.num_img = num_img\n","        self.latent_dim = latent_dim\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n","        generated_images = self.model.generator(random_latent_vectors)\n","        generated_images *= 255\n","        generated_images.numpy()\n","        for i in range(self.num_img):\n","            img = keras.preprocessing.image.array_to_img(generated_images[i])\n","            img.save(\"generated_img_{i}_{epoch}.png\".format(i=i, epoch=epoch))\n"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uUwTszFSWbcq"},"source":["## Train the end-to-end model"]},{"cell_type":"code","metadata":{"id":"qdmd_SYLWbcq","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3e7d8cda-b1a9-49de-965f-03e0b00a4f82"},"source":["epochs = 100\n","\n","gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n","gan.compile(\n","    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n","    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n","    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",")\n","\n","gan.fit(\n","    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=3, latent_dim=latent_dim)]\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","2188/2188 [==============================] - 70s 32ms/step - d_loss: 0.3537 - g_loss: 2.6370\n","Epoch 2/100\n","2188/2188 [==============================] - 70s 32ms/step - d_loss: 0.6075 - g_loss: 1.1090\n","Epoch 3/100\n","2188/2188 [==============================] - 70s 32ms/step - d_loss: 0.6074 - g_loss: 0.9873\n","Epoch 4/100\n","2188/2188 [==============================] - 70s 32ms/step - d_loss: 0.5770 - g_loss: 1.0381\n","Epoch 5/100\n","2188/2188 [==============================] - 70s 32ms/step - d_loss: 0.5489 - g_loss: 1.0940\n","Epoch 6/100\n","2188/2188 [==============================] - 70s 32ms/step - d_loss: 0.5332 - g_loss: 1.1376\n","Epoch 7/100\n","2188/2188 [==============================] - 70s 32ms/step - d_loss: 0.5289 - g_loss: 1.1564\n","Epoch 8/100\n","2188/2188 [==============================] - 70s 32ms/step - d_loss: 0.5404 - g_loss: 1.1415\n","Epoch 9/100\n","2188/2188 [==============================] - 70s 32ms/step - d_loss: 0.5488 - g_loss: 1.1291\n","Epoch 10/100\n","2188/2188 [==============================] - 70s 32ms/step - d_loss: 0.5558 - g_loss: 1.1219\n","Epoch 11/100\n","2188/2188 [==============================] - 70s 32ms/step - d_loss: 0.5614 - g_loss: 1.1152\n","Epoch 12/100\n","2188/2188 [==============================] - 70s 32ms/step - d_loss: 0.5679 - g_loss: 1.1093\n","Epoch 13/100\n","2188/2188 [==============================] - 70s 32ms/step - d_loss: 0.5758 - g_loss: 1.0865\n","Epoch 14/100\n","2188/2188 [==============================] - 70s 32ms/step - d_loss: 0.5798 - g_loss: 1.0797\n","Epoch 15/100\n","2188/2188 [==============================] - 70s 32ms/step - d_loss: 0.5829 - g_loss: 1.0709\n","Epoch 16/100\n","2188/2188 [==============================] - 70s 32ms/step - d_loss: 0.5863 - g_loss: 1.0619\n","Epoch 17/100\n","1413/2188 [==================>...........] - ETA: 24s - d_loss: 0.5897 - g_loss: 1.0604"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bMahI3H3Wbcq"},"source":["Display the last generated images:"]},{"cell_type":"code","metadata":{"id":"-3QcIxqjWbcq"},"source":["from IPython.display import Image, display\n","for i in range(epochs):\n","  display(Image(f\"generated_img_2_{i}.png\"))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FnyYvhsgXT5z"},"source":["display(Image(f\"generated_img_0_{epochs-1}.png\"))\n","display(Image(f\"generated_img_1_{epochs-1}.png\"))\n","display(Image(f\"generated_img_2_{epochs-1}.png\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L7gHAwHCjaAm"},"source":["\n"],"execution_count":null,"outputs":[]}]}