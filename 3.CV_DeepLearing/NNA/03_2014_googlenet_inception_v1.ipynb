{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data Preparation\n",
    "\n",
    "googlenet 이후부터는 227 x 227 안쓰고  원래대로 224 x 224 사용해도 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from tensorflow.contrib.learn.python.learn.datasets import base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from tensorflow.contrib.learn.python.learn.datasets import base\n",
    "\n",
    "\n",
    "class DataSet(object):\n",
    "    def __init__(self, data_type, images, image_reshape_size=224, labels=None):\n",
    "        \"\"\"\n",
    "        Construct a new DataSet object.\n",
    "        :param images: np.ndarray, shape: (N, H, W, C).\n",
    "        :param labels: np.ndarray, shape: (N, num_classes) or (N,).\n",
    "        \"\"\"\n",
    "        if labels is not None:\n",
    "            assert images.shape[0] == labels.shape[0], (\n",
    "                'Number of examples mismatch, between images and labels.'\n",
    "            )\n",
    "        self._num_examples = images.shape[0]\n",
    "        self._data_type = data_type\n",
    "        self._images = images\n",
    "        self._labels = labels    # NOTE: this can be None, if not given.\n",
    "        self._indices = np.arange(self._num_examples, dtype=np.uint)    # image/label indices(can be permuted)\n",
    "        self._augment = True\n",
    "        self._image_reshape_size = image_reshape_size\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self):\n",
    "        \"\"\"Reset some variables.\"\"\"\n",
    "        self._completed_epoch_count = 0\n",
    "        self._idx_in_current_epoch = 0\n",
    "        \n",
    "    def set_augment(self, augment):\n",
    "        self._augment = augment\n",
    "\n",
    "    @property\n",
    "    def images(self):\n",
    "        return self._images\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "\n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "\n",
    "    def next_batch(self, batch_size, shuffle=True, fake_data=False):\n",
    "        \"\"\"\n",
    "        Return the next `batch_size` examples from this dataset.\n",
    "        :param batch_size: int, size of a single batch.\n",
    "        :param shuffle: bool, whether to shuffle the whole set while sampling a batch.\n",
    "        :param augment: bool, whether to perform data augmentation while sampling a batch.\n",
    "        :param is_train: bool, current phase for sampling.\n",
    "        :param fake_data: bool, whether to generate fake data (for debugging).\n",
    "        :return: batch_images: np.ndarray, shape: (N, h, w, C) or (N, 10, h, w, C).\n",
    "                 batch_labels: np.ndarray, shape: (N, num_classes) or (N,).\n",
    "        \"\"\"\n",
    "        if fake_data:\n",
    "            fake_batch_images = np.random.random(size=(batch_size, self._image_reshape_size, self._image_reshape_size, 3))\n",
    "            fake_batch_labels = np.zeros((batch_size, 2), dtype=np.uint8)\n",
    "            fake_batch_labels[np.arange(batch_size), np.random.randint(2, size=batch_size)] = 1\n",
    "            return fake_batch_images, fake_batch_labels\n",
    "\n",
    "        idx_begin = self._idx_in_current_epoch\n",
    "\n",
    "        # Shuffle the dataset, for the first epoch\n",
    "        if self._completed_epoch_count == 0 and idx_begin == 0 and shuffle:\n",
    "            np.random.shuffle(self._indices)\n",
    "\n",
    "        # Go to the next epoch, if current index goes beyond the total number of examples\n",
    "        if idx_begin + batch_size > self._num_examples:\n",
    "            # Increment the number of epochs completed\n",
    "            self._completed_epoch_count += 1\n",
    "            \n",
    "            # Get the rest examples in this epoch\n",
    "            remaining_num_examples = self._num_examples - idx_begin\n",
    "            remaining_indices = self._indices[idx_begin:self._num_examples]\n",
    "\n",
    "            # Shuffle the dataset, after finishing a single epoch\n",
    "            if shuffle:\n",
    "                np.random.shuffle(self._indices)\n",
    "\n",
    "            # Start the next epoch\n",
    "            idx_begin = 0\n",
    "            self._idx_in_current_epoch = batch_size - remaining_num_examples\n",
    "            idx_end = self._idx_in_current_epoch\n",
    "            new_indices = self._indices[idx_begin:idx_end]\n",
    "\n",
    "            remaining_images = self.images[remaining_indices]\n",
    "            new_images = self.images[new_indices]\n",
    "            batch_images = np.concatenate((remaining_images, new_images), axis=0)\n",
    "            if self.labels is not None:\n",
    "                remaining_labels = self.labels[remaining_indices]\n",
    "                new_labels = self.labels[new_indices]\n",
    "                batch_labels = np.concatenate((remaining_labels, new_labels), axis=0)\n",
    "            else:\n",
    "                print('nono1')\n",
    "                batch_labels = None\n",
    "        else:\n",
    "            self._idx_in_current_epoch += batch_size\n",
    "            idx_end = self._idx_in_current_epoch\n",
    "            indices = self._indices[idx_begin:idx_end]\n",
    "            batch_images = self.images[indices]\n",
    "            if self.labels is not None:\n",
    "                batch_labels = self.labels[indices]\n",
    "            else:\n",
    "                batch_labels = None\n",
    "\n",
    "        if self._augment and self._data_type == 'train':\n",
    "            # Perform data augmentation, for training phase\n",
    "            batch_images = random_crop_reflect(batch_images, self._image_reshape_size)\n",
    "        elif self._augment and self._data_type != 'train':\n",
    "            # Perform data augmentation, for evaluation phase(10x)\n",
    "            batch_images = corner_center_crop_reflect(batch_images, self._image_reshape_size)\n",
    "        else:\n",
    "            # Don't perform data augmentation, generating center-cropped patches\n",
    "            batch_images = center_crop(batch_images, self._image_reshape_size)\n",
    "        \n",
    "        return batch_images, batch_labels\n",
    "\n",
    "\n",
    "def random_crop_reflect(images, crop_l):\n",
    "    \"\"\"\n",
    "    Perform random cropping and reflection from images.\n",
    "    :param images: np.ndarray, shape: (N, H, W, C).\n",
    "    :param crop_l: int, a side length of crop region.\n",
    "    :return: np.ndarray, shape: (N, h, w, C).\n",
    "    \"\"\"\n",
    "    H, W = images.shape[1:3]\n",
    "    augmented_images = []\n",
    "    for image in images:    # image.shape: (H, W, C)\n",
    "            \n",
    "        # Randomly crop patch\n",
    "        y = np.random.randint(H-crop_l)\n",
    "        x = np.random.randint(W-crop_l)\n",
    "        image = image[y:y+crop_l, x:x+crop_l]    # (h, w, C)\n",
    "\n",
    "        # Randomly reflect patch horizontally\n",
    "        reflect = bool(np.random.randint(2))\n",
    "        if reflect:\n",
    "            image = image[:, ::-1]\n",
    "\n",
    "        augmented_images.append(image)\n",
    "    return np.stack(augmented_images)    # shape: (N, h, w, C)\n",
    "\n",
    "\n",
    "def corner_center_crop_reflect(images, crop_l):\n",
    "    \"\"\"\n",
    "    Perform 4 corners and center cropping and reflection from images,\n",
    "    resulting in 10x augmented patches.\n",
    "    :param images: np.ndarray, shape: (N, H, W, C).\n",
    "    :param crop_l: int, a side length of crop region.\n",
    "    :return: np.ndarray, shape: (N, 10, h, w, C).\n",
    "    \"\"\"\n",
    "    H, W = images.shape[1:3]\n",
    "    augmented_images = []\n",
    "    for image in images:    # image.shape: (H, W, C)\n",
    "        aug_image_orig = []\n",
    "        # Crop image in 4 corners\n",
    "        aug_image_orig.append(image[:crop_l, :crop_l])\n",
    "        aug_image_orig.append(image[:crop_l, -crop_l:])\n",
    "        aug_image_orig.append(image[-crop_l:, :crop_l])\n",
    "        aug_image_orig.append(image[-crop_l:, -crop_l:])\n",
    "        # Crop image in the center\n",
    "        aug_image_orig.append(image[H//2-(crop_l//2):H//2+(crop_l-crop_l//2),\n",
    "                                    W//2-(crop_l//2):W//2+(crop_l-crop_l//2)])\n",
    "        aug_image_orig = np.stack(aug_image_orig)    # (5, h, w, C)\n",
    "\n",
    "        # Flip augmented images and add it\n",
    "        aug_image_flipped = aug_image_orig[:, :, ::-1]    # (5, h, w, C)\n",
    "        aug_image = np.concatenate((aug_image_orig, aug_image_flipped), axis=0)    # (10, h, w, C)\n",
    "        augmented_images.append(aug_image)\n",
    "    return np.stack(augmented_images)    # shape: (N, 10, h, w, C)\n",
    "\n",
    "\n",
    "def center_crop(images, crop_l):\n",
    "    \"\"\"\n",
    "    Perform center cropping of images.\n",
    "    :param images: np.ndarray, shape: (N, H, W, C).\n",
    "    :param crop_l: int, a side length of crop region.\n",
    "    :return: np.ndarray, shape: (N, h, w, C).\n",
    "    \"\"\"\n",
    "    H, W = images.shape[1:3]\n",
    "    cropped_images = []\n",
    "    for image in images:    # image.shape: (H, W, C)\n",
    "        # Crop image in the center\n",
    "        cropped_images.append(image[H//2-(crop_l//2):H//2+(crop_l-crop_l//2),\n",
    "                              W//2-(crop_l//2):W//2+(crop_l-crop_l//2)])\n",
    "    return np.stack(cropped_images)\n",
    "\n",
    "\n",
    "def read_asirra_subset(subset_dir, one_hot=True, sample_size=None):\n",
    "    \"\"\"\n",
    "    Load the Asirra Dogs vs. Cats data subset from disk\n",
    "    and perform preprocessing for training AlexNet.\n",
    "    :param subset_dir: str, path to the directory to read.\n",
    "    :param one_hot: bool, whether to return one-hot encoded labels.\n",
    "    :param sample_size: int, sample size specified when we are not using the entire set.\n",
    "    :return: X_set: np.ndarray, shape: (N, H, W, C).\n",
    "             y_set: np.ndarray, shape: (N, num_channels) or (N,).\n",
    "    \"\"\"\n",
    "    # Read trainval data\n",
    "    filename_list = os.listdir(subset_dir)\n",
    "    set_size = len(filename_list)\n",
    "\n",
    "    if sample_size is not None and sample_size < set_size:\n",
    "        # Randomly sample subset of data when sample_size is specified\n",
    "        filename_list = np.random.choice(filename_list, size=sample_size, replace=False)\n",
    "        set_size = sample_size\n",
    "    else:\n",
    "        # Just shuffle the filename list\n",
    "        np.random.shuffle(filename_list)\n",
    "\n",
    "    # Pre-allocate data arrays\n",
    "    msg_interval = 1000 if set_size >= 1000 else 10\n",
    "    \n",
    "    X_set = np.empty((set_size, 256, 256, 3), dtype=np.float32)    # (N, H, W, 3)\n",
    "    y_set = np.empty((set_size), dtype=np.uint8)                   # (N,)\n",
    "    for i, filename in enumerate(filename_list):\n",
    "        if i % msg_interval == 0:\n",
    "            print('     progress: {}/{}...'.format(i, set_size), end='\\r')\n",
    "        label = filename.split('.')[0]\n",
    "        if label == 'cat':\n",
    "            y = 0\n",
    "        else:  # label == 'dog'\n",
    "            y = 1\n",
    "        file_path = os.path.join(subset_dir, filename)\n",
    "        img = imread(file_path)    # shape: (H, W, 3), range: [0, 255]\n",
    "        img = resize(img, (256, 256), mode='constant').astype(np.float32)    # (256, 256, 3), [0.0, 1.0]\n",
    "        X_set[i] = img\n",
    "        y_set[i] = y\n",
    "\n",
    "    if one_hot:\n",
    "        # Convert labels to one-hot vectors, shape: (N, num_classes)\n",
    "        y_set_oh = np.zeros((set_size, 2), dtype=np.uint8)\n",
    "        y_set_oh[np.arange(set_size), y_set] = 1\n",
    "        y_set = y_set_oh\n",
    "        \n",
    "    print('     progress: {}/{}...'.format(set_size, set_size), end='\\r')\n",
    "    print('\\n Done\\n')\n",
    "\n",
    "    return X_set, y_set, set_size\n",
    "\n",
    "\n",
    "def read_train_data_sets(subset_dir, image_reshape_size=227, one_hot=True, sample_train_size=None):\n",
    "    print(\" Reading train/validation data\")\n",
    "    train_images, train_labels, set_size = read_asirra_subset(subset_dir + 'train', one_hot, sample_train_size) \n",
    "    validation_size = int(set_size * 0.2)\n",
    "    \n",
    "    validation_images = train_images[:validation_size]\n",
    "    validation_labels = train_labels[:validation_size]\n",
    "    train_images = train_images[validation_size:]\n",
    "    train_labels = train_labels[validation_size:]\n",
    "\n",
    "    train = DataSet('train', train_images, image_reshape_size, train_labels)\n",
    "    validation = DataSet('validation', validation_images, image_reshape_size, validation_labels)\n",
    "    \n",
    "    return base.Datasets(train=train, validation=validation, test=None)\n",
    "\n",
    "\n",
    "def read_test_data_sets(subset_dir, image_reshape_size=227, one_hot=True, sample_train_size=None):\n",
    "    print(\"\\n Reading test data..\")\n",
    "    test_images, test_labels, _ = read_asirra_subset(subset_dir + 'test', one_hot) \n",
    "\n",
    "    test = DataSet('test', test_images, image_reshape_size, test_labels)    \n",
    "    \n",
    "    return base.Datasets(train=None, validation=None, test=test)\n",
    "    \n",
    "        \n",
    "def read_data_sets(subset_dir, image_reshape_size=227, one_hot=True, sample_train_size=None):\n",
    "    print(\" Reading train/validation data\")\n",
    "    train_images, train_labels, set_size = read_asirra_subset(subset_dir + 'train', one_hot, sample_train_size) \n",
    "    validation_size = int(set_size * 0.2)\n",
    "    \n",
    "    validation_images = train_images[:validation_size]\n",
    "    validation_labels = train_labels[:validation_size]\n",
    "    train_images = train_images[validation_size:]\n",
    "    train_labels = train_labels[validation_size:]\n",
    "\n",
    "    print(\"\\n Reading test data..\")\n",
    "    test_images, test_labels, _ = read_asirra_subset(subset_dir + 'test', one_hot) \n",
    "\n",
    "    train = DataSet('train', train_images, image_reshape_size, train_labels)\n",
    "    validation = DataSet('validation', validation_images, image_reshape_size, validation_labels)\n",
    "    test = DataSet('test', test_images, image_reshape_size, test_labels)    \n",
    "    \n",
    "    return base.Datasets(train=train, validation=validation, test=test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_train = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Reading train/validation data\n",
      "     progress: 16/16...\n",
      " Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = read_train_data_sets('./asirra_smaller/', image_reshape_size=224)\n",
    "data_train = data.train\n",
    "data_validation = data.validation\n",
    "\n",
    "num_classes = len(data_train.labels[0])  # cat, dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape   : (13, 256, 256, 3)\n",
      "ConvNet Input Image Shape   : (2, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Image Shape   : {0}\".format(data_train.images.shape))\n",
    "sample_input_x, sample_input_y = data_train.next_batch(2)\n",
    "print(\"ConvNet Input Image Shape   : {0}\".format(sample_input_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train batch\n",
    "batch_size = 256\n",
    "batch_size = batch_size \\\n",
    "                if batch_size <= data_train.num_examples \\\n",
    "                else data_train.num_examples\n",
    "\n",
    "num_epochs = 300  # deep network라서 많이 돌려야 됨\n",
    "num_batches_per_epoch = data_train.num_examples // batch_size   # 10 // 3 = 3\n",
    "\n",
    "\n",
    "# L2 regularization (weight decay)\n",
    "# Used at: comput loss\n",
    "weight_decay = 0.0005\n",
    "\n",
    "# dropout regularization: \n",
    "# Used at: fc layers\n",
    "train_dropout_rate = 0.4\n",
    "\n",
    "\n",
    "# adding momentum (to avoid local minima)\n",
    "# Used at: tf.train.MomentumOptimizer\n",
    "momentum = 0.9\n",
    "\n",
    "# update learning rate (epsilon)\n",
    "# Used at: update_learning_rate\n",
    "init_learning_rate = 0.01\n",
    "patience_of_no_improvement_epochs = 30\n",
    "learning_rate_decay = 0.1\n",
    "lower_bound_learning_rate = 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "# Build GoogLeNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = ''  # log printing variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### layer building functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_images(height, width, in_channel):\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, [None, height, width, in_channel])\n",
    "    \n",
    "    global info\n",
    "    info = ' Inputs / Labels'\n",
    "    info += '\\n   {:12s}: {:17s}  {}'.format('x', str(x.shape), 'input images')\n",
    "    return x\n",
    "\n",
    "def output_labels(out_channel):\n",
    "    y = tf.placeholder(tf.float32, [None, out_channel])\n",
    "    global info\n",
    "    info += '\\n   {:12s}: {:17s}  {}\\n\\n Feature Extraction'.format('y', str(y.shape), 'target value (answer label)')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(name, inputs, filter_size, stride, num_filters, padding='VALID', is_print=True):\n",
    "   \n",
    "    w_mean=0.0\n",
    "    w_stddev=0.01\n",
    "    bias=0.1\n",
    "    \n",
    "    in_channel = int(inputs.get_shape()[-1])\n",
    "    out_channel = num_filters\n",
    "\n",
    "    weights = tf.get_variable(name=name + '_weights',\n",
    "                shape=[filter_size, filter_size, in_channel, out_channel],\n",
    "                initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    biases = tf.get_variable(name + '_biases',\n",
    "                [out_channel], tf.float32,\n",
    "                tf.constant_initializer(value=bias))\n",
    "\n",
    "    conv = tf.nn.conv2d(inputs, weights, \n",
    "                strides=[1, stride, stride, 1],\n",
    "                padding=padding) + bias\n",
    "\n",
    "    conv = tf.nn.relu(conv)  # activation (non-linearizing)\n",
    "\n",
    "    if is_print:\n",
    "        global info\n",
    "        # skip if this is an inception layer's sub layer\n",
    "        info += '\\n   {:12s}: {:17s} -> {:17s}'.format(\n",
    "                        name,  str(inputs.shape), str(conv.shape) )        \n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool(name, inputs, filter_size, stride, padding='VALID', is_print=True):\n",
    "    pool = tf.nn.max_pool(inputs, \n",
    "               ksize = [1, filter_size, filter_size, 1],\n",
    "               strides = [1,stride,stride,1], padding=padding)\n",
    "\n",
    "    if is_print:\n",
    "        global info\n",
    "        # skip if this is an inception layer's sub layer\n",
    "        info += '\\n   {:12s}: {:17s} -> {:17s}'.format(\n",
    "                        name,  str(inputs.shape), str(pool.shape) )\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_pool(name, inputs, filter_size, stride, padding='VALID', is_print=True):\n",
    "    avg_pool = tf.nn.avg_pool(inputs, \n",
    "               ksize = [1, filter_size, filter_size, 1],\n",
    "               strides = [1,stride,stride,1], padding=padding)\n",
    "\n",
    "    if is_print:\n",
    "        global info\n",
    "        # skip if this is an inception layer's sub layer\n",
    "        info += '\\n   {:12s}: {:17s} -> {:17s}'.format(\n",
    "                        name,  str(inputs.shape), str(avg_pool.shape) )\n",
    "    return avg_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrn(name, inputs, depth_radius=5, alpha=0.0001, beta=0.75):\n",
    "    #  LRN (local response normalization) layer\n",
    "    global info\n",
    "    info += '\\n   local response normalization'\n",
    "    return tf.nn.local_response_normalization(name=name, \n",
    "                    input=inputs, depth_radius=depth_radius, alpha=alpha, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception(name, inputs, conv_1x1_out, conv_3x3_reduce_out, conv_3x3_out, conv_5x5_reduce_out, conv_5x5_out, pool_proj_out):\n",
    "    \"\"\"                   namme\n",
    "                          input        filtersize  stride ,    |filters|          padding  is_print\"\"\"\n",
    "    conv_1x1        = conv(name + '_conv_1x1',\n",
    "                           inputs         , 1      , 1     ,   conv_1x1_out       , 'SAME', False)\n",
    "    conv_3x3_reduce = conv(name + '_conv_3x3_reduce',\n",
    "                           inputs         , 1      , 1     ,   conv_3x3_reduce_out, 'SAME', False)\n",
    "    conv_3x3        = conv(name + '_conv_3x3',\n",
    "                           conv_3x3_reduce, 3      , 1     ,   conv_3x3_out       , 'SAME', False)        \n",
    "    conv_5x5_reduce = conv(name + '_conv_5x5_reduce',\n",
    "                           inputs         , 1      , 1     ,   conv_5x5_reduce_out, 'SAME', False)        \n",
    "    conv_5x5        = conv(name + '_conv_5x5',\n",
    "                           conv_5x5_reduce, 5      , 1     ,   conv_5x5_out       , 'SAME', False)        \n",
    "    _pool           = pool(name + 'max_pool_3x3',\n",
    "                           inputs         , 3      , 1     ,   'SAME', False)        \n",
    "    pool_proj       = conv(name + '_pool_proj',\n",
    "                           _pool          , 1      , 1     ,   pool_proj_out      , 'SAME', False)\n",
    "    inception       = tf.concat([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3)\n",
    "    \n",
    "    global info\n",
    "    info += '\\n   {:12s}: {:17s} -> {:17s}'.format(\n",
    "                    name, str(inputs.shape), str(inception.shape))\n",
    "    return inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auxilliary_classifier(name, inputs, aux_fc1_out, aux_fc2_out):\n",
    "    train_dropout_rate = 0.7  # auxilliary classifier 할 때만 잠시 global hyperparameter 값 바꿈\n",
    "    \"\"\"                     name                               filter_size  stride  out_channel padding  print \"\"\"\n",
    "    aux_avg_pool = avg_pool(name + '_avg_pool'       , inputs       , 5     , 3   ,            'VALID', False)   \n",
    "    aux_conv     = conv(name + '_conv'               , aux_avg_pool , 1     , 1   ,   128  ,   'SAME' , False)\n",
    "    aux_flat     = tf.contrib.layers.flatten(aux_conv)\n",
    "    aux_fc1      = fc(name + '_fc1'   , aux_flat,      aux_fc1_out     , False)\n",
    "    aux_fc2      = fc(name + '_fc2'   , aux_fc1 ,      aux_fc2_out     , False)\n",
    "    aux_logits   = fc_last(name + '_logits', aux_fc2 , num_classes, False)\n",
    "\n",
    "    global info\n",
    "    info += '\\n   {:12s}: {:8s} auxilliary classifer, only performed at the train stage'.format(name + '_y_pred', str(aux_logits.shape))\n",
    "\n",
    "    train_dropout_rate = 0.4  # 원래 값 복원\n",
    "    return aux_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(name, inputs):\n",
    "    flattened = tf.contrib.layers.flatten(inputs)\n",
    "\n",
    "    global info\n",
    "    info += '\\n   {:12s}: {:17s} -> {:17s}\\n\\n Classification'.format(\n",
    "                    name, str(inputs.shape), str(flattened.shape) )\n",
    "    return flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(name, inputs):\n",
    "    # The probability of keeping each unit for dropout layers\n",
    "    keep_prob_value = tf.cond(tf.cast(is_train, tf.bool),\n",
    "                              lambda: train_dropout_rate,\n",
    "                              lambda: 1.0)\n",
    "\n",
    "    dropout = tf.nn.dropout(inputs, keep_prob=keep_prob_value)\n",
    "    global info\n",
    "    info += '\\n   {:12s}: {:17s} -> {:17s}'.format(\n",
    "                    name,  str(inputs.shape), str(dropout.shape) )\n",
    "    return dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc(name, inputs, output_size, is_print=True):\n",
    "    #w_mean=0.0      to speedup train time\n",
    "    #w_stddev=0.01\n",
    "    bias=0.1\n",
    "    in_dim = int(inputs.get_shape()[-1])\n",
    "    out_dim = output_size\n",
    "\n",
    "    weights = tf.get_variable(name=name + '_weights',\n",
    "                shape=[in_dim, out_dim],\n",
    "                initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    biases = tf.get_variable(name + '_biases',\n",
    "                [out_dim], tf.float32,\n",
    "                tf.constant_initializer(value=bias))\n",
    "\n",
    "    fc = tf.matmul(inputs, weights) + biases\n",
    "    fc = tf.nn.relu(fc)  # activation\n",
    "\n",
    "    # The probability of keeping each unit for dropout layers\n",
    "    keep_prob_value = tf.cond(tf.cast(is_train, tf.bool),\n",
    "                              lambda: train_dropout_rate,\n",
    "                              lambda: 1.0)\n",
    "    # print('dropout rate', train_dropout_rate)\n",
    "    # sess = tf.Session()\n",
    "    # print(\"answer    : \", sess.run(keep_prob_value))\n",
    "\n",
    "    fc = tf.nn.dropout(fc, keep_prob=keep_prob_value)\n",
    "\n",
    "    if is_print:\n",
    "        global info\n",
    "        info += '\\n   {:12s}: {:17s} -> {:17s}'.format(\n",
    "                       name,  str(inputs.shape), str(fc.shape) )        \n",
    "    return fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_last(name, inputs, output_size, is_print=True):\n",
    "    #w_mean=0.0\n",
    "    #w_stddev=0.01\n",
    "    bias=0.1\n",
    "    in_dim = int(inputs.get_shape()[-1])\n",
    "    out_dim = output_size\n",
    "\n",
    "    #weights = tf.get_variable(name + '_weights', \n",
    "    #            [in_dim, out_dim],\n",
    "    #            tf.float32,\n",
    "    #            tf.random_normal_initializer(mean=w_mean, stddev=w_stddev))\n",
    "    weights = tf.get_variable(name=name + '_weights',\n",
    "                shape=[in_dim, out_dim],\n",
    "                initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    biases = tf.get_variable(name + '_biases',\n",
    "                [out_dim], tf.float32,\n",
    "                tf.constant_initializer(value=bias))\n",
    "\n",
    "    logits = tf.matmul(inputs, weights) + biases\n",
    "\n",
    "    if is_print:\n",
    "        global info\n",
    "        info += '\\n   {:12s}: {:17s} -> {:17s}'.format(\n",
    "                        name,  str(inputs.shape), str(logits.shape) )        \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_softmax(name, inputs):\n",
    "    # hypothesis (prediction) of target value y\n",
    "    y_hat = tf.nn.softmax(inputs)  \n",
    "    \n",
    "    global info\n",
    "    info += '\\n\\n Output\\n   {:12s}: {:8s}hypothesis (prediction) of target value y'.format(name, str(y_hat.shape))\n",
    "\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### network layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModel:\n",
    "    # input\n",
    "    x = None\n",
    "    y = None\n",
    "\n",
    "    # feature extraction\n",
    "    conv1 = None\n",
    "    pool1 = None        \n",
    "    lrn1 = None  #  LRN (local response normalization) layer\n",
    "\n",
    "    conv2_1 = None\n",
    "    conv2_2 = None\n",
    "    pool2 = None\n",
    "\n",
    "    inception3a = None\n",
    "    inception3b = None\n",
    "    pool3 = None\n",
    "\n",
    "    inception4a = None\n",
    "    aux_logits1 = None\n",
    "    inception4b = None\n",
    "    inception4c = None\n",
    "    inception4d = None\n",
    "    aux_logits2 = None\n",
    "    inception4e = None\n",
    "    pool4 = None\n",
    "\n",
    "    inception5a = None\n",
    "    inception5b = None\n",
    "    avg_pool5 = None        \n",
    "    dropout5 = None\n",
    "\n",
    "    flat = None\n",
    "\n",
    "    # classification\n",
    "    fc6 = None\n",
    "    _logits = None\n",
    "\n",
    "    # hypothesis (prediction) of target value y\n",
    "    y_prediction = None\n",
    "    \n",
    "m = ConvModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # reset tensor graph\n",
    "\n",
    "m.x = input_images(height=224, width=224, in_channel=3)\n",
    "m.y = output_labels(out_channel=num_classes)\n",
    "\n",
    "\"\"\"               name     input   filtersize  stride  |filters|  padding \"\"\"\n",
    "m.conv1   = conv('conv1'  , m.x      , 7       , 2     ,   64     , 'SAME')\n",
    "m.pool1   = pool('pool1'  , m.conv1  , 3       , 2     ,            'SAME' )\n",
    "m.lrn1    = lrn('lrn1'    , m.pool1)\n",
    "\n",
    "m.conv2_1 = conv('conv2-1', m.lrn1   , 1       , 1     ,   64     , 'VALID')\n",
    "m.conv2_2 = conv('conv2-2', m.conv2_1, 3       , 1     ,   192    , 'SAME' )\n",
    "m.lrn2    = lrn('lrn2'    , m.conv2_2)\n",
    "m.pool2   = pool('pool2'  , m.lrn2   , 3       , 2     ,            'SAME' )\n",
    "\n",
    "m.inception3a = inception('inception3a', m.pool2      , 64 , 96 , 128, 16 , 32 , 32 )\n",
    "m.inception3b = inception('inception3b', m.inception3a, 128, 128, 192, 32 , 96 , 64 )\n",
    "m.pool3       = pool('pool3', m.inception3b, 3  , 2    ,            'SAME' )\n",
    "\n",
    "m.inception4a = inception('inception4a', m.pool3      , 192, 96 , 208, 16 , 48 , 64 )\n",
    "\n",
    "if is_train:\n",
    "    m.aux_logits1 = auxilliary_classifier(\"aux1\", m.inception4a, 1024, 1000)\n",
    "    \n",
    "m.inception4b = inception('inception4b', m.inception4a, 160, 112, 224, 24 , 64 , 64 )\n",
    "m.inception4c = inception('inception4c', m.inception4b, 128, 128, 256, 24 , 64 , 64 )\n",
    "m.inception4d = inception('inception4d', m.inception4c, 112, 144, 288, 32 , 64 , 64 ) \n",
    "\n",
    "if is_train:\n",
    "    m.aux_logits2 = auxilliary_classifier(\"aux2\", m.inception4d, 1024, 1000)\n",
    "    \n",
    "m.inception4e = inception('inception4e', m.inception4d, 256, 160, 320, 32 , 128, 128)\n",
    "m.pool4       = pool('pool3'  , m.inception4e, 3, 2    ,           'SAME' )\n",
    "        \n",
    "m.inception5a = inception('inception5a', m.pool4      , 256, 160, 320, 32 , 128, 128)\n",
    "m.inception5b = inception('inception5b', m.inception5a, 384, 192, 384, 48 , 128, 128)\n",
    "m.avg_pool5   = avg_pool('avg_pool5'   , m.inception5b, 7   , 1  , 'VALID')        \n",
    "\n",
    "m.dropout5    = dropout('dropout5', m.avg_pool5)\n",
    "        \n",
    "m.flat = flatten('flat', m.dropout5)\n",
    "\n",
    "\"\"\"                 name     input   output_size  \"\"\"\n",
    "m.fc6    = fc(     'fc6'   , m.flat,      1000  )\n",
    "m.logits = fc_last('logits', m.fc6 , num_classes)\n",
    "             \n",
    "m.y_prediction = logits_to_softmax('y_prediction', m.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Inputs / Labels\n",
      "   x           : (?, 224, 224, 3)   input images\n",
      "   y           : (?, 2)             target value (answer label)\n",
      "\n",
      " Feature Extraction\n",
      "   conv1       : (?, 224, 224, 3)  -> (?, 112, 112, 64)\n",
      "   pool1       : (?, 112, 112, 64) -> (?, 56, 56, 64)  \n",
      "   local response normalization\n",
      "   conv2-1     : (?, 56, 56, 64)   -> (?, 56, 56, 64)  \n",
      "   conv2-2     : (?, 56, 56, 64)   -> (?, 56, 56, 192) \n",
      "   local response normalization\n",
      "   pool2       : (?, 56, 56, 192)  -> (?, 28, 28, 192) \n",
      "   inception3a : (?, 28, 28, 192)  -> (?, 28, 28, 256) \n",
      "   inception3b : (?, 28, 28, 256)  -> (?, 28, 28, 480) \n",
      "   pool3       : (?, 28, 28, 480)  -> (?, 14, 14, 480) \n",
      "   inception4a : (?, 14, 14, 480)  -> (?, 14, 14, 512) \n",
      "   aux1_y_pred : (?, 2)   auxilliary classifer, only performed at the train stage\n",
      "   inception4b : (?, 14, 14, 512)  -> (?, 14, 14, 512) \n",
      "   inception4c : (?, 14, 14, 512)  -> (?, 14, 14, 512) \n",
      "   inception4d : (?, 14, 14, 512)  -> (?, 14, 14, 528) \n",
      "   aux2_y_pred : (?, 2)   auxilliary classifer, only performed at the train stage\n",
      "   inception4e : (?, 14, 14, 528)  -> (?, 14, 14, 832) \n",
      "   pool3       : (?, 14, 14, 832)  -> (?, 7, 7, 832)   \n",
      "   inception5a : (?, 7, 7, 832)    -> (?, 7, 7, 832)   \n",
      "   inception5b : (?, 7, 7, 832)    -> (?, 7, 7, 1024)  \n",
      "   avg_pool5   : (?, 7, 7, 1024)   -> (?, 1, 1, 1024)  \n",
      "   dropout5    : (?, 1, 1, 1024)   -> (?, 1, 1, 1024)  \n",
      "   flat        : (?, 1, 1, 1024)   -> (?, 1024)        \n",
      "\n",
      " Classification\n",
      "   fc6         : (?, 1024)         -> (?, 1000)        \n",
      "   logits      : (?, 1000)         -> (?, 2)           \n",
      "\n",
      " Output\n",
      "   y_prediction: (?, 2)  hypothesis (prediction) of target value y\n"
     ]
    }
   ],
   "source": [
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "# Set Model Propagation\n",
    "\n",
    "#### 1. Forward propagation\n",
    "model에 input data 넣어서 model로 구한 y_prediction 값을 구하는 과정\n",
    "\n",
    "#### 2. Loss computation\n",
    "y_prediction 값과 y_true 값을 비교해서 loss (error)를 구하는 과정\n",
    "\n",
    "#### 3. Backpropagation\n",
    "loss 를가지고 model 의 train weight 를 update, optimize 시킴\n",
    "\n",
    "\n",
    "1 > 2 > 3 과정을 반복하며 y_true값과 유사한 결과를 내도록 모델을 학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_propagation = None\n",
    "compute_loss = None\n",
    "back_propagation = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_forward_propagation():\n",
    "    return m.y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_from_logits(labels, logits, weight_decay):\n",
    "    softmax_cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=logits)\n",
    "    softmax_loss = tf.reduce_mean(softmax_cross_entropy)\n",
    "\n",
    "    # L2 regularization loss\n",
    "    # coefficient weight decay = 0.0005 is used at the alexnet paper\n",
    "    L2_weight_decay = weight_decay / 2.0        \n",
    "\n",
    "    # L2 norm for all train parameters\n",
    "    L2_norm = tf.add_n([tf.nn.l2_loss(var) for var in tf.trainable_variables()]) \n",
    "    L2_regularization_loss = L2_norm * L2_weight_decay        \n",
    "\n",
    "    # Add L2 regularization for weight decay\n",
    "    return softmax_loss + L2_regularization_loss\n",
    "\n",
    "def define_loss_function():\n",
    "    aux1_loss = get_loss_from_logits(m.y, m.aux_logits1, 0.0002)\n",
    "    aux2_loss = get_loss_from_logits(m.y, m.aux_logits2, 0.0002)\n",
    "    loss = get_loss_from_logits(m.y, m.logits, weight_decay)\n",
    "\n",
    "    return (loss + aux1_loss * 0.3 + aux2_loss * 0.3) / 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_backward_propagation():    \n",
    "    # Gradient descent optimizer, with Momentum algorithm\n",
    "    # tf.train.Optimizer.minimize Op for a gradient update.\n",
    "    variables_to_update = tf.trainable_variables()\n",
    "    m.current_learning_rate = tf.placeholder(tf.float32)\n",
    "\n",
    "    optimizer = tf.train.MomentumOptimizer(\n",
    "                    m.current_learning_rate,\n",
    "                    momentum,\n",
    "                    use_nesterov=False).minimize(compute_loss, var_list=variables_to_update)\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Softmax:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "forward_propagation = set_forward_propagation()\n",
    "print(forward_propagation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"truediv_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "compute_loss = define_loss_function()\n",
    "print(compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"Momentum_1\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Momentum_1/update_conv1_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_conv1_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_conv2-1_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_conv2-1_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_conv2-2_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_conv2-2_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception3a_conv_1x1_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception3a_conv_1x1_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception3a_conv_3x3_reduce_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception3a_conv_3x3_reduce_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception3a_conv_3x3_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception3a_conv_3x3_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception3a_conv_5x5_reduce_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception3a_conv_5x5_reduce_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception3a_conv_5x5_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception3a_conv_5x5_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception3a_pool_proj_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception3a_pool_proj_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception3b_conv_1x1_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception3b_conv_1x1_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception3b_conv_3x3_reduce_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception3b_conv_3x3_reduce_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception3b_conv_3x3_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception3b_conv_3x3_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception3b_conv_5x5_reduce_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception3b_conv_5x5_reduce_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception3b_conv_5x5_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception3b_conv_5x5_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception3b_pool_proj_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception3b_pool_proj_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4a_conv_1x1_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4a_conv_1x1_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4a_conv_3x3_reduce_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4a_conv_3x3_reduce_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4a_conv_3x3_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4a_conv_3x3_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4a_conv_5x5_reduce_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4a_conv_5x5_reduce_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4a_conv_5x5_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4a_conv_5x5_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4a_pool_proj_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4a_pool_proj_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_aux1_conv_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_aux1_conv_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_aux1_fc1_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_aux1_fc1_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_aux1_fc2_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_aux1_fc2_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_aux1_logits_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_aux1_logits_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4b_conv_1x1_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4b_conv_1x1_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4b_conv_3x3_reduce_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4b_conv_3x3_reduce_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4b_conv_3x3_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4b_conv_3x3_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4b_conv_5x5_reduce_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4b_conv_5x5_reduce_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4b_conv_5x5_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4b_conv_5x5_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4b_pool_proj_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4b_pool_proj_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4c_conv_1x1_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4c_conv_1x1_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4c_conv_3x3_reduce_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4c_conv_3x3_reduce_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4c_conv_3x3_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4c_conv_3x3_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4c_conv_5x5_reduce_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4c_conv_5x5_reduce_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4c_conv_5x5_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4c_conv_5x5_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4c_pool_proj_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4c_pool_proj_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4d_conv_1x1_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4d_conv_1x1_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4d_conv_3x3_reduce_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4d_conv_3x3_reduce_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4d_conv_3x3_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4d_conv_3x3_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4d_conv_5x5_reduce_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4d_conv_5x5_reduce_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4d_conv_5x5_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4d_conv_5x5_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4d_pool_proj_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4d_pool_proj_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_aux2_conv_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_aux2_conv_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_aux2_fc1_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_aux2_fc1_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_aux2_fc2_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_aux2_fc2_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_aux2_logits_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_aux2_logits_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4e_conv_1x1_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4e_conv_1x1_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4e_conv_3x3_reduce_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4e_conv_3x3_reduce_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4e_conv_3x3_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4e_conv_3x3_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4e_conv_5x5_reduce_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4e_conv_5x5_reduce_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4e_conv_5x5_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4e_conv_5x5_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4e_pool_proj_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception4e_pool_proj_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception5a_conv_1x1_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception5a_conv_1x1_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception5a_conv_3x3_reduce_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception5a_conv_3x3_reduce_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception5a_conv_3x3_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception5a_conv_3x3_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception5a_conv_5x5_reduce_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception5a_conv_5x5_reduce_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception5a_conv_5x5_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception5a_conv_5x5_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception5a_pool_proj_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception5a_pool_proj_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception5b_conv_1x1_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception5b_conv_1x1_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception5b_conv_3x3_reduce_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception5b_conv_3x3_reduce_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception5b_conv_3x3_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception5b_conv_3x3_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception5b_conv_5x5_reduce_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception5b_conv_5x5_reduce_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception5b_conv_5x5_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception5b_conv_5x5_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception5b_pool_proj_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_inception5b_pool_proj_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_fc6_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_fc6_biases/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_logits_weights/ApplyMomentum\"\n",
      "input: \"^Momentum_1/update_logits_biases/ApplyMomentum\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "back_propagation = set_backward_propagation()\n",
    "print(back_propagation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "# Run Train\n",
    "\n",
    "#### functions to help batch training/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_train(sess):\n",
    "\n",
    "    for batch_step in range(num_batches_per_epoch):\n",
    "\n",
    "        batch_x, batch_y_true = data_train.next_batch(batch_size)\n",
    "\n",
    "        _y_prediction, _loss, _, = sess.run([\n",
    "                        forward_propagation,\n",
    "                        compute_loss,\n",
    "                        back_propagation],\n",
    "                                feed_dict={\n",
    "                                m.x: batch_x,\n",
    "                                m.y: batch_y_true,\n",
    "                                m.current_learning_rate: current_learning_rate_value})\n",
    "\n",
    "    # after batch train loop, save this epoch's train score\n",
    "    y_true = batch_y_true.argmax(axis=1)\n",
    "    y_pred = _y_prediction.argmax(axis=1)\n",
    "\n",
    "    return _loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_validation(sess):\n",
    "    validation_y_prediction = run_forward_propagation_for_evaluation(sess, data_validation)\n",
    "    \n",
    "    y_true = data_validation.labels.argmax(axis=1)\n",
    "    y_pred = validation_y_prediction.argmax(axis=1)\n",
    "    \n",
    "    validation_score = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    return validation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_forward_propagation_for_evaluation(sess, dataset, augment_type=True):\n",
    "    if dataset.labels is not None:\n",
    "        assert len(dataset.labels.shape) > 1, 'Labels must be one-hot encoded.'\n",
    "\n",
    "    prediction_size = dataset.num_examples\n",
    "    \n",
    "    num_steps = prediction_size // batch_size\n",
    "    last_batch_size = prediction_size % batch_size\n",
    "\n",
    "    # Start prediction loop\n",
    "    y_prediction = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(num_steps+1):\n",
    "        _batch_size = batch_size if i < num_steps else last_batch_size\n",
    "        if _batch_size == 0:\n",
    "            break            \n",
    "\n",
    "        x, _ = dataset.next_batch(_batch_size, shuffle=False)\n",
    "        # if augment_pred == True:  X.shape: (N, 10, h, w, C)\n",
    "        # else:                     X.shape: (N, h, w, C)\n",
    "\n",
    "        if augment_type is True:\n",
    "            y_prediction_patches = np.empty((_batch_size, 10, num_classes),\n",
    "                                      dtype=np.float32)    # (N, 10, num_classes)\n",
    "            # compute predictions for each of 10 patch modes,\n",
    "            for idx in range(10):\n",
    "                y_prediction_patch = sess.run(forward_propagation,\n",
    "                                        feed_dict={m.x: x[:, idx]}) # (N, h, w, C)\n",
    "                y_prediction_patches[:, idx] = y_prediction_patch                   \n",
    "\n",
    "            _y_prediction = y_prediction_patches.mean(axis=1)    # (N, num_classes)\n",
    "\n",
    "        else:\n",
    "            # Compute predictions\n",
    "            _y_prediction = sess.run(tr1_forward_propagation,\n",
    "                              feed_dict={m.x: x})    # (N, num_classes)\n",
    "\n",
    "        y_prediction.append(_y_prediction)\n",
    "\n",
    "    y_prediction = np.concatenate(y_prediction, axis=0)    # (N, num_classes)\n",
    "\n",
    "    return y_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "base_path = 'trained_model_result/'  # result saving location\n",
    "\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)\n",
    "    os.chown(base_path, uid=1000, gid=1000)\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_path = os.path.join(base_path, timestamp + '/')\n",
    "\n",
    "os.makedirs(output_path)\n",
    "os.chown(output_path, uid=1000, gid=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------------------\n",
      " execute train\n",
      "------------------------------------------------------------------------\n",
      "  train data size       :         13\n",
      "  batch size            :         13\n",
      "  batche loop per epoch :          1 = |train data| 13 / |batch| 13\n",
      "  epoches               :        300\n",
      "  total iterations      :        300 = |batch loop| 1 * |epoch| 300\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_epochs = 0\n",
    "best_score = 0.0\n",
    "current_learning_rate_value = init_learning_rate\n",
    "\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(graph=graph, config=config)        \n",
    "sess.run(tf.global_variables_initializer())    # initialize all weights\n",
    "\n",
    "saver = tf.train.Saver()  # to save trained model\n",
    "output_model_path = os.path.join(output_path, 'model.ckpt')\n",
    "\n",
    "train_results = dict()    # dictionary to contain training(, evaluation) results and details\n",
    "total_steps = num_epochs * num_batches_per_epoch\n",
    "\n",
    "str = '\\n------------------------------------------------------------------------' + \\\n",
    "    '\\n execute train' + \\\n",
    "    '\\n------------------------------------------------------------------------' + \\\n",
    "    '\\n  train data size       : {:10}'.format(data_train.num_examples) + \\\n",
    "    '\\n  batch size            : {:10}'.format(batch_size) + \\\n",
    "    '\\n  batche loop per epoch : {:10} = |train data| {} / |batch| {}'.format(num_batches_per_epoch, data_train.num_examples, batch_size) + \\\n",
    "    '\\n  epoches               : {:10}'.format(num_epochs) + \\\n",
    "    '\\n  total iterations      : {:10} = |batch loop| {} * |epoch| {}\\n\\n'.format(total_steps, num_batches_per_epoch, num_epochs)\n",
    "\n",
    "print(str)\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_better(current_score, best_score):\n",
    "    score_threshold = 1e-4\n",
    "    relative_eps = 1.0 + score_threshold\n",
    "    return current_score > best_score * relative_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_learning_rate():\n",
    "    # decaying learning rate (epsilon)\n",
    "    global bad_epochs\n",
    "    global current_learning_rate_value\n",
    "\n",
    "    if bad_epochs > patience_of_no_improvement_epochs:            \n",
    "        new_learning_rate = current_learning_rate_value * learning_rate_decay\n",
    "        \n",
    "        # Decay learning rate only when the difference is higher than lower bound epsilon.\n",
    "        if current_learning_rate_value - new_learning_rate > lower_bound_learning_rate:\n",
    "            current_learning_rate_value = new_learning_rate\n",
    "        \n",
    "        bad_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch   0] loss: 2.184828 | validation score: 0.333333 | learning rate: 0.000000\n",
      "   exit train: learning rate is too small (< 0.000001)\n"
     ]
    }
   ],
   "source": [
    "# start training loop\n",
    "for epoch_step in range(num_epochs):\n",
    "    # perform a gradient update of the current epoch\n",
    "    current_loss = execute_train(sess)       \n",
    "    current_score = execute_validation(sess)\n",
    "\n",
    "    str = '[epoch{:4}] loss: {:.6f} | validation score: {:.6f} | learning rate: {:.6f}'\\\n",
    "                    .format(epoch_step, current_loss, current_score, current_learning_rate_value)\n",
    "    print(str)\n",
    "\n",
    "    # Keep track of the current best model,\n",
    "    if is_better(current_score, best_score):\n",
    "        best_score = current_score\n",
    "        bad_epochs = 0\n",
    "\n",
    "        saver.save(sess, output_model_path)  # save current weights\n",
    "    else:\n",
    "        bad_epochs += 1\n",
    "        \n",
    "    update_learning_rate()\n",
    "    if current_learning_rate_value < 0.000001:\n",
    "        print('   exit train: learning rate is too small (< 0.000001)')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_test(sess):\n",
    "\n",
    "    test_y_prediction = run_forward_propagation_for_evaluation(sess, data_test)\n",
    "   \n",
    "    y_true = data_test.labels.argmax(axis=1)\n",
    "    y_pred = test_y_prediction.argmax(axis=1)\n",
    "\n",
    "    test_score = accuracy_score(y_true, y_pred)\n",
    "    return test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Reading test data..\n",
      "     progress: 0/10...\r",
      "     progress: 10/10...\r\n",
      " Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = read_test_data_sets('../test_data/asirra_smaller/', image_reshape_size=224)\n",
    "data_test = data.test\n",
    "num_classes = len(data_test.labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from trained_model_result/20190712_064712/model.ckpt\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "execute test\n",
      "------------------------------------------------------------------------\n",
      "  test data size       :         10\n",
      "  batch size           :         13\n"
     ]
    }
   ],
   "source": [
    "graph = tf.get_default_graph()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(graph=graph, config=config)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, output_model_path) \n",
    "\n",
    "str = '\\n------------------------------------------------------------------------' + \\\n",
    "    '\\nexecute test' + \\\n",
    "    '\\n------------------------------------------------------------------------' + \\\n",
    "    '\\n  test data size       : {:10}'.format(data_test.num_examples) + \\\n",
    "    '\\n  batch size           : {:10}'.format(batch_size) \n",
    "\n",
    "print(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = execute_test(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Test finished.\n",
      "------------------------------------------------------------------------\n",
      "\n",
      " Test score (accuracy) : 0.3\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    " str = '\\n\\n\\n------------------------------------------------------------------------' + \\\n",
    "    '\\nTest finished.' + \\\n",
    "    '\\n------------------------------------------------------------------------' + \\\n",
    "    '\\n\\n Test score (accuracy) : {}'.format(test_score) + \\\n",
    "    '\\n------------------------------------------------------------------------\\n\\n'\n",
    "\n",
    "print(str)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
