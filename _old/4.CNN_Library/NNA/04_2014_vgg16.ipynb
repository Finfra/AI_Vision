{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from tensorflow.contrib.learn.python.learn.datasets import base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from tensorflow.contrib.learn.python.learn.datasets import base\n",
    "\n",
    "\n",
    "class DataSet(object):\n",
    "    def __init__(self, data_type, images, image_reshape_size=224, labels=None):\n",
    "        \"\"\"\n",
    "        Construct a new DataSet object.\n",
    "        :param images: np.ndarray, shape: (N, H, W, C).\n",
    "        :param labels: np.ndarray, shape: (N, num_classes) or (N,).\n",
    "        \"\"\"\n",
    "        if labels is not None:\n",
    "            assert images.shape[0] == labels.shape[0], (\n",
    "                'Number of examples mismatch, between images and labels.'\n",
    "            )\n",
    "        self._num_examples = images.shape[0]\n",
    "        self._data_type = data_type\n",
    "        self._images = images\n",
    "        self._labels = labels    # NOTE: this can be None, if not given.\n",
    "        self._indices = np.arange(self._num_examples, dtype=np.uint)    # image/label indices(can be permuted)\n",
    "        self._augment = True\n",
    "        self._image_reshape_size = image_reshape_size\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self):\n",
    "        \"\"\"Reset some variables.\"\"\"\n",
    "        self._completed_epoch_count = 0\n",
    "        self._idx_in_current_epoch = 0\n",
    "        \n",
    "    def set_augment(self, augment):\n",
    "        self._augment = augment\n",
    "\n",
    "    @property\n",
    "    def images(self):\n",
    "        return self._images\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "\n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "\n",
    "    def next_batch(self, batch_size, shuffle=True, fake_data=False):\n",
    "        \"\"\"\n",
    "        Return the next `batch_size` examples from this dataset.\n",
    "        :param batch_size: int, size of a single batch.\n",
    "        :param shuffle: bool, whether to shuffle the whole set while sampling a batch.\n",
    "        :param augment: bool, whether to perform data augmentation while sampling a batch.\n",
    "        :param is_train: bool, current phase for sampling.\n",
    "        :param fake_data: bool, whether to generate fake data (for debugging).\n",
    "        :return: batch_images: np.ndarray, shape: (N, h, w, C) or (N, 10, h, w, C).\n",
    "                 batch_labels: np.ndarray, shape: (N, num_classes) or (N,).\n",
    "        \"\"\"\n",
    "        if fake_data:\n",
    "            fake_batch_images = np.random.random(size=(batch_size, self._image_reshape_size, self._image_reshape_size, 3))\n",
    "            fake_batch_labels = np.zeros((batch_size, 2), dtype=np.uint8)\n",
    "            fake_batch_labels[np.arange(batch_size), np.random.randint(2, size=batch_size)] = 1\n",
    "            return fake_batch_images, fake_batch_labels\n",
    "\n",
    "        idx_begin = self._idx_in_current_epoch\n",
    "\n",
    "        # Shuffle the dataset, for the first epoch\n",
    "        if self._completed_epoch_count == 0 and idx_begin == 0 and shuffle:\n",
    "            np.random.shuffle(self._indices)\n",
    "\n",
    "        # Go to the next epoch, if current index goes beyond the total number of examples\n",
    "        if idx_begin + batch_size > self._num_examples:\n",
    "            # Increment the number of epochs completed\n",
    "            self._completed_epoch_count += 1\n",
    "            \n",
    "            # Get the rest examples in this epoch\n",
    "            remaining_num_examples = self._num_examples - idx_begin\n",
    "            remaining_indices = self._indices[idx_begin:self._num_examples]\n",
    "\n",
    "            # Shuffle the dataset, after finishing a single epoch\n",
    "            if shuffle:\n",
    "                np.random.shuffle(self._indices)\n",
    "\n",
    "            # Start the next epoch\n",
    "            idx_begin = 0\n",
    "            self._idx_in_current_epoch = batch_size - remaining_num_examples\n",
    "            idx_end = self._idx_in_current_epoch\n",
    "            new_indices = self._indices[idx_begin:idx_end]\n",
    "\n",
    "            remaining_images = self.images[remaining_indices]\n",
    "            new_images = self.images[new_indices]\n",
    "            batch_images = np.concatenate((remaining_images, new_images), axis=0)\n",
    "            if self.labels is not None:\n",
    "                remaining_labels = self.labels[remaining_indices]\n",
    "                new_labels = self.labels[new_indices]\n",
    "                batch_labels = np.concatenate((remaining_labels, new_labels), axis=0)\n",
    "            else:\n",
    "                print('nono1')\n",
    "                batch_labels = None\n",
    "        else:\n",
    "            self._idx_in_current_epoch += batch_size\n",
    "            idx_end = self._idx_in_current_epoch\n",
    "            indices = self._indices[idx_begin:idx_end]\n",
    "            batch_images = self.images[indices]\n",
    "            if self.labels is not None:\n",
    "                batch_labels = self.labels[indices]\n",
    "            else:\n",
    "                batch_labels = None\n",
    "\n",
    "        if self._augment and self._data_type == 'train':\n",
    "            # Perform data augmentation, for training phase\n",
    "            batch_images = random_crop_reflect(batch_images, self._image_reshape_size)\n",
    "        elif self._augment and self._data_type != 'train':\n",
    "            # Perform data augmentation, for evaluation phase(10x)\n",
    "            batch_images = corner_center_crop_reflect(batch_images, self._image_reshape_size)\n",
    "        else:\n",
    "            # Don't perform data augmentation, generating center-cropped patches\n",
    "            batch_images = center_crop(batch_images, self._image_reshape_size)\n",
    "        \n",
    "        return batch_images, batch_labels\n",
    "\n",
    "\n",
    "def random_crop_reflect(images, crop_l):\n",
    "    \"\"\"\n",
    "    Perform random cropping and reflection from images.\n",
    "    :param images: np.ndarray, shape: (N, H, W, C).\n",
    "    :param crop_l: int, a side length of crop region.\n",
    "    :return: np.ndarray, shape: (N, h, w, C).\n",
    "    \"\"\"\n",
    "    H, W = images.shape[1:3]\n",
    "    augmented_images = []\n",
    "    for image in images:    # image.shape: (H, W, C)\n",
    "            \n",
    "        # Randomly crop patch\n",
    "        y = np.random.randint(H-crop_l)\n",
    "        x = np.random.randint(W-crop_l)\n",
    "        image = image[y:y+crop_l, x:x+crop_l]    # (h, w, C)\n",
    "\n",
    "        # Randomly reflect patch horizontally\n",
    "        reflect = bool(np.random.randint(2))\n",
    "        if reflect:\n",
    "            image = image[:, ::-1]\n",
    "\n",
    "        augmented_images.append(image)\n",
    "    return np.stack(augmented_images)    # shape: (N, h, w, C)\n",
    "\n",
    "\n",
    "def corner_center_crop_reflect(images, crop_l):\n",
    "    \"\"\"\n",
    "    Perform 4 corners and center cropping and reflection from images,\n",
    "    resulting in 10x augmented patches.\n",
    "    :param images: np.ndarray, shape: (N, H, W, C).\n",
    "    :param crop_l: int, a side length of crop region.\n",
    "    :return: np.ndarray, shape: (N, 10, h, w, C).\n",
    "    \"\"\"\n",
    "    H, W = images.shape[1:3]\n",
    "    augmented_images = []\n",
    "    for image in images:    # image.shape: (H, W, C)\n",
    "        aug_image_orig = []\n",
    "        # Crop image in 4 corners\n",
    "        aug_image_orig.append(image[:crop_l, :crop_l])\n",
    "        aug_image_orig.append(image[:crop_l, -crop_l:])\n",
    "        aug_image_orig.append(image[-crop_l:, :crop_l])\n",
    "        aug_image_orig.append(image[-crop_l:, -crop_l:])\n",
    "        # Crop image in the center\n",
    "        aug_image_orig.append(image[H//2-(crop_l//2):H//2+(crop_l-crop_l//2),\n",
    "                                    W//2-(crop_l//2):W//2+(crop_l-crop_l//2)])\n",
    "        aug_image_orig = np.stack(aug_image_orig)    # (5, h, w, C)\n",
    "\n",
    "        # Flip augmented images and add it\n",
    "        aug_image_flipped = aug_image_orig[:, :, ::-1]    # (5, h, w, C)\n",
    "        aug_image = np.concatenate((aug_image_orig, aug_image_flipped), axis=0)    # (10, h, w, C)\n",
    "        augmented_images.append(aug_image)\n",
    "    return np.stack(augmented_images)    # shape: (N, 10, h, w, C)\n",
    "\n",
    "\n",
    "def center_crop(images, crop_l):\n",
    "    \"\"\"\n",
    "    Perform center cropping of images.\n",
    "    :param images: np.ndarray, shape: (N, H, W, C).\n",
    "    :param crop_l: int, a side length of crop region.\n",
    "    :return: np.ndarray, shape: (N, h, w, C).\n",
    "    \"\"\"\n",
    "    H, W = images.shape[1:3]\n",
    "    cropped_images = []\n",
    "    for image in images:    # image.shape: (H, W, C)\n",
    "        # Crop image in the center\n",
    "        cropped_images.append(image[H//2-(crop_l//2):H//2+(crop_l-crop_l//2),\n",
    "                              W//2-(crop_l//2):W//2+(crop_l-crop_l//2)])\n",
    "    return np.stack(cropped_images)\n",
    "\n",
    "\n",
    "def read_asirra_subset(subset_dir, one_hot=True, sample_size=None):\n",
    "    \"\"\"\n",
    "    Load the Asirra Dogs vs. Cats data subset from disk\n",
    "    and perform preprocessing for training AlexNet.\n",
    "    :param subset_dir: str, path to the directory to read.\n",
    "    :param one_hot: bool, whether to return one-hot encoded labels.\n",
    "    :param sample_size: int, sample size specified when we are not using the entire set.\n",
    "    :return: X_set: np.ndarray, shape: (N, H, W, C).\n",
    "             y_set: np.ndarray, shape: (N, num_channels) or (N,).\n",
    "    \"\"\"\n",
    "    # Read trainval data\n",
    "    filename_list = os.listdir(subset_dir)\n",
    "    set_size = len(filename_list)\n",
    "\n",
    "    if sample_size is not None and sample_size < set_size:\n",
    "        # Randomly sample subset of data when sample_size is specified\n",
    "        filename_list = np.random.choice(filename_list, size=sample_size, replace=False)\n",
    "        set_size = sample_size\n",
    "    else:\n",
    "        # Just shuffle the filename list\n",
    "        np.random.shuffle(filename_list)\n",
    "\n",
    "    # Pre-allocate data arrays\n",
    "    msg_interval = 1000 if set_size >= 1000 else 10\n",
    "    \n",
    "    X_set = np.empty((set_size, 256, 256, 3), dtype=np.float32)    # (N, H, W, 3)\n",
    "    y_set = np.empty((set_size), dtype=np.uint8)                   # (N,)\n",
    "    for i, filename in enumerate(filename_list):\n",
    "        if i % msg_interval == 0:\n",
    "            print('     progress: {}/{}...'.format(i, set_size), end='\\r')\n",
    "        label = filename.split('.')[0]\n",
    "        if label == 'cat':\n",
    "            y = 0\n",
    "        else:  # label == 'dog'\n",
    "            y = 1\n",
    "        file_path = os.path.join(subset_dir, filename)\n",
    "        img = imread(file_path)    # shape: (H, W, 3), range: [0, 255]\n",
    "        img = resize(img, (256, 256), mode='constant').astype(np.float32)    # (256, 256, 3), [0.0, 1.0]\n",
    "        X_set[i] = img\n",
    "        y_set[i] = y\n",
    "\n",
    "    if one_hot:\n",
    "        # Convert labels to one-hot vectors, shape: (N, num_classes)\n",
    "        y_set_oh = np.zeros((set_size, 2), dtype=np.uint8)\n",
    "        y_set_oh[np.arange(set_size), y_set] = 1\n",
    "        y_set = y_set_oh\n",
    "        \n",
    "    print('     progress: {}/{}...'.format(set_size, set_size), end='\\r')\n",
    "    print('\\n Done\\n')\n",
    "\n",
    "    return X_set, y_set, set_size\n",
    "\n",
    "\n",
    "def read_train_data_sets(subset_dir, image_reshape_size=227, one_hot=True, sample_train_size=None):\n",
    "    print(\" Reading train/validation data\")\n",
    "    train_images, train_labels, set_size = read_asirra_subset(subset_dir + 'train', one_hot, sample_train_size) \n",
    "    validation_size = int(set_size * 0.2)\n",
    "    \n",
    "    validation_images = train_images[:validation_size]\n",
    "    validation_labels = train_labels[:validation_size]\n",
    "    train_images = train_images[validation_size:]\n",
    "    train_labels = train_labels[validation_size:]\n",
    "\n",
    "    train = DataSet('train', train_images, image_reshape_size, train_labels)\n",
    "    validation = DataSet('validation', validation_images, image_reshape_size, validation_labels)\n",
    "    \n",
    "    return base.Datasets(train=train, validation=validation, test=None)\n",
    "\n",
    "\n",
    "def read_test_data_sets(subset_dir, image_reshape_size=227, one_hot=True, sample_train_size=None):\n",
    "    print(\"\\n Reading test data..\")\n",
    "    test_images, test_labels, _ = read_asirra_subset(subset_dir + 'test', one_hot) \n",
    "\n",
    "    test = DataSet('test', test_images, image_reshape_size, test_labels)    \n",
    "    \n",
    "    return base.Datasets(train=None, validation=None, test=test)\n",
    "    \n",
    "        \n",
    "def read_data_sets(subset_dir, image_reshape_size=227, one_hot=True, sample_train_size=None):\n",
    "    print(\" Reading train/validation data\")\n",
    "    train_images, train_labels, set_size = read_asirra_subset(subset_dir + 'train', one_hot, sample_train_size) \n",
    "    validation_size = int(set_size * 0.2)\n",
    "    \n",
    "    validation_images = train_images[:validation_size]\n",
    "    validation_labels = train_labels[:validation_size]\n",
    "    train_images = train_images[validation_size:]\n",
    "    train_labels = train_labels[validation_size:]\n",
    "\n",
    "    print(\"\\n Reading test data..\")\n",
    "    test_images, test_labels, _ = read_asirra_subset(subset_dir + 'test', one_hot) \n",
    "\n",
    "    train = DataSet('train', train_images, image_reshape_size, train_labels)\n",
    "    validation = DataSet('validation', validation_images, image_reshape_size, validation_labels)\n",
    "    test = DataSet('test', test_images, image_reshape_size, test_labels)    \n",
    "    \n",
    "    return base.Datasets(train=train, validation=validation, test=test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_train = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Reading train/validation data\n",
      "     progress: 16/16...\n",
      " Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = read_train_data_sets('./asirra_smaller/', image_reshape_size=224)\n",
    "data_train = data.train\n",
    "data_validation = data.validation\n",
    "\n",
    "num_classes = len(data_train.labels[0])  # cat, dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape   : (13, 256, 256, 3)\n",
      "ConvNet Input Image Shape   : (2, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Image Shape   : {0}\".format(data_train.images.shape))\n",
    "sample_input_x, sample_input_y = data_train.next_batch(2)\n",
    "print(\"ConvNet Input Image Shape   : {0}\".format(sample_input_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train batch\n",
    "batch_size = 256\n",
    "batch_size = batch_size \\\n",
    "                if batch_size <= data_train.num_examples \\\n",
    "                else data_train.num_examples\n",
    "\n",
    "num_epochs = 300  # deep network라서 많이 돌려야 됨\n",
    "num_batches_per_epoch = data_train.num_examples // batch_size   # 10 // 3 = 3\n",
    "\n",
    "\n",
    "# L2 regularization (weight decay)\n",
    "# Used at: comput loss\n",
    "weight_decay = 0.0005\n",
    "\n",
    "# dropout regularization: \n",
    "# Used at: fc layers\n",
    "train_dropout_rate = 0.4\n",
    "\n",
    "\n",
    "# adding momentum (to avoid local minima)\n",
    "# Used at: tf.train.MomentumOptimizer\n",
    "momentum = 0.9\n",
    "\n",
    "# update learning rate (epsilon)\n",
    "# Used at: update_learning_rate\n",
    "init_learning_rate = 0.01\n",
    "patience_of_no_improvement_epochs = 30\n",
    "learning_rate_decay = 0.1\n",
    "lower_bound_learning_rate = 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "# Build VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = ''  # log printing variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### layer building functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_images(height, width, in_channel):\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, [None, height, width, in_channel])\n",
    "    \n",
    "    global info\n",
    "    info = ' Inputs / Labels'\n",
    "    info += '\\n   {:12s}: {:17s}  {}'.format('x', str(x.shape), 'input images')\n",
    "    return x\n",
    "\n",
    "def output_labels(out_channel):\n",
    "    y = tf.placeholder(tf.float32, [None, out_channel])\n",
    "    global info\n",
    "    info += '\\n   {:12s}: {:17s}  {}\\n\\n Feature Extraction'.format('y', str(y.shape), 'target value (answer label)')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(name, inputs, filter_size, stride, num_filters, padding='SAME', is_print=True):\n",
    "\n",
    "    bias=0.0\n",
    "    \n",
    "    in_channel = int(inputs.get_shape()[-1])\n",
    "    out_channel = num_filters\n",
    "\n",
    "    weights = tf.get_variable(name=name + '_weights',\n",
    "                shape=[filter_size, filter_size, in_channel, out_channel],\n",
    "                initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    biases = tf.get_variable(name + '_biases',\n",
    "                [out_channel], tf.float32,\n",
    "                tf.constant_initializer(value=bias))\n",
    "\n",
    "    conv = tf.nn.conv2d(inputs, weights, \n",
    "                strides=[1, stride, stride, 1],\n",
    "                padding=padding) + bias\n",
    "\n",
    "    conv = tf.nn.relu(conv)  # activation (non-linearizing)\n",
    "\n",
    "    if is_print:\n",
    "        global info\n",
    "        # skip if this is an inception layer's sub layer\n",
    "        info += '\\n   {:12s}: {:17s} -> {:17s}'.format(\n",
    "                        name,  str(inputs.shape), str(conv.shape) )        \n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool(name, inputs, filter_size, stride, padding='VALID', is_print=True):\n",
    "    pool = tf.nn.max_pool(inputs, \n",
    "               ksize = [1, filter_size, filter_size, 1],\n",
    "               strides = [1,stride,stride,1], padding=padding)\n",
    "\n",
    "    if is_print:\n",
    "        global info\n",
    "        # skip if this is an inception layer's sub layer\n",
    "        info += '\\n   {:12s}: {:17s} -> {:17s}'.format(\n",
    "                        name,  str(inputs.shape), str(pool.shape) )\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_pool(name, inputs, filter_size, stride, padding='VALID', is_print=True):\n",
    "    avg_pool = tf.nn.avg_pool(inputs, \n",
    "               ksize = [1, filter_size, filter_size, 1],\n",
    "               strides = [1,stride,stride,1], padding=padding)\n",
    "\n",
    "    if is_print:\n",
    "        global info\n",
    "        # skip if this is an inception layer's sub layer\n",
    "        info += '\\n   {:12s}: {:17s} -> {:17s}'.format(\n",
    "                        name,  str(inputs.shape), str(avg_pool.shape) )\n",
    "    return avg_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def lrn(name, inputs, depth_radius=5, alpha=0.0001, beta=0.75):\n",
    "#    #  LRN (local response normalization) layer\n",
    "#    global info\n",
    "#    info += '\\n   local response normalization'\n",
    "#    return tf.nn.local_response_normalization(name=name, \n",
    "#                    input=inputs, depth_radius=depth_radius, alpha=alpha, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def inception(name, inputs, conv_1x1_out, conv_3x3_reduce_out, conv_3x3_out, conv_5x5_reduce_out, conv_5x5_out, pool_proj_out):\n",
    "    conv_1x1        = conv(name + '_conv_1x1',\n",
    "                           inputs         , 1      , 1     ,   conv_1x1_out       , 'SAME', False)\n",
    "    conv_3x3_reduce = conv(name + '_conv_3x3_reduce',\n",
    "                           inputs         , 1      , 1     ,   conv_3x3_reduce_out, 'SAME', False)\n",
    "    conv_3x3        = conv(name + '_conv_3x3',\n",
    "                           conv_3x3_reduce, 3      , 1     ,   conv_3x3_out       , 'SAME', False)        \n",
    "    conv_5x5_reduce = conv(name + '_conv_5x5_reduce',\n",
    "                           inputs         , 1      , 1     ,   conv_5x5_reduce_out, 'SAME', False)        \n",
    "    conv_5x5        = conv(name + '_conv_5x5',\n",
    "                           conv_5x5_reduce, 5      , 1     ,   conv_5x5_out       , 'SAME', False)        \n",
    "    _pool           = pool(name + 'max_pool_3x3',\n",
    "                           inputs         , 3      , 1     ,   'SAME', False)        \n",
    "    pool_proj       = conv(name + '_pool_proj',\n",
    "                           _pool          , 1      , 1     ,   pool_proj_out      , 'SAME', False)\n",
    "    inception       = tf.concat([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3)\n",
    "    \n",
    "    global info\n",
    "    info += '\\n   {:12s}: {:17s} -> {:17s}'.format(\n",
    "                    name, str(inputs.shape), str(inception.shape))\n",
    "    return inception\n",
    "\"\"\"\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def auxilliary_classifier(name, inputs, aux_fc1_out, aux_fc2_out):\n",
    "    train_dropout_rate = 0.7  # auxilliary classifier 할 때만 잠시 global hyperparameter 값 바꿈\n",
    "    aux_avg_pool = avg_pool(name + '_avg_pool'       , inputs       , 5     , 3   ,            'VALID', False)   \n",
    "    aux_conv     = conv(name + '_conv'               , aux_avg_pool , 1     , 1   ,   128  ,   'SAME' , False)\n",
    "    aux_flat     = tf.contrib.layers.flatten(aux_conv)\n",
    "    aux_fc1      = fc(name + '_fc1'   , aux_flat,      aux_fc1_out     , False)\n",
    "    aux_fc2      = fc(name + '_fc2'   , aux_fc1 ,      aux_fc2_out     , False)\n",
    "    aux_logits   = fc_last(name + '_logits', aux_fc2 , num_classes, False)\n",
    "\n",
    "    global info\n",
    "    info += '\\n   {:12s}: {:8s} auxilliary classifer, only performed at the train stage'.format(name + '_y_pred', str(aux_logits.shape))\n",
    "\n",
    "    train_dropout_rate = 0.4  # 원래 값 복원\n",
    "    return aux_logits\n",
    "\"\"\"\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(name, inputs):\n",
    "    flattened = tf.contrib.layers.flatten(inputs)\n",
    "\n",
    "    global info\n",
    "    info += '\\n   {:12s}: {:17s} -> {:17s}\\n\\n Classification'.format(\n",
    "                    name, str(inputs.shape), str(flattened.shape) )\n",
    "    return flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(name, inputs):\n",
    "    # The probability of keeping each unit for dropout layers\n",
    "    keep_prob_value = tf.cond(tf.cast(is_train, tf.bool),\n",
    "                              lambda: train_dropout_rate,\n",
    "                              lambda: 1.0)\n",
    "\n",
    "    dropout = tf.nn.dropout(inputs, keep_prob=keep_prob_value)\n",
    "    global info\n",
    "    info += '\\n   {:12s}: {:17s} -> {:17s}'.format(\n",
    "                    name,  str(inputs.shape), str(dropout.shape) )\n",
    "    return dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc(name, inputs, output_size, is_print=True):\n",
    "    bias=0.1\n",
    "    in_dim = int(inputs.get_shape()[-1])\n",
    "    out_dim = output_size\n",
    "\n",
    "    weights = tf.get_variable(name=name + '_weights',\n",
    "                shape=[in_dim, out_dim],\n",
    "                initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    biases = tf.get_variable(name + '_biases',\n",
    "                [out_dim], tf.float32,\n",
    "                tf.constant_initializer(value=bias))\n",
    "\n",
    "    fc = tf.matmul(inputs, weights) + biases\n",
    "    fc = tf.nn.relu(fc)  # activation\n",
    "\n",
    "    # The probability of keeping each unit for dropout layers\n",
    "    keep_prob_value = tf.cond(tf.cast(is_train, tf.bool),\n",
    "                              lambda: train_dropout_rate,\n",
    "                              lambda: 1.0)\n",
    "\n",
    "    fc = tf.nn.dropout(fc, keep_prob=keep_prob_value)\n",
    "\n",
    "    if is_print:\n",
    "        global info\n",
    "        info += '\\n   {:12s}: {:17s} -> {:17s}'.format(\n",
    "                       name,  str(inputs.shape), str(fc.shape) )        \n",
    "    return fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_last(name, inputs, output_size, is_print=True):\n",
    "    bias=0.0 \n",
    "    in_dim = int(inputs.get_shape()[-1])\n",
    "    out_dim = output_size\n",
    "\n",
    "    weights = tf.get_variable(name=name + '_weights',\n",
    "                shape=[in_dim, out_dim],\n",
    "                initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    biases = tf.get_variable(name + '_biases',\n",
    "                [out_dim], tf.float32,\n",
    "                tf.constant_initializer(value=bias))\n",
    "\n",
    "    logits = tf.matmul(inputs, weights) + biases\n",
    "\n",
    "    if is_print:\n",
    "        global info\n",
    "        info += '\\n   {:12s}: {:17s} -> {:17s}'.format(\n",
    "                        name,  str(inputs.shape), str(logits.shape) )        \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_softmax(name, inputs):\n",
    "    # hypothesis (prediction) of target value y\n",
    "    y_hat = tf.nn.softmax(inputs)  \n",
    "    \n",
    "    global info\n",
    "    info += '\\n\\n Output\\n   {:12s}: {:8s}hypothesis (prediction) of target value y'.format(name, str(y_hat.shape))\n",
    "\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### network layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModel:\n",
    "    # input\n",
    "    x = None\n",
    "    y = None\n",
    "\n",
    "    # feature extraction\n",
    "    conv1 = None\n",
    "    conv2 = None\n",
    "    pool2 = None\n",
    "\n",
    "    conv3 = None\n",
    "    conv4 = None\n",
    "    pool4 = None\n",
    "\n",
    "    conv5 = None\n",
    "    conv6 = None\n",
    "    conv7 = None\n",
    "    pool7 = None\n",
    "\n",
    "    conv8 = None\n",
    "    conv9 = None\n",
    "    conv10 = None\n",
    "    pool10 = None\n",
    "\n",
    "    conv11 = None\n",
    "    conv12 = None\n",
    "    conv13 = None\n",
    "    pool13 = None\n",
    "\n",
    "    flat = None\n",
    "\n",
    "    # classification\n",
    "    fc14 = None\n",
    "    fc15 = None\n",
    "    logits = None\n",
    "\n",
    "    # hypothesis (prediction) of target value y\n",
    "    y_prediction = None\n",
    "    \n",
    "m = ConvModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # reset tensor graph\n",
    "\n",
    "m.x = input_images(height=224, width=224, in_channel=3)\n",
    "m.y = output_labels(out_channel=num_classes)\n",
    "\n",
    "\"\"\"               name     input   filtersize  stride  |filters|  \"\"\"\n",
    "m.conv1  = conv('conv1' , m.x     , 3, 1, 64 )\n",
    "m.conv2  = conv('conv2' , m.conv1 , 3, 1, 64 )\n",
    "m.pool2  = pool('pool2' , m.conv2 , 2, 2)\n",
    "\n",
    "m.conv3  = conv('conv3' , m.pool2 , 3, 1, 128)\n",
    "m.conv4  = conv('conv4' , m.conv3 , 3, 1, 128)\n",
    "m.pool4  = pool('pool4' , m.conv4 , 2, 2)\n",
    "\n",
    "m.conv5  = conv('conv5' , m.pool4 , 3, 1, 256)\n",
    "m.conv6  = conv('conv6' , m.conv5 , 3, 1, 256)\n",
    "m.conv7  = conv('conv7' , m.conv6 , 3, 1, 256)\n",
    "m.pool7  = pool('pool7' , m.conv7 , 2, 2)\n",
    "\n",
    "m.conv8  = conv('conv8' , m.pool7 , 3, 1, 512)\n",
    "m.conv9  = conv('conv9' , m.conv8 , 3, 1, 512)\n",
    "m.conv10 = conv('conv10', m.conv9 , 3, 1, 512)\n",
    "m.pool10 = pool('pool10', m.conv10, 2, 2)\n",
    "\n",
    "m.conv11 = conv('conv11', m.pool10, 3, 1, 512)\n",
    "m.conv12 = conv('conv12', m.conv11, 3, 1, 512)\n",
    "m.conv13 = conv('conv13', m.conv12, 3, 1, 512)\n",
    "m.pool13 = pool('pool13', m.conv13, 2, 2)\n",
    "\n",
    "m.flat = flatten('flat', m.pool13)\n",
    "\n",
    "\"\"\"                    name     input     output_size    \"\"\"\n",
    "m.fc14   = fc(     'fc14'  , m.flat,      4096      )\n",
    "m.fc15   = fc(     'fc15'  , m.fc14,      4096      )\n",
    "m.logits = fc_last('logits', m.fc15, num_classes)\n",
    "\n",
    "m.y_prediction = logits_to_softmax('y_prediction', m.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Inputs / Labels\n",
      "   x           : (?, 224, 224, 3)   input images\n",
      "   y           : (?, 2)             target value (answer label)\n",
      "\n",
      " Feature Extraction\n",
      "   conv1       : (?, 224, 224, 3)  -> (?, 224, 224, 64)\n",
      "   conv2       : (?, 224, 224, 64) -> (?, 224, 224, 64)\n",
      "   pool2       : (?, 224, 224, 64) -> (?, 112, 112, 64)\n",
      "   conv3       : (?, 112, 112, 64) -> (?, 112, 112, 128)\n",
      "   conv4       : (?, 112, 112, 128) -> (?, 112, 112, 128)\n",
      "   pool4       : (?, 112, 112, 128) -> (?, 56, 56, 128) \n",
      "   conv5       : (?, 56, 56, 128)  -> (?, 56, 56, 256) \n",
      "   conv6       : (?, 56, 56, 256)  -> (?, 56, 56, 256) \n",
      "   conv7       : (?, 56, 56, 256)  -> (?, 56, 56, 256) \n",
      "   pool7       : (?, 56, 56, 256)  -> (?, 28, 28, 256) \n",
      "   conv8       : (?, 28, 28, 256)  -> (?, 28, 28, 512) \n",
      "   conv9       : (?, 28, 28, 512)  -> (?, 28, 28, 512) \n",
      "   conv10      : (?, 28, 28, 512)  -> (?, 28, 28, 512) \n",
      "   pool10      : (?, 28, 28, 512)  -> (?, 14, 14, 512) \n",
      "   conv11      : (?, 14, 14, 512)  -> (?, 14, 14, 512) \n",
      "   conv12      : (?, 14, 14, 512)  -> (?, 14, 14, 512) \n",
      "   conv13      : (?, 14, 14, 512)  -> (?, 14, 14, 512) \n",
      "   pool13      : (?, 14, 14, 512)  -> (?, 7, 7, 512)   \n",
      "   flat        : (?, 7, 7, 512)    -> (?, 25088)       \n",
      "\n",
      " Classification\n",
      "   fc14        : (?, 25088)        -> (?, 4096)        \n",
      "   fc15        : (?, 4096)         -> (?, 4096)        \n",
      "   logits      : (?, 4096)         -> (?, 2)           \n",
      "\n",
      " Output\n",
      "   y_prediction: (?, 2)  hypothesis (prediction) of target value y\n"
     ]
    }
   ],
   "source": [
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "# Set Model Propagation\n",
    "\n",
    "#### 1. Forward propagation\n",
    "model에 input data 넣어서 model로 구한 y_prediction 값을 구하는 과정\n",
    "\n",
    "#### 2. Loss computation\n",
    "y_prediction 값과 y_true 값을 비교해서 loss (error)를 구하는 과정\n",
    "\n",
    "#### 3. Backpropagation\n",
    "loss 를가지고 model 의 train weight 를 update, optimize 시킴\n",
    "\n",
    "\n",
    "1 > 2 > 3 과정을 반복하며 y_true값과 유사한 결과를 내도록 모델을 학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_propagation = None\n",
    "compute_loss = None\n",
    "back_propagation = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_forward_propagation():\n",
    "    return m.y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_from_logits(labels, logits, weight_decay):\n",
    "    softmax_cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=logits)\n",
    "    softmax_loss = tf.reduce_mean(softmax_cross_entropy)\n",
    "\n",
    "    # L2 regularization loss\n",
    "    # coefficient weight decay = 0.0005 is used at the alexnet paper\n",
    "    L2_weight_decay = weight_decay / 2.0        \n",
    "\n",
    "    # L2 norm for all train parameters\n",
    "    L2_norm = tf.add_n([tf.nn.l2_loss(var) for var in tf.trainable_variables()]) \n",
    "    L2_regularization_loss = L2_norm * L2_weight_decay        \n",
    "\n",
    "    # Add L2 regularization for weight decay\n",
    "    return softmax_loss + L2_regularization_loss\n",
    "\n",
    "def define_loss_function():\n",
    "    loss = get_loss_from_logits(m.y, m.logits, weight_decay)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_backward_propagation():    \n",
    "    # Gradient descent optimizer, with Momentum algorithm\n",
    "    # tf.train.Optimizer.minimize Op for a gradient update.\n",
    "    variables_to_update = tf.trainable_variables()\n",
    "    m.current_learning_rate = tf.placeholder(tf.float32)\n",
    "\n",
    "    optimizer = tf.train.MomentumOptimizer(\n",
    "                    m.current_learning_rate,\n",
    "                    momentum,\n",
    "                    use_nesterov=False).minimize(compute_loss, var_list=variables_to_update)\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Softmax:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "forward_propagation = set_forward_propagation()\n",
    "print(forward_propagation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_16:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "compute_loss = define_loss_function()\n",
    "print(compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"Momentum\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Momentum/update_conv1_weights/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv1_biases/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv2_weights/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv2_biases/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv3_weights/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv3_biases/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv4_weights/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv4_biases/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv5_weights/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv5_biases/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv6_weights/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv6_biases/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv7_weights/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv7_biases/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv8_weights/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv8_biases/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv9_weights/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv9_biases/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv10_weights/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv10_biases/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv11_weights/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv11_biases/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv12_weights/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv12_biases/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv13_weights/ApplyMomentum\"\n",
      "input: \"^Momentum/update_conv13_biases/ApplyMomentum\"\n",
      "input: \"^Momentum/update_fc14_weights/ApplyMomentum\"\n",
      "input: \"^Momentum/update_fc14_biases/ApplyMomentum\"\n",
      "input: \"^Momentum/update_fc15_weights/ApplyMomentum\"\n",
      "input: \"^Momentum/update_fc15_biases/ApplyMomentum\"\n",
      "input: \"^Momentum/update_logits_weights/ApplyMomentum\"\n",
      "input: \"^Momentum/update_logits_biases/ApplyMomentum\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "back_propagation = set_backward_propagation()\n",
    "print(back_propagation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "# Run Train\n",
    "\n",
    "#### functions to help batch training/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_train(sess):\n",
    "\n",
    "    for batch_step in range(num_batches_per_epoch):\n",
    "\n",
    "        batch_x, batch_y_true = data_train.next_batch(batch_size)\n",
    "\n",
    "        _y_prediction, _loss, _, = sess.run([\n",
    "                        forward_propagation,\n",
    "                        compute_loss,\n",
    "                        back_propagation],\n",
    "                                feed_dict={\n",
    "                                m.x: batch_x,\n",
    "                                m.y: batch_y_true,\n",
    "                                m.current_learning_rate: current_learning_rate_value})\n",
    "\n",
    "    # after batch train loop, save this epoch's train score\n",
    "    y_true = batch_y_true.argmax(axis=1)\n",
    "    y_pred = _y_prediction.argmax(axis=1)\n",
    "\n",
    "    return _loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_validation(sess):\n",
    "    validation_y_prediction = run_forward_propagation_for_evaluation(sess, data_validation)\n",
    "    \n",
    "    y_true = data_validation.labels.argmax(axis=1)\n",
    "    y_pred = validation_y_prediction.argmax(axis=1)\n",
    "    \n",
    "    validation_score = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    return validation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_forward_propagation_for_evaluation(sess, dataset, augment_type=True):\n",
    "    if dataset.labels is not None:\n",
    "        assert len(dataset.labels.shape) > 1, 'Labels must be one-hot encoded.'\n",
    "\n",
    "    prediction_size = dataset.num_examples\n",
    "    \n",
    "    num_steps = prediction_size // batch_size\n",
    "    last_batch_size = prediction_size % batch_size\n",
    "\n",
    "    # Start prediction loop\n",
    "    y_prediction = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(num_steps+1):\n",
    "        _batch_size = batch_size if i < num_steps else last_batch_size\n",
    "        if _batch_size == 0:\n",
    "            break            \n",
    "\n",
    "        x, _ = dataset.next_batch(_batch_size, shuffle=False)\n",
    "        # if augment_pred == True:  X.shape: (N, 10, h, w, C)\n",
    "        # else:                     X.shape: (N, h, w, C)\n",
    "\n",
    "        if augment_type is True:\n",
    "            y_prediction_patches = np.empty((_batch_size, 10, num_classes),\n",
    "                                      dtype=np.float32)    # (N, 10, num_classes)\n",
    "            # compute predictions for each of 10 patch modes,\n",
    "            for idx in range(10):\n",
    "                y_prediction_patch = sess.run(forward_propagation,\n",
    "                                        feed_dict={m.x: x[:, idx]}) # (N, h, w, C)\n",
    "                y_prediction_patches[:, idx] = y_prediction_patch                   \n",
    "\n",
    "            _y_prediction = y_prediction_patches.mean(axis=1)    # (N, num_classes)\n",
    "\n",
    "        else:\n",
    "            # Compute predictions\n",
    "            _y_prediction = sess.run(tr1_forward_propagation,\n",
    "                              feed_dict={m.x: x})    # (N, num_classes)\n",
    "\n",
    "        y_prediction.append(_y_prediction)\n",
    "\n",
    "    y_prediction = np.concatenate(y_prediction, axis=0)    # (N, num_classes)\n",
    "\n",
    "    return y_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "base_path = 'trained_model_result/'  # result saving location\n",
    "\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)\n",
    "    os.chown(base_path, uid=1000, gid=1000)\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_path = os.path.join(base_path, timestamp + '/')\n",
    "\n",
    "os.makedirs(output_path)\n",
    "os.chown(output_path, uid=1000, gid=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------------------\n",
      " execute train\n",
      "------------------------------------------------------------------------\n",
      "  train data size       :         13\n",
      "  batch size            :         13\n",
      "  batche loop per epoch :          1 = |train data| 13 / |batch| 13\n",
      "  epoches               :        300\n",
      "  total iterations      :        300 = |batch loop| 1 * |epoch| 300\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_epochs = 0\n",
    "best_score = 0.0\n",
    "current_learning_rate_value = init_learning_rate\n",
    "\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(graph=graph, config=config)        \n",
    "sess.run(tf.global_variables_initializer())    # initialize all weights\n",
    "\n",
    "saver = tf.train.Saver()  # to save trained model\n",
    "output_model_path = os.path.join(output_path, 'model.ckpt')\n",
    "\n",
    "train_results = dict()    # dictionary to contain training(, evaluation) results and details\n",
    "total_steps = num_epochs * num_batches_per_epoch\n",
    "\n",
    "str = '\\n------------------------------------------------------------------------' + \\\n",
    "    '\\n execute train' + \\\n",
    "    '\\n------------------------------------------------------------------------' + \\\n",
    "    '\\n  train data size       : {:10}'.format(data_train.num_examples) + \\\n",
    "    '\\n  batch size            : {:10}'.format(batch_size) + \\\n",
    "    '\\n  batche loop per epoch : {:10} = |train data| {} / |batch| {}'.format(num_batches_per_epoch, data_train.num_examples, batch_size) + \\\n",
    "    '\\n  epoches               : {:10}'.format(num_epochs) + \\\n",
    "    '\\n  total iterations      : {:10} = |batch loop| {} * |epoch| {}\\n\\n'.format(total_steps, num_batches_per_epoch, num_epochs)\n",
    "\n",
    "print(str)\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_better(current_score, best_score):\n",
    "    score_threshold = 1e-4\n",
    "    relative_eps = 1.0 + score_threshold\n",
    "    return current_score > best_score * relative_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_learning_rate():\n",
    "    # decaying learning rate (epsilon)\n",
    "    global bad_epochs\n",
    "    global current_learning_rate_value\n",
    "\n",
    "    if bad_epochs > patience_of_no_improvement_epochs:            \n",
    "        new_learning_rate = current_learning_rate_value * learning_rate_decay\n",
    "        \n",
    "        # Decay learning rate only when the difference is higher than lower bound epsilon.\n",
    "        if current_learning_rate_value - new_learning_rate > lower_bound_learning_rate:\n",
    "            current_learning_rate_value = new_learning_rate\n",
    "        \n",
    "        bad_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch   0] loss: 2.592460 | validation score: 0.666667 | learning rate: 0.010000\n",
      "[epoch   1] loss: 2.631156 | validation score: 0.333333 | learning rate: 0.010000\n",
      "[epoch   2] loss: 2.553823 | validation score: 0.333333 | learning rate: 0.010000\n",
      "[epoch   3] loss: 2.653147 | validation score: 0.333333 | learning rate: 0.010000\n",
      "[epoch   4] loss: 2.602943 | validation score: 0.333333 | learning rate: 0.010000\n",
      "[epoch   5] loss: 2.636897 | validation score: 0.333333 | learning rate: 0.010000\n",
      "[epoch   6] loss: 2.673689 | validation score: 0.333333 | learning rate: 0.010000\n",
      "[epoch   7] loss: 2.648526 | validation score: 0.666667 | learning rate: 0.010000\n",
      "[epoch   8] loss: 2.653535 | validation score: 0.333333 | learning rate: 0.010000\n",
      "[epoch   9] loss: 2.496190 | validation score: 0.333333 | learning rate: 0.010000\n",
      "[epoch  10] loss: 2.604900 | validation score: 0.333333 | learning rate: 0.010000\n",
      "[epoch  11] loss: 2.568743 | validation score: 0.333333 | learning rate: 0.010000\n",
      "[epoch  12] loss: 2.483334 | validation score: 0.333333 | learning rate: 0.010000\n",
      "[epoch  13] loss: 2.683096 | validation score: 0.666667 | learning rate: 0.010000\n",
      "[epoch  14] loss: 2.653782 | validation score: 0.666667 | learning rate: 0.010000\n",
      "[epoch  15] loss: 2.559458 | validation score: 0.666667 | learning rate: 0.010000\n",
      "[epoch  16] loss: 2.566571 | validation score: 0.000000 | learning rate: 0.010000\n",
      "[epoch  17] loss: 2.660149 | validation score: 0.333333 | learning rate: 0.010000\n",
      "[epoch  18] loss: 2.950148 | validation score: 0.333333 | learning rate: 0.010000\n",
      "[epoch  19] loss: 2.683706 | validation score: 0.333333 | learning rate: 0.010000\n",
      "[epoch  20] loss: 2.428404 | validation score: 0.000000 | learning rate: 0.010000\n",
      "[epoch  21] loss: 2.685738 | validation score: 0.666667 | learning rate: 0.010000\n",
      "[epoch  22] loss: 2.688460 | validation score: 0.666667 | learning rate: 0.010000\n",
      "[epoch  23] loss: 2.848156 | validation score: 0.666667 | learning rate: 0.010000\n",
      "[epoch  24] loss: 2.571508 | validation score: 0.333333 | learning rate: 0.010000\n",
      "[epoch  25] loss: 2.637759 | validation score: 0.333333 | learning rate: 0.010000\n",
      "[epoch  26] loss: 2.648531 | validation score: 0.333333 | learning rate: 0.010000\n",
      "[epoch  27] loss: 2.949567 | validation score: 0.666667 | learning rate: 0.010000\n",
      "[epoch  28] loss: 2.691204 | validation score: 0.666667 | learning rate: 0.010000\n",
      "[epoch  29] loss: 2.924347 | validation score: 0.666667 | learning rate: 0.010000\n",
      "[epoch  30] loss: 2.714364 | validation score: 0.333333 | learning rate: 0.010000\n",
      "[epoch  31] loss: 2.692605 | validation score: 0.333333 | learning rate: 0.010000\n",
      "[epoch  32] loss: 2.691342 | validation score: 0.333333 | learning rate: 0.001000\n",
      "[epoch  33] loss: 2.526385 | validation score: 0.333333 | learning rate: 0.001000\n",
      "[epoch  34] loss: 2.484611 | validation score: 0.333333 | learning rate: 0.001000\n",
      "[epoch  35] loss: 2.643968 | validation score: 0.333333 | learning rate: 0.001000\n",
      "[epoch  36] loss: 2.801817 | validation score: 0.333333 | learning rate: 0.001000\n",
      "[epoch  37] loss: 2.542885 | validation score: 0.666667 | learning rate: 0.001000\n",
      "[epoch  38] loss: 2.665627 | validation score: 1.000000 | learning rate: 0.001000\n",
      "[epoch  39] loss: 2.848067 | validation score: 0.666667 | learning rate: 0.001000\n",
      "[epoch  40] loss: 2.558539 | validation score: 0.666667 | learning rate: 0.001000\n",
      "[epoch  41] loss: 2.525388 | validation score: 0.666667 | learning rate: 0.001000\n",
      "[epoch  42] loss: 2.756402 | validation score: 0.666667 | learning rate: 0.001000\n",
      "[epoch  43] loss: 2.440892 | validation score: 0.666667 | learning rate: 0.001000\n",
      "[epoch  44] loss: 3.021307 | validation score: 0.666667 | learning rate: 0.001000\n",
      "[epoch  45] loss: 2.793569 | validation score: 1.000000 | learning rate: 0.001000\n",
      "[epoch  46] loss: 2.541765 | validation score: 0.333333 | learning rate: 0.001000\n",
      "[epoch  47] loss: 2.777534 | validation score: 0.666667 | learning rate: 0.001000\n",
      "[epoch  48] loss: 2.595064 | validation score: 0.333333 | learning rate: 0.001000\n",
      "[epoch  49] loss: 2.986108 | validation score: 0.666667 | learning rate: 0.001000\n",
      "[epoch  50] loss: 2.796150 | validation score: 0.000000 | learning rate: 0.001000\n",
      "[epoch  51] loss: 2.688570 | validation score: 0.333333 | learning rate: 0.001000\n",
      "[epoch  52] loss: 2.810354 | validation score: 0.333333 | learning rate: 0.001000\n",
      "[epoch  53] loss: 2.453922 | validation score: 0.333333 | learning rate: 0.001000\n",
      "[epoch  54] loss: 2.674858 | validation score: 0.333333 | learning rate: 0.001000\n",
      "[epoch  55] loss: 2.720123 | validation score: 0.666667 | learning rate: 0.001000\n",
      "[epoch  56] loss: 2.781467 | validation score: 0.333333 | learning rate: 0.001000\n",
      "[epoch  57] loss: 2.664314 | validation score: 1.000000 | learning rate: 0.001000\n",
      "[epoch  58] loss: 2.822899 | validation score: 0.666667 | learning rate: 0.001000\n",
      "[epoch  59] loss: 2.679128 | validation score: 0.666667 | learning rate: 0.001000\n",
      "[epoch  60] loss: 2.498972 | validation score: 0.666667 | learning rate: 0.001000\n",
      "[epoch  61] loss: 2.619594 | validation score: 0.333333 | learning rate: 0.001000\n",
      "[epoch  62] loss: 2.542283 | validation score: 0.333333 | learning rate: 0.001000\n",
      "[epoch  63] loss: 3.038755 | validation score: 0.666667 | learning rate: 0.001000\n",
      "[epoch  64] loss: 2.740779 | validation score: 0.000000 | learning rate: 0.001000\n",
      "[epoch  65] loss: 2.693505 | validation score: 0.666667 | learning rate: 0.001000\n",
      "[epoch  66] loss: 2.803574 | validation score: 0.666667 | learning rate: 0.001000\n",
      "[epoch  67] loss: 2.612137 | validation score: 0.666667 | learning rate: 0.001000\n",
      "[epoch  68] loss: 2.626512 | validation score: 0.333333 | learning rate: 0.001000\n",
      "[epoch  69] loss: 2.541229 | validation score: 0.333333 | learning rate: 0.001000\n",
      "[epoch  70] loss: 2.516401 | validation score: 0.000000 | learning rate: 0.000100\n",
      "[epoch  71] loss: 2.945111 | validation score: 0.333333 | learning rate: 0.000100\n",
      "[epoch  72] loss: 2.769375 | validation score: 0.333333 | learning rate: 0.000100\n",
      "[epoch  73] loss: 2.664194 | validation score: 0.333333 | learning rate: 0.000100\n",
      "[epoch  74] loss: 2.543048 | validation score: 0.333333 | learning rate: 0.000100\n",
      "[epoch  75] loss: 2.670841 | validation score: 0.333333 | learning rate: 0.000100\n",
      "[epoch  76] loss: 2.403303 | validation score: 0.333333 | learning rate: 0.000100\n",
      "[epoch  77] loss: 2.418967 | validation score: 0.333333 | learning rate: 0.000100\n",
      "[epoch  78] loss: 2.458399 | validation score: 0.333333 | learning rate: 0.000100\n",
      "[epoch  79] loss: 2.681561 | validation score: 0.000000 | learning rate: 0.000100\n",
      "[epoch  80] loss: 2.589518 | validation score: 0.333333 | learning rate: 0.000100\n",
      "[epoch  81] loss: 2.548106 | validation score: 0.666667 | learning rate: 0.000100\n",
      "[epoch  82] loss: 2.680175 | validation score: 0.333333 | learning rate: 0.000100\n",
      "[epoch  83] loss: 2.885334 | validation score: 0.333333 | learning rate: 0.000100\n",
      "[epoch  84] loss: 2.626417 | validation score: 0.666667 | learning rate: 0.000100\n",
      "[epoch  85] loss: 2.604953 | validation score: 0.666667 | learning rate: 0.000100\n",
      "[epoch  86] loss: 2.647515 | validation score: 0.666667 | learning rate: 0.000100\n",
      "[epoch  87] loss: 2.600692 | validation score: 0.333333 | learning rate: 0.000100\n",
      "[epoch  88] loss: 2.747632 | validation score: 0.666667 | learning rate: 0.000100\n",
      "[epoch  89] loss: 2.850613 | validation score: 0.333333 | learning rate: 0.000100\n",
      "[epoch  90] loss: 2.480922 | validation score: 0.333333 | learning rate: 0.000100\n",
      "[epoch  91] loss: 2.618437 | validation score: 0.000000 | learning rate: 0.000100\n",
      "[epoch  92] loss: 2.812213 | validation score: 0.333333 | learning rate: 0.000100\n",
      "[epoch  93] loss: 2.485285 | validation score: 0.666667 | learning rate: 0.000100\n",
      "[epoch  94] loss: 2.784303 | validation score: 0.333333 | learning rate: 0.000100\n",
      "[epoch  95] loss: 2.686050 | validation score: 0.333333 | learning rate: 0.000100\n",
      "[epoch  96] loss: 2.547885 | validation score: 0.333333 | learning rate: 0.000100\n",
      "[epoch  97] loss: 3.004740 | validation score: 0.333333 | learning rate: 0.000100\n",
      "[epoch  98] loss: 2.546993 | validation score: 0.000000 | learning rate: 0.000100\n",
      "[epoch  99] loss: 2.790274 | validation score: 0.333333 | learning rate: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 100] loss: 2.489831 | validation score: 0.333333 | learning rate: 0.000100\n",
      "[epoch 101] loss: 2.589458 | validation score: 0.333333 | learning rate: 0.000010\n",
      "[epoch 102] loss: 2.947601 | validation score: 0.666667 | learning rate: 0.000010\n",
      "[epoch 103] loss: 2.579515 | validation score: 0.333333 | learning rate: 0.000010\n",
      "[epoch 104] loss: 2.877043 | validation score: 0.666667 | learning rate: 0.000010\n",
      "[epoch 105] loss: 2.868003 | validation score: 0.333333 | learning rate: 0.000010\n",
      "[epoch 106] loss: 2.673076 | validation score: 0.333333 | learning rate: 0.000010\n",
      "[epoch 107] loss: 2.485342 | validation score: 0.333333 | learning rate: 0.000010\n",
      "[epoch 108] loss: 2.755638 | validation score: 0.333333 | learning rate: 0.000010\n",
      "[epoch 109] loss: 2.490468 | validation score: 0.666667 | learning rate: 0.000010\n",
      "[epoch 110] loss: 2.584959 | validation score: 0.000000 | learning rate: 0.000010\n",
      "[epoch 111] loss: 2.342264 | validation score: 0.333333 | learning rate: 0.000010\n",
      "[epoch 112] loss: 2.706506 | validation score: 0.666667 | learning rate: 0.000010\n",
      "[epoch 113] loss: 2.556082 | validation score: 0.333333 | learning rate: 0.000010\n",
      "[epoch 114] loss: 2.733103 | validation score: 0.666667 | learning rate: 0.000010\n",
      "[epoch 115] loss: 2.601713 | validation score: 0.666667 | learning rate: 0.000010\n",
      "[epoch 116] loss: 2.450031 | validation score: 0.666667 | learning rate: 0.000010\n",
      "[epoch 117] loss: 2.502139 | validation score: 0.333333 | learning rate: 0.000010\n",
      "[epoch 118] loss: 2.701348 | validation score: 0.666667 | learning rate: 0.000010\n",
      "[epoch 119] loss: 2.884700 | validation score: 0.333333 | learning rate: 0.000010\n",
      "[epoch 120] loss: 2.549761 | validation score: 0.333333 | learning rate: 0.000010\n",
      "[epoch 121] loss: 2.737625 | validation score: 0.000000 | learning rate: 0.000010\n",
      "[epoch 122] loss: 2.492259 | validation score: 0.666667 | learning rate: 0.000010\n",
      "[epoch 123] loss: 2.615569 | validation score: 0.000000 | learning rate: 0.000010\n",
      "[epoch 124] loss: 2.997334 | validation score: 0.333333 | learning rate: 0.000010\n",
      "[epoch 125] loss: 2.676537 | validation score: 0.666667 | learning rate: 0.000010\n",
      "[epoch 126] loss: 2.518789 | validation score: 0.333333 | learning rate: 0.000010\n",
      "[epoch 127] loss: 2.776797 | validation score: 0.666667 | learning rate: 0.000010\n",
      "[epoch 128] loss: 2.846574 | validation score: 0.666667 | learning rate: 0.000010\n",
      "[epoch 129] loss: 2.846639 | validation score: 0.666667 | learning rate: 0.000010\n",
      "[epoch 130] loss: 2.858825 | validation score: 0.666667 | learning rate: 0.000010\n",
      "[epoch 131] loss: 2.688323 | validation score: 0.333333 | learning rate: 0.000010\n",
      "[epoch 132] loss: 2.682800 | validation score: 0.333333 | learning rate: 0.000001\n",
      "[epoch 133] loss: 2.667166 | validation score: 0.666667 | learning rate: 0.000001\n",
      "[epoch 134] loss: 2.713085 | validation score: 0.666667 | learning rate: 0.000001\n",
      "[epoch 135] loss: 2.711960 | validation score: 0.333333 | learning rate: 0.000001\n",
      "[epoch 136] loss: 2.532790 | validation score: 0.333333 | learning rate: 0.000001\n",
      "[epoch 137] loss: 2.615800 | validation score: 0.333333 | learning rate: 0.000001\n",
      "[epoch 138] loss: 2.674976 | validation score: 0.333333 | learning rate: 0.000001\n",
      "[epoch 139] loss: 2.599813 | validation score: 0.333333 | learning rate: 0.000001\n",
      "[epoch 140] loss: 2.782485 | validation score: 0.333333 | learning rate: 0.000001\n",
      "[epoch 141] loss: 2.670827 | validation score: 0.000000 | learning rate: 0.000001\n",
      "[epoch 142] loss: 2.749040 | validation score: 0.666667 | learning rate: 0.000001\n",
      "[epoch 143] loss: 2.648785 | validation score: 0.666667 | learning rate: 0.000001\n",
      "[epoch 144] loss: 2.407964 | validation score: 0.666667 | learning rate: 0.000001\n",
      "[epoch 145] loss: 2.539164 | validation score: 0.666667 | learning rate: 0.000001\n",
      "[epoch 146] loss: 2.717442 | validation score: 0.333333 | learning rate: 0.000001\n",
      "[epoch 147] loss: 2.953111 | validation score: 0.333333 | learning rate: 0.000001\n",
      "[epoch 148] loss: 2.886191 | validation score: 0.333333 | learning rate: 0.000001\n",
      "[epoch 149] loss: 2.665566 | validation score: 1.000000 | learning rate: 0.000001\n",
      "[epoch 150] loss: 2.593957 | validation score: 0.666667 | learning rate: 0.000001\n",
      "[epoch 151] loss: 2.703463 | validation score: 0.333333 | learning rate: 0.000001\n",
      "[epoch 152] loss: 2.777964 | validation score: 0.333333 | learning rate: 0.000001\n",
      "[epoch 153] loss: 2.783247 | validation score: 0.666667 | learning rate: 0.000001\n",
      "[epoch 154] loss: 2.686168 | validation score: 0.333333 | learning rate: 0.000001\n",
      "[epoch 155] loss: 2.962361 | validation score: 0.333333 | learning rate: 0.000001\n",
      "[epoch 156] loss: 2.895718 | validation score: 0.333333 | learning rate: 0.000001\n",
      "[epoch 157] loss: 2.757759 | validation score: 0.000000 | learning rate: 0.000001\n",
      "[epoch 158] loss: 2.943732 | validation score: 0.333333 | learning rate: 0.000001\n",
      "[epoch 159] loss: 2.661602 | validation score: 0.333333 | learning rate: 0.000001\n",
      "[epoch 160] loss: 2.625148 | validation score: 0.666667 | learning rate: 0.000001\n",
      "[epoch 161] loss: 2.689748 | validation score: 0.000000 | learning rate: 0.000001\n",
      "[epoch 162] loss: 2.629830 | validation score: 0.000000 | learning rate: 0.000001\n",
      "   exit train: learning rate is too small (< 0.000001)\n"
     ]
    }
   ],
   "source": [
    "# start training loop\n",
    "for epoch_step in range(num_epochs):\n",
    "    # perform a gradient update of the current epoch\n",
    "    current_loss = execute_train(sess)       \n",
    "    current_score = execute_validation(sess)\n",
    "\n",
    "    str = '[epoch{:4}] loss: {:.6f} | validation score: {:.6f} | learning rate: {:.6f}'\\\n",
    "                    .format(epoch_step, current_loss, current_score, current_learning_rate_value)\n",
    "    print(str)\n",
    "\n",
    "    # Keep track of the current best model,\n",
    "    if is_better(current_score, best_score):\n",
    "        best_score = current_score\n",
    "        bad_epochs = 0\n",
    "\n",
    "        saver.save(sess, output_model_path)  # save current weights\n",
    "    else:\n",
    "        bad_epochs += 1\n",
    "        \n",
    "    update_learning_rate()\n",
    "    if current_learning_rate_value < 0.000001:\n",
    "        print('   exit train: learning rate is too small (< 0.000001)')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_test(sess):\n",
    "\n",
    "    test_y_prediction = run_forward_propagation_for_evaluation(sess, data_test)\n",
    "   \n",
    "    y_true = data_test.labels.argmax(axis=1)\n",
    "    y_pred = test_y_prediction.argmax(axis=1)\n",
    "\n",
    "    test_score = accuracy_score(y_true, y_pred)\n",
    "    return test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Reading test data..\n",
      "     progress: 0/10...\r",
      "     progress: 10/10...\r\n",
      " Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = read_test_data_sets('../test_data/asirra_smaller/', image_reshape_size=224)\n",
    "data_test = data.test\n",
    "num_classes = len(data_test.labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from trained_model_result/20190712_072644/model.ckpt\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "execute test\n",
      "------------------------------------------------------------------------\n",
      "  test data size       :         10\n",
      "  batch size           :         13\n"
     ]
    }
   ],
   "source": [
    "graph = tf.get_default_graph()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(graph=graph, config=config)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, output_model_path) \n",
    "\n",
    "str = '\\n------------------------------------------------------------------------' + \\\n",
    "    '\\nexecute test' + \\\n",
    "    '\\n------------------------------------------------------------------------' + \\\n",
    "    '\\n  test data size       : {:10}'.format(data_test.num_examples) + \\\n",
    "    '\\n  batch size           : {:10}'.format(batch_size) \n",
    "\n",
    "print(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = execute_test(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Test finished.\n",
      "------------------------------------------------------------------------\n",
      "\n",
      " Test score (accuracy) : 0.4\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    " str = '\\n\\n\\n------------------------------------------------------------------------' + \\\n",
    "    '\\nTest finished.' + \\\n",
    "    '\\n------------------------------------------------------------------------' + \\\n",
    "    '\\n\\n Test score (accuracy) : {}'.format(test_score) + \\\n",
    "    '\\n------------------------------------------------------------------------\\n\\n'\n",
    "\n",
    "print(str)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
