{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"CNN_fromFile_flower_gray.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"xBJWMeO0r-qy"},"source":["# 이미지 준비"]},{"cell_type":"code","metadata":{"id":"OzdgttRvp6F3"},"source":["%%bash\n","apt install -y imagemagick\n","[ ! -f flower_photos_300x200_small_train_test.zip ]&& wget https://raw.githubusercontent.com/Finfra/AI_CNN_RNN/main/data/flower_photos_300x200_small_train_test.zip\n","\n","rm -rf __MACOSX\n","rm -rf flowers\n","unzip -q flower_photos_300x200_small_train_test.zip\n","mv flower_photos_300x200_small_train_test flowers\n","\n","cd flowers\n","files=$(find |grep \"\\.jpg$\\|\\.png$\")\n","for i in $files; do\n","    convert $i -quiet  -resize 300x200^ -gravity center -extent 300x200  -colorspace Gray    ${i%.*}.png\n","    #convert $i -quiet  -resize 300x200^ -gravity center -extent 300x200  -define png:color-type=2   ${i%.*}.png\n","    \n","    # identify ${i%.*}.png\n","    rm -f $i\n","done\n","\n","find .|grep .DS_Store|xargs rm -f\n","find .|head -n 10\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dhow5w0Cyhu9"},"source":["# CNN Example FromFile by Keras\n"]},{"cell_type":"code","metadata":{"id":"bIcSLm6Cyhu-"},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","import tensorflow as tf\n","from tensorflow.keras import datasets, layers, models\n","from tensorflow.keras.utils import to_categorical\n","\n","import numpy as np\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sS-n7IiW7I0P"},"source":["# 해당 Path의 이미지 Array로 리턴"]},{"cell_type":"code","metadata":{"id":"z3_tr9TGyhvC"},"source":["from os import listdir\n","from os.path import isfile, join\n","from pylab import *\n","from numpy import *\n","\n","def getFolder(thePath,isFile=True):\n","    return [f for f in listdir(thePath) if isFile == isfile(join(thePath, f)) ]\n","\n","\n","def getImagesAndLabels(tPath,isGray=False):\n","    labels=getFolder(tPath,False)\n","    tImgDic={f:getFolder(join(tPath,f)) for f in labels}\n","    tImages,tLabels=None,None\n","    ks=sorted(list(tImgDic.keys()))\n","\n","    oh=np.identity(len(ks))\n","    for label in tImgDic.keys():\n","        for image in tImgDic[label]:\n","            le=np.array([float(label)],ndmin=1)\n","            img=imread(join(tPath,label,image))\n","            if isGray:\n","                img=img.reshape(img.shape+(1,))\n","            \n","            img=img.reshape((1,) +img.shape)\n","            \n","            if tImages is None:\n","                tImages, tLabels =img, le\n","            else:\n","                tImages,tLabels = np.append(tImages,img,axis=0), np.append(tLabels,le ,axis=0)\n","    return (tImages,to_categorical(tLabels) )\n","\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KERgFFAlQZOm"},"source":["w=300\n","h=200\n","color=1\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W4s0Itg07vYk"},"source":["\n","tPath='flowers/train'\n","train_images,train_labels=getImagesAndLabels(tPath,isGray=True)    \n","tPath='flowers/test'\n","test_images,test_labels=getImagesAndLabels(tPath,isGray=True)    \n","train_images, test_images = train_images / 255.0, test_images / 255.0\n","\n","print(f\"Shape of Train_images = {train_images.shape} , Shape of Train_labels = {train_labels.shape}\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kk0CsU6LyhvI"},"source":["model = models.Sequential()\n","model.add(layers.Conv2D(96, (13, 13), activation='relu', padding='same', input_shape=(h,w, color)))\n","model.add(layers.Dropout(0.2))\n","model.add(layers.MaxPooling2D((3, 3)))\n","\n","\n","model.add(layers.Conv2D(64, (7, 7), activation='relu', padding='same'))\n","model.add(layers.Dropout(0.2))\n","model.add(layers.MaxPooling2D((3, 3)))\n","\n","model.add(layers.Conv2D(64, (5, 5), activation='relu', padding='same'))\n","model.add(layers.Dropout(0.2))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPooling2D((3, 3)))\n","\n","model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n","model.add(layers.MaxPooling2D((3, 3)))\n","model.add(layers.Flatten())\n","\n","model.add(layers.Dense(200, activation='tanh',kernel_regularizer='l1'))\n","model.add(layers.Dense(2, activation='softmax'))\n","model.summary()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z8n7Q1jfyhvM"},"source":["model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","hist=model.fit(train_images, train_labels, epochs=40,batch_size=100)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wAEJQV6x5aLz"},"source":["# Train history"]},{"cell_type":"code","metadata":{"id":"nqLZ4c6F6zMA"},"source":["\n","print('## training loss and acc ##')\n","fig, loss_ax = plt.subplots()\n","acc_ax = loss_ax.twinx()\n","\n","loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n","loss_ax.set_xlabel('epoch')\n","loss_ax.set_ylabel('loss')\n","loss_ax.legend(loc='upper left')\n","\n","acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n","acc_ax.set_ylabel('accuracy')\n","acc_ax.legend(loc='upper right')\n","\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rMpYl9BByhvP"},"source":["\n","# Result"]},{"cell_type":"code","metadata":{"id":"5k2PbbcG62d0"},"source":["score = model.evaluate(test_images, test_labels, verbose=0, batch_size=32)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Lq0A8545gSB"},"source":[""],"execution_count":null,"outputs":[]}]}