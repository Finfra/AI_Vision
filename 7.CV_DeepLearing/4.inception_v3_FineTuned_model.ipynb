{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4.inception_v3_FineTuned_model.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"oyc4aqeDfBsq"},"source":["* 출처 : https://keras.io/ko/applications/\n"]},{"cell_type":"code","metadata":{"id":"Zag6rlkFlnW-"},"source":["%%bash\n","[ ! -f flower_photos_300x200_small_train_test2.zip ]&& wget https://raw.githubusercontent.com/Finfra/AI_Vision/master/data/flower_photos_300x200_small_train_test2.zip\n","\n","rm -rf __MACOSX\n","rm -rf flowers\n","unzip -q flower_photos_300x200_small_train_test2.zip\n","mv flower_photos_300x200_small_train_test2 flowers\n","\n","cd flowers\n","\n","\n","find .|grep .DS_Store|xargs rm -f\n","find .|head -n 10\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P8CuInzImA_i","executionInfo":{"status":"ok","timestamp":1638333381328,"user_tz":-540,"elapsed":436,"user":{"displayName":"HyunJae Na","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01248657443637565537"}}},"source":["from os import listdir\n","from os.path import isfile, join, splitext\n","import cv2\n","def getFolder(thePath,isFile=True):\n","    return [f for f in listdir(thePath) if isFile == isfile(join(thePath, f)) ]\n","\n","def convert(thePath,to_w,to_h):\n","    ext=splitext(\".jpg\")[0]\n","    if ext in ('.jpg','.png'):\n","      img = cv2.imread(thePath)\n","      if (to_h,to_w,3) != img.shape :\n","        img = cv2.resize(img,(to_w,to_h))\n","        print(img.shape[0],img.shape[1],'to',to_w,to_h , thePath , )\n","        cv2.imwrite(thePath,img)\n","      # else:\n","      #   print(thePath,\"is not changed (same)\")\n","\n","def convertAll(tPath,to_w,to_h):\n","  for folder in getFolder(tPath,False):\n","    print('-------------------')\n","    print(join(tPath,folder))\n","    convertAll(join(tPath,folder),to_w,to_h)\n","  for files in getFolder(tPath,True):\n","      convert(join(tPath,files),to_w,to_h)\n","\n","\n","tPath='/content/flowers/'\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lkS3UpxfR37E","executionInfo":{"status":"ok","timestamp":1638333501990,"user_tz":-540,"elapsed":2341,"user":{"displayName":"HyunJae Na","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01248657443637565537"}},"outputId":"aee57035-a3df-4685-9a28-c4925cc092a2"},"source":["!apt-get install imagemagick\n"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  fonts-droid-fallback fonts-noto-mono ghostscript gsfonts\n","  imagemagick-6-common imagemagick-6.q16 libcupsfilters1 libcupsimage2\n","  libdjvulibre-text libdjvulibre21 libgs9 libgs9-common libijs-0.35\n","  libjbig2dec0 liblqr-1-0 libmagickcore-6.q16-3 libmagickcore-6.q16-3-extra\n","  libmagickwand-6.q16-3 libnetpbm10 libwmf0.2-7 netpbm poppler-data\n","Suggested packages:\n","  fonts-noto ghostscript-x imagemagick-doc autotrace cups-bsd | lpr | lprng\n","  enscript gimp gnuplot grads hp2xx html2ps libwmf-bin mplayer povray radiance\n","  sane-utils texlive-base-bin transfig ufraw-batch inkscape libjxr-tools\n","  libwmf0.2-7-gtk poppler-utils fonts-japanese-mincho | fonts-ipafont-mincho\n","  fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai\n","  fonts-arphic-uming fonts-nanum\n","The following NEW packages will be installed:\n","  fonts-droid-fallback fonts-noto-mono ghostscript gsfonts imagemagick\n","  imagemagick-6-common imagemagick-6.q16 libcupsfilters1 libcupsimage2\n","  libdjvulibre-text libdjvulibre21 libgs9 libgs9-common libijs-0.35\n","  libjbig2dec0 liblqr-1-0 libmagickcore-6.q16-3 libmagickcore-6.q16-3-extra\n","  libmagickwand-6.q16-3 libnetpbm10 libwmf0.2-7 netpbm poppler-data\n","0 upgraded, 23 newly installed, 0 to remove and 37 not upgraded.\n","Need to get 2,473 kB/18.4 MB of archives.\n","After this operation, 66.3 MB of additional disk space will be used.\n","Ign:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 imagemagick-6-common all 8:6.9.7.4+dfsg-16ubuntu6.11\n","Ign:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickcore-6.q16-3 amd64 8:6.9.7.4+dfsg-16ubuntu6.11\n","Ign:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickwand-6.q16-3 amd64 8:6.9.7.4+dfsg-16ubuntu6.11\n","Ign:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 imagemagick-6.q16 amd64 8:6.9.7.4+dfsg-16ubuntu6.11\n","Ign:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 imagemagick amd64 8:6.9.7.4+dfsg-16ubuntu6.11\n","Ign:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickcore-6.q16-3-extra amd64 8:6.9.7.4+dfsg-16ubuntu6.11\n","Err:1 http://security.ubuntu.com/ubuntu bionic-updates/main amd64 imagemagick-6-common all 8:6.9.7.4+dfsg-16ubuntu6.11\n","  404  Not Found [IP: 91.189.88.152 80]\n","Err:2 http://security.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickcore-6.q16-3 amd64 8:6.9.7.4+dfsg-16ubuntu6.11\n","  404  Not Found [IP: 91.189.88.152 80]\n","Err:3 http://security.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickwand-6.q16-3 amd64 8:6.9.7.4+dfsg-16ubuntu6.11\n","  404  Not Found [IP: 91.189.88.152 80]\n","Err:4 http://security.ubuntu.com/ubuntu bionic-updates/main amd64 imagemagick-6.q16 amd64 8:6.9.7.4+dfsg-16ubuntu6.11\n","  404  Not Found [IP: 91.189.88.152 80]\n","Err:5 http://security.ubuntu.com/ubuntu bionic-updates/main amd64 imagemagick amd64 8:6.9.7.4+dfsg-16ubuntu6.11\n","  404  Not Found [IP: 91.189.88.152 80]\n","Err:6 http://security.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickcore-6.q16-3-extra amd64 8:6.9.7.4+dfsg-16ubuntu6.11\n","  404  Not Found [IP: 91.189.88.152 80]\n","E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/i/imagemagick/imagemagick-6-common_6.9.7.4+dfsg-16ubuntu6.11_all.deb  404  Not Found [IP: 91.189.88.152 80]\n","E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/i/imagemagick/libmagickcore-6.q16-3_6.9.7.4+dfsg-16ubuntu6.11_amd64.deb  404  Not Found [IP: 91.189.88.152 80]\n","E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/i/imagemagick/libmagickwand-6.q16-3_6.9.7.4+dfsg-16ubuntu6.11_amd64.deb  404  Not Found [IP: 91.189.88.152 80]\n","E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/i/imagemagick/imagemagick-6.q16_6.9.7.4+dfsg-16ubuntu6.11_amd64.deb  404  Not Found [IP: 91.189.88.152 80]\n","E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/i/imagemagick/imagemagick_6.9.7.4+dfsg-16ubuntu6.11_amd64.deb  404  Not Found [IP: 91.189.88.152 80]\n","E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/i/imagemagick/libmagickcore-6.q16-3-extra_6.9.7.4+dfsg-16ubuntu6.11_amd64.deb  404  Not Found [IP: 91.189.88.152 80]\n","E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2__Ny8jCSAGt","executionInfo":{"status":"ok","timestamp":1638333492781,"user_tz":-540,"elapsed":517,"user":{"displayName":"HyunJae Na","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01248657443637565537"}},"outputId":"99e09506-1a56-40f9-fbdc-00b2abb822b8"},"source":["!identify /content/flowers/test/daisy/14221836990_90374e6b34.jpg"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: convert: command not found\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DKBf13FRlUrr","executionInfo":{"status":"ok","timestamp":1638333571961,"user_tz":-540,"elapsed":4307,"user":{"displayName":"HyunJae Na","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01248657443637565537"}},"outputId":"f22a92bb-bc14-428b-bbea-5cf669422f27"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","w=224\n","h=224\n","color=3\n","\n","convertAll(tPath,w,h)\n","\n","\n","\n","# load and iterate training dataset\n","datagen = ImageDataGenerator()\n","train_data = datagen.flow_from_directory(directory='flowers/train/', class_mode='categorical', batch_size=64,target_size=(h, w))\n","# load and iterate test dataset\n","test_data = datagen.flow_from_directory(directory='flowers/test/',  class_mode='categorical', batch_size=64,target_size=(h,w))\n","\n"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["-------------------\n","/content/flowers/train\n","-------------------\n","/content/flowers/train/tulip\n","224 224 to 224 224 /content/flowers/train/tulip/130685245_dcdd23836f_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/142235017_07816937c6.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/6958243974_8851425ddb_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/2229804138_db9cba3443_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/3601085193_de1195d3d7_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14674071872_2df55466d5_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/16506668270_b823935dc3.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/4571353297_5634177744_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/2481015475_b71a12917d.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/18245124970_e68fd3f3c3.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/8687675254_c93f50d8b0_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/8713387500_6a9138b41b_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14127532150_112823a8f6.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/7094415739_6b29e5215c_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/8454719295_4276c0e9c5_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/7166567320_0a2beb6d42.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/3626132563_d955973447_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/4442928974_9672d630b2_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/7448453762_aea8739f1b.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/3909355648_42cb3a5e09_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/4550091966_7f3e0f8802_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/7166618384_850905fc63_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/11746276_de3dec8201.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/4558912791_084e440365_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/8689672277_b289909f97_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/16717320956_d4b00807f2.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/17199496791_3caaf5e278_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/4599815420_8ee42c2382.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14487705209_ea723109e1_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/8713357842_9964a93473_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14122029097_3e3285ca5c_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/17844723633_da85357fe3.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/5813495998_64be1b8ab6_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/17309951996_552d632cbb_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/17324469461_2b318aff8d_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14064731501_ea14b58161.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/3457017604_90e4de7480_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/15147473067_7c5498eb0e_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/5810456385_b44358a0ae.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/2249756775_02e693beda_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/7047408023_6e98fd1e3f.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/8713388322_e5ae26263b_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/6958343928_7e596da4ed_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14097745904_436c4ba1b4_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/17189526216_fa24dd541a_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/16303377824_6e9128b4bd.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/8681825637_837a63513a_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/7166550328_de0d73cfa9.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/5552198702_35856ed8ec.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14067778605_0285b7cc3a.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/17908793211_ff0f1f81d3_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14491997336_36ba524713.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14266093711_66d18a1e44_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/2333321040_3960b9d67e_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/6998661030_46cbb7892a.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/3454461550_64d6e726bf_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/8713390684_041148dd3e_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14097328354_4f1469a170.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/15632065904_0d9caf174b.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/3614805920_7a6610aa4b_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/2425067141_b27043a800_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/16282277874_b92776b194.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/8673416556_639f5c88f1_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/7447655334_e8f805ab95_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/8623173256_3f0eb4c506.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/7145978709_2d1596f462.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/130684941_d1abfa3be6_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/17202535346_ab828e779b.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14651385476_7ccb20e594_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/17408197905_829c4d7940_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/2436998042_4906ea07af.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14275234071_6e6f473356.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/7166554924_432aaae4b2_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/112428919_f0c5ad7d9d_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/17159349572_c0c51599f7_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/17862445825_f7031d6f26.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14487762578_baba13d16a_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/17907238905_1ae121f8d9_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/6931489544_2f35025f7b_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/3502251824_3be758edc6_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/17282288501_e8738c9cfb_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/4300258119_b03f2f956e.jpg\n","-------------------\n","/content/flowers/train/daisy\n","224 224 to 224 224 /content/flowers/train/daisy/2349640101_212c275aa7.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/7227973870_806d9d3e42_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/2488902131_3417698611_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/2538504987_fe524b92a8_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/9120905231_329598304e.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/367020749_3c9a652d75.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/43474673_7bb4465a86.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/4923279674_e7f8e70794_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/2556503265_63ae6b9e0e_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/7669550908_bc5a11276f_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/1286274236_1d7ac84efb_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/813445367_187ecf080a_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/8964198962_6d8593b533.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/4286053334_a75541f20b_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/8694909523_3ca25d449d_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3637428148_a1dcccafa9_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5876455546_32049e5585.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/1355787476_32e9f2a30b.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/2551708158_1f10e81e11.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/11834945233_a53b7a92ac_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/9175280426_40ecc395b8_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5110109540_beed4ed162_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/2632216904_274aa17433.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/695778683_890c46ebac.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3546455114_cd2dea5e02.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/6148728633_27afc47b0c_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5673728_71b8cb57eb.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5869147563_66fb88119d.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3975010332_3209f9f447_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3379332157_04724f6480.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/4890424315_6a59696357_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/144603918_b9de002f60_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5626895440_97a0ec04c2_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/9515186037_3be48fe68f.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/4561871220_47f420ca59_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/1656856503_447e5b0f03.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/162362897_1d21b70621_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/9922116524_ab4a2533fe_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3598615130_578ed30e5f.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5997702776_c7bc37aa6b_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/6776075110_1ea7a09dd4_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/2561371688_c80a4fe957_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/4544110929_a7de65d65f_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/538920244_59899a78f8_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/1285423653_18926dc2c8_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/512177035_70afc925c8.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/11870378973_2ec1919f12.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/2365428551_39f83f10bf_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5883162120_dc7274af76_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/391364010_4b0942d400_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/2454280135_ac3aa75cdc_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/7538403124_f2fc48750a.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/7629784968_b953501902_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3625257860_33efeef614_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/9204730092_a7f2182347.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5110105726_53eb7a93be_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/105806915_a9c13e2106_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/14073784469_ffb12f3387_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5881907044_92a85a05c8_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3084924076_4d5c5711af_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/14219214466_3ca6104eae_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/12701063955_4840594ea6_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5948835387_5a98d39eff_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/7702332000_3f21ef4571_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5586977262_6b24412805_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3474942718_c418dae6f1.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3717746329_53f515c6a6_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5110107234_12ddc0206b_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5885826924_38fdc6bcaa_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3713290261_8a66de23ab.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/799964360_7e07a227ea_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3780380240_ef9ec1b737_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/483886997_27ee798327.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/2331133004_582772d58f_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/7066602021_2647457985_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/517054467_d82d323c33_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/476857510_d2b30175de_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5794835_d15905c7c8_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3704305945_a80e60e2f6_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3963330924_6c6a3fa7be_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/2641979584_2b21c3fe29_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/9054268881_19792c5203_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/154332674_453cea64f4.jpg\n","-------------------\n","/content/flowers/test\n","-------------------\n","/content/flowers/test/tulip\n","224 224 to 224 224 /content/flowers/test/tulip/13910028149_6c9d5485ef.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/14053292975_fdc1093571_n.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/13529687904_3d60abb479_n.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/13513851673_9d813dc7b0.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/13562271714_d534531374.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/8723767533_9145dec4bd_n.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/13472393854_b2530f7029_n.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/13910737760_c71c8b6ff2.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/9870557734_88eb3b9e3b_n.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/12025042086_78bafc0eb6_n.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/12024561754_ce9667e4dc_n.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/8717900362_2aa508e9e5.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/13910131718_731353d84c_n.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/13910719110_1b21d1fc81.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/13530690445_9f1f5cf43a_n.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/8838347159_746d14e6c1_m.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/13514136074_ab1b827e4f.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/8768645961_8f1e097170_n.jpg\n","-------------------\n","/content/flowers/test/daisy\n","224 224 to 224 224 /content/flowers/test/daisy/14485782498_fb342ec301.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/14221836990_90374e6b34.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/21626652132_97e1318bb8_m.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/15784493690_b1858cdb2b_n.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/19544831049_0d738d4872_m.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/16161045294_70c76ce846_n.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/19280272025_57de24e940_m.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/14471433500_cdaa22e3ea_m.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/16819071290_471d99e166_m.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/16527403771_2391f137c4_n.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/20773528301_008fcbc5a1_n.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/19178753159_a471bf4b6b.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/14600779226_7bbc288d40_m.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/16401288243_36112bd52f_m.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/20580471306_ab5a011b15_n.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/18635898912_eb8e058ef0.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/14221848160_7f0a37c395.jpg\n","Found 165 images belonging to 2 classes.\n","Found 35 images belonging to 2 classes.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eCcMiRiMnPRY","executionInfo":{"status":"ok","timestamp":1638333587749,"user_tz":-540,"elapsed":418,"user":{"displayName":"HyunJae Na","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01248657443637565537"}},"outputId":"5a9cb2e0-0fdd-402a-e2f0-647b088ea819"},"source":["for image_batch, label_batch in train_data:\n","  print(\"Image batch shape: \", image_batch.shape)\n","  print(\"Label batch shape: \", label_batch.shape)\n","  label_set_count=label_batch.shape[1]\n","  break\n"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Image batch shape:  (64, 224, 224, 3)\n","Label batch shape:  (64, 2)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4dSSUhcfmJyU","executionInfo":{"status":"ok","timestamp":1638333703489,"user_tz":-540,"elapsed":55784,"user":{"displayName":"HyunJae Na","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01248657443637565537"}},"outputId":"06c62dd1-fff9-4516-a82e-b15341816f88"},"source":["from keras.applications.inception_v3 import InceptionV3\n","from keras.preprocessing import image\n","from keras.models import Model\n","from keras.layers import Dense, GlobalAveragePooling2D\n","from keras import backend as K\n","\n","# 선행학습된 기준모델을 만듭니다\n","base_model = InceptionV3(weights='imagenet', include_top=False)\n","\n","# 글로벌 공간 평균값 풀링 레이어를 더합니다\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","# 완전 연결 레이어를 더합니다\n","x = Dense(1024, activation='relu')(x)\n","# 로지스틱 레이어를 더합니다 -- 200가지 클래스가 있다고 가정합니다\n","predictions = Dense(label_set_count, activation='softmax')(x)\n","\n","# 다음은 학습할 모델입니다\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","# 첫째로: (난수로 초기값이 설정된) 가장 상위 레이어들만 학습시킵니다\n","# 다시 말해서 모든 InceptionV3 콘볼루션 레이어를 고정합니다\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# 모델을 컴파일합니다 (*꼭* 레이어를 학습불가 상태로 세팅하고난 *후*에 컴파일합니다)\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","\n","\n","# 모델을 새로운 데이터에 대해 몇 세대간 학습합니다\n","model.fit_generator(train_data, \n","                    validation_data=test_data, \n","                    validation_steps=8,\n","                    epochs=50\n",")"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87916544/87910968 [==============================] - 1s 0us/step\n","87924736/87910968 [==============================] - 1s 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","3/3 [==============================] - ETA: 0s - loss: 327.6520 - accuracy: 0.4788WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 8 batches). You may need to use the repeat() function when building your dataset.\n","3/3 [==============================] - 20s 2s/step - loss: 327.6520 - accuracy: 0.4788 - val_loss: 54.4965 - val_accuracy: 0.4857\n","Epoch 2/50\n","3/3 [==============================] - 1s 189ms/step - loss: 35.5246 - accuracy: 0.5394\n","Epoch 3/50\n","3/3 [==============================] - 1s 140ms/step - loss: 22.3948 - accuracy: 0.5394\n","Epoch 4/50\n","3/3 [==============================] - 1s 139ms/step - loss: 21.1054 - accuracy: 0.5394\n","Epoch 5/50\n","3/3 [==============================] - 1s 143ms/step - loss: 12.6726 - accuracy: 0.5515\n","Epoch 6/50\n","3/3 [==============================] - 1s 185ms/step - loss: 9.9751 - accuracy: 0.5697\n","Epoch 7/50\n","3/3 [==============================] - 1s 159ms/step - loss: 13.3273 - accuracy: 0.5152\n","Epoch 8/50\n","3/3 [==============================] - 1s 141ms/step - loss: 6.5070 - accuracy: 0.5879\n","Epoch 9/50\n","3/3 [==============================] - 1s 188ms/step - loss: 7.4468 - accuracy: 0.6182\n","Epoch 10/50\n","3/3 [==============================] - 1s 190ms/step - loss: 9.9220 - accuracy: 0.5636\n","Epoch 11/50\n","3/3 [==============================] - 1s 183ms/step - loss: 6.5863 - accuracy: 0.5818\n","Epoch 12/50\n","3/3 [==============================] - 1s 192ms/step - loss: 4.4316 - accuracy: 0.6788\n","Epoch 13/50\n","3/3 [==============================] - 1s 149ms/step - loss: 6.3467 - accuracy: 0.6303\n","Epoch 14/50\n","3/3 [==============================] - 1s 191ms/step - loss: 7.1018 - accuracy: 0.5939\n","Epoch 15/50\n","3/3 [==============================] - 1s 145ms/step - loss: 7.8291 - accuracy: 0.5455\n","Epoch 16/50\n","3/3 [==============================] - 1s 155ms/step - loss: 3.8704 - accuracy: 0.7091\n","Epoch 17/50\n","3/3 [==============================] - 1s 151ms/step - loss: 1.9279 - accuracy: 0.7576\n","Epoch 18/50\n","3/3 [==============================] - 1s 188ms/step - loss: 1.7565 - accuracy: 0.7697\n","Epoch 19/50\n","3/3 [==============================] - 1s 192ms/step - loss: 7.2549 - accuracy: 0.5939\n","Epoch 20/50\n","3/3 [==============================] - 1s 156ms/step - loss: 4.6078 - accuracy: 0.6606\n","Epoch 21/50\n","3/3 [==============================] - 1s 144ms/step - loss: 8.2311 - accuracy: 0.4970\n","Epoch 22/50\n","3/3 [==============================] - 1s 190ms/step - loss: 4.4160 - accuracy: 0.6909\n","Epoch 23/50\n","3/3 [==============================] - 1s 140ms/step - loss: 5.1645 - accuracy: 0.5394\n","Epoch 24/50\n","3/3 [==============================] - 1s 189ms/step - loss: 0.9919 - accuracy: 0.8121\n","Epoch 25/50\n","3/3 [==============================] - 1s 145ms/step - loss: 1.3293 - accuracy: 0.7576\n","Epoch 26/50\n","3/3 [==============================] - 1s 153ms/step - loss: 6.7966 - accuracy: 0.5818\n","Epoch 27/50\n","3/3 [==============================] - 1s 149ms/step - loss: 2.5173 - accuracy: 0.7333\n","Epoch 28/50\n","3/3 [==============================] - 1s 148ms/step - loss: 2.7165 - accuracy: 0.6727\n","Epoch 29/50\n","3/3 [==============================] - 1s 143ms/step - loss: 5.0172 - accuracy: 0.5818\n","Epoch 30/50\n","3/3 [==============================] - 1s 154ms/step - loss: 1.1623 - accuracy: 0.8000\n","Epoch 31/50\n","3/3 [==============================] - 1s 192ms/step - loss: 1.4460 - accuracy: 0.7515\n","Epoch 32/50\n","3/3 [==============================] - 1s 140ms/step - loss: 2.2791 - accuracy: 0.7091\n","Epoch 33/50\n","3/3 [==============================] - 1s 150ms/step - loss: 2.7044 - accuracy: 0.6424\n","Epoch 34/50\n","3/3 [==============================] - 1s 141ms/step - loss: 1.6620 - accuracy: 0.7515\n","Epoch 35/50\n","3/3 [==============================] - 1s 154ms/step - loss: 0.8650 - accuracy: 0.7939\n","Epoch 36/50\n","3/3 [==============================] - 1s 188ms/step - loss: 0.4902 - accuracy: 0.9212\n","Epoch 37/50\n","3/3 [==============================] - 1s 149ms/step - loss: 5.3210 - accuracy: 0.5697\n","Epoch 38/50\n","3/3 [==============================] - 1s 145ms/step - loss: 1.7728 - accuracy: 0.7152\n","Epoch 39/50\n","3/3 [==============================] - 1s 143ms/step - loss: 1.4153 - accuracy: 0.7152\n","Epoch 40/50\n","3/3 [==============================] - 1s 145ms/step - loss: 2.4702 - accuracy: 0.6545\n","Epoch 41/50\n","3/3 [==============================] - 1s 185ms/step - loss: 2.1814 - accuracy: 0.6545\n","Epoch 42/50\n","3/3 [==============================] - 1s 189ms/step - loss: 2.3258 - accuracy: 0.7091\n","Epoch 43/50\n","3/3 [==============================] - 1s 143ms/step - loss: 1.0112 - accuracy: 0.8000\n","Epoch 44/50\n","3/3 [==============================] - 1s 196ms/step - loss: 2.4153 - accuracy: 0.6848\n","Epoch 45/50\n","3/3 [==============================] - 1s 148ms/step - loss: 0.2580 - accuracy: 0.9273\n","Epoch 46/50\n","3/3 [==============================] - 1s 152ms/step - loss: 0.1858 - accuracy: 0.9394\n","Epoch 47/50\n","3/3 [==============================] - 1s 147ms/step - loss: 0.1432 - accuracy: 0.9576\n","Epoch 48/50\n","3/3 [==============================] - 1s 146ms/step - loss: 0.2878 - accuracy: 0.8970\n","Epoch 49/50\n","3/3 [==============================] - 1s 149ms/step - loss: 2.1361 - accuracy: 0.6970\n","Epoch 50/50\n","3/3 [==============================] - 1s 149ms/step - loss: 2.9587 - accuracy: 0.6848\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fc89a1131d0>"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tnO4HTLlp3L0","executionInfo":{"status":"ok","timestamp":1606883141544,"user_tz":-540,"elapsed":41119,"user":{"displayName":"남중구","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdjUdzM516IqW5OZZ8t6jU96Fd8d5gitHsvgLBeA=s64","userId":"04014122822541888792"}},"outputId":"dd8bd24b-1c26-462d-96c2-5eb1fa9cdee2"},"source":["score = model.evaluate_generator(test_data)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-7-815428d1b02e>:1: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use Model.evaluate, which supports generators.\n","Test loss: 1.8776918649673462\n","Test accuracy: 0.6571428775787354\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"slHsjoM6lWfb","executionInfo":{"status":"ok","timestamp":1606883141544,"user_tz":-540,"elapsed":41111,"user":{"displayName":"남중구","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdjUdzM516IqW5OZZ8t6jU96Fd8d5gitHsvgLBeA=s64","userId":"04014122822541888792"}},"outputId":"4901e653-ea46-47bd-8cc5-bfaed73dc8fc"},"source":["# 이 시점에서 상위 레이어들은 충분히 학습이 되었기에,\n","# inception V3의 콘볼루션 레이어에 대한 파인튜닝을 시작합니다 \n","# 가장 밑 N개의 레이어를 고정하고 나머지 상위 레이어를 학습시킵니다\n","\n","# 레이어 이름과 레이어 인덱스를 시각화하여\n","# 얼마나 많은 레이어를 고정시켜야 하는지 확인합니다:\n","for i, layer in enumerate(base_model.layers):\n","   print(i, layer.name)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 input_1\n","1 conv2d\n","2 batch_normalization\n","3 activation\n","4 conv2d_1\n","5 batch_normalization_1\n","6 activation_1\n","7 conv2d_2\n","8 batch_normalization_2\n","9 activation_2\n","10 max_pooling2d\n","11 conv2d_3\n","12 batch_normalization_3\n","13 activation_3\n","14 conv2d_4\n","15 batch_normalization_4\n","16 activation_4\n","17 max_pooling2d_1\n","18 conv2d_8\n","19 batch_normalization_8\n","20 activation_8\n","21 conv2d_6\n","22 conv2d_9\n","23 batch_normalization_6\n","24 batch_normalization_9\n","25 activation_6\n","26 activation_9\n","27 average_pooling2d\n","28 conv2d_5\n","29 conv2d_7\n","30 conv2d_10\n","31 conv2d_11\n","32 batch_normalization_5\n","33 batch_normalization_7\n","34 batch_normalization_10\n","35 batch_normalization_11\n","36 activation_5\n","37 activation_7\n","38 activation_10\n","39 activation_11\n","40 mixed0\n","41 conv2d_15\n","42 batch_normalization_15\n","43 activation_15\n","44 conv2d_13\n","45 conv2d_16\n","46 batch_normalization_13\n","47 batch_normalization_16\n","48 activation_13\n","49 activation_16\n","50 average_pooling2d_1\n","51 conv2d_12\n","52 conv2d_14\n","53 conv2d_17\n","54 conv2d_18\n","55 batch_normalization_12\n","56 batch_normalization_14\n","57 batch_normalization_17\n","58 batch_normalization_18\n","59 activation_12\n","60 activation_14\n","61 activation_17\n","62 activation_18\n","63 mixed1\n","64 conv2d_22\n","65 batch_normalization_22\n","66 activation_22\n","67 conv2d_20\n","68 conv2d_23\n","69 batch_normalization_20\n","70 batch_normalization_23\n","71 activation_20\n","72 activation_23\n","73 average_pooling2d_2\n","74 conv2d_19\n","75 conv2d_21\n","76 conv2d_24\n","77 conv2d_25\n","78 batch_normalization_19\n","79 batch_normalization_21\n","80 batch_normalization_24\n","81 batch_normalization_25\n","82 activation_19\n","83 activation_21\n","84 activation_24\n","85 activation_25\n","86 mixed2\n","87 conv2d_27\n","88 batch_normalization_27\n","89 activation_27\n","90 conv2d_28\n","91 batch_normalization_28\n","92 activation_28\n","93 conv2d_26\n","94 conv2d_29\n","95 batch_normalization_26\n","96 batch_normalization_29\n","97 activation_26\n","98 activation_29\n","99 max_pooling2d_2\n","100 mixed3\n","101 conv2d_34\n","102 batch_normalization_34\n","103 activation_34\n","104 conv2d_35\n","105 batch_normalization_35\n","106 activation_35\n","107 conv2d_31\n","108 conv2d_36\n","109 batch_normalization_31\n","110 batch_normalization_36\n","111 activation_31\n","112 activation_36\n","113 conv2d_32\n","114 conv2d_37\n","115 batch_normalization_32\n","116 batch_normalization_37\n","117 activation_32\n","118 activation_37\n","119 average_pooling2d_3\n","120 conv2d_30\n","121 conv2d_33\n","122 conv2d_38\n","123 conv2d_39\n","124 batch_normalization_30\n","125 batch_normalization_33\n","126 batch_normalization_38\n","127 batch_normalization_39\n","128 activation_30\n","129 activation_33\n","130 activation_38\n","131 activation_39\n","132 mixed4\n","133 conv2d_44\n","134 batch_normalization_44\n","135 activation_44\n","136 conv2d_45\n","137 batch_normalization_45\n","138 activation_45\n","139 conv2d_41\n","140 conv2d_46\n","141 batch_normalization_41\n","142 batch_normalization_46\n","143 activation_41\n","144 activation_46\n","145 conv2d_42\n","146 conv2d_47\n","147 batch_normalization_42\n","148 batch_normalization_47\n","149 activation_42\n","150 activation_47\n","151 average_pooling2d_4\n","152 conv2d_40\n","153 conv2d_43\n","154 conv2d_48\n","155 conv2d_49\n","156 batch_normalization_40\n","157 batch_normalization_43\n","158 batch_normalization_48\n","159 batch_normalization_49\n","160 activation_40\n","161 activation_43\n","162 activation_48\n","163 activation_49\n","164 mixed5\n","165 conv2d_54\n","166 batch_normalization_54\n","167 activation_54\n","168 conv2d_55\n","169 batch_normalization_55\n","170 activation_55\n","171 conv2d_51\n","172 conv2d_56\n","173 batch_normalization_51\n","174 batch_normalization_56\n","175 activation_51\n","176 activation_56\n","177 conv2d_52\n","178 conv2d_57\n","179 batch_normalization_52\n","180 batch_normalization_57\n","181 activation_52\n","182 activation_57\n","183 average_pooling2d_5\n","184 conv2d_50\n","185 conv2d_53\n","186 conv2d_58\n","187 conv2d_59\n","188 batch_normalization_50\n","189 batch_normalization_53\n","190 batch_normalization_58\n","191 batch_normalization_59\n","192 activation_50\n","193 activation_53\n","194 activation_58\n","195 activation_59\n","196 mixed6\n","197 conv2d_64\n","198 batch_normalization_64\n","199 activation_64\n","200 conv2d_65\n","201 batch_normalization_65\n","202 activation_65\n","203 conv2d_61\n","204 conv2d_66\n","205 batch_normalization_61\n","206 batch_normalization_66\n","207 activation_61\n","208 activation_66\n","209 conv2d_62\n","210 conv2d_67\n","211 batch_normalization_62\n","212 batch_normalization_67\n","213 activation_62\n","214 activation_67\n","215 average_pooling2d_6\n","216 conv2d_60\n","217 conv2d_63\n","218 conv2d_68\n","219 conv2d_69\n","220 batch_normalization_60\n","221 batch_normalization_63\n","222 batch_normalization_68\n","223 batch_normalization_69\n","224 activation_60\n","225 activation_63\n","226 activation_68\n","227 activation_69\n","228 mixed7\n","229 conv2d_72\n","230 batch_normalization_72\n","231 activation_72\n","232 conv2d_73\n","233 batch_normalization_73\n","234 activation_73\n","235 conv2d_70\n","236 conv2d_74\n","237 batch_normalization_70\n","238 batch_normalization_74\n","239 activation_70\n","240 activation_74\n","241 conv2d_71\n","242 conv2d_75\n","243 batch_normalization_71\n","244 batch_normalization_75\n","245 activation_71\n","246 activation_75\n","247 max_pooling2d_3\n","248 mixed8\n","249 conv2d_80\n","250 batch_normalization_80\n","251 activation_80\n","252 conv2d_77\n","253 conv2d_81\n","254 batch_normalization_77\n","255 batch_normalization_81\n","256 activation_77\n","257 activation_81\n","258 conv2d_78\n","259 conv2d_79\n","260 conv2d_82\n","261 conv2d_83\n","262 average_pooling2d_7\n","263 conv2d_76\n","264 batch_normalization_78\n","265 batch_normalization_79\n","266 batch_normalization_82\n","267 batch_normalization_83\n","268 conv2d_84\n","269 batch_normalization_76\n","270 activation_78\n","271 activation_79\n","272 activation_82\n","273 activation_83\n","274 batch_normalization_84\n","275 activation_76\n","276 mixed9_0\n","277 concatenate\n","278 activation_84\n","279 mixed9\n","280 conv2d_89\n","281 batch_normalization_89\n","282 activation_89\n","283 conv2d_86\n","284 conv2d_90\n","285 batch_normalization_86\n","286 batch_normalization_90\n","287 activation_86\n","288 activation_90\n","289 conv2d_87\n","290 conv2d_88\n","291 conv2d_91\n","292 conv2d_92\n","293 average_pooling2d_8\n","294 conv2d_85\n","295 batch_normalization_87\n","296 batch_normalization_88\n","297 batch_normalization_91\n","298 batch_normalization_92\n","299 conv2d_93\n","300 batch_normalization_85\n","301 activation_87\n","302 activation_88\n","303 activation_91\n","304 activation_92\n","305 batch_normalization_93\n","306 activation_85\n","307 mixed9_1\n","308 concatenate_1\n","309 activation_93\n","310 mixed10\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WIggcooulXez","executionInfo":{"status":"ok","timestamp":1638333803340,"user_tz":-540,"elapsed":2,"user":{"displayName":"HyunJae Na","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01248657443637565537"}}},"source":["# 가장 상위 2개의 inception 블록을 학습하기로 고릅니다,\n","# 다시 말하면 첫 249개의 레이어는 고정시키고 나머지는 고정하지 않습니다:\n","for layer in model.layers[:249]:\n","   layer.trainable = False\n","for layer in model.layers[249:]:\n","   layer.trainable = True\n","\n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_2XmZ3q0lYrF","executionInfo":{"status":"ok","timestamp":1638333881876,"user_tz":-540,"elapsed":69804,"user":{"displayName":"HyunJae Na","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01248657443637565537"}},"outputId":"aa1a3877-a76f-4d8d-a5f9-bf22496fad81"},"source":["# 이러한 수정사항이 효과를 내려면 모델을 다시 컴파일해야 합니다\n","# 낮은 학습 속도로 세팅된 SGD를 사용합니다\n","from tensorflow.keras.optimizers import SGD\n","model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","# 다시 한 번 모델을 학습시킵니다\n","# (이번엔 상위 2개의 inception 블록을 상위의 밀집 레이어들과 함께 파인튜닝합니다)\n","model.fit_generator(train_data, \n","                    validation_data=test_data, \n","                    validation_steps=8,\n","                    epochs=100\n",")"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(SGD, self).__init__(name, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","3/3 [==============================] - ETA: 0s - loss: 0.8890 - accuracy: 0.4970WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 8 batches). You may need to use the repeat() function when building your dataset.\n","3/3 [==============================] - 11s 1s/step - loss: 0.8890 - accuracy: 0.4970 - val_loss: 0.9199 - val_accuracy: 0.6000\n","Epoch 2/100\n","3/3 [==============================] - 1s 159ms/step - loss: 0.8799 - accuracy: 0.4970\n","Epoch 3/100\n","3/3 [==============================] - 1s 194ms/step - loss: 0.8540 - accuracy: 0.4970\n","Epoch 4/100\n","3/3 [==============================] - 1s 147ms/step - loss: 0.8332 - accuracy: 0.4970\n","Epoch 5/100\n","3/3 [==============================] - 1s 141ms/step - loss: 0.8026 - accuracy: 0.4970\n","Epoch 6/100\n","3/3 [==============================] - 1s 154ms/step - loss: 0.7718 - accuracy: 0.4970\n","Epoch 7/100\n","3/3 [==============================] - 1s 193ms/step - loss: 0.7478 - accuracy: 0.4970\n","Epoch 8/100\n","3/3 [==============================] - 1s 162ms/step - loss: 0.7364 - accuracy: 0.4970\n","Epoch 9/100\n","3/3 [==============================] - 1s 150ms/step - loss: 0.7128 - accuracy: 0.4970\n","Epoch 10/100\n","3/3 [==============================] - 1s 190ms/step - loss: 0.6889 - accuracy: 0.5091\n","Epoch 11/100\n","3/3 [==============================] - 1s 163ms/step - loss: 0.6752 - accuracy: 0.5273\n","Epoch 12/100\n","3/3 [==============================] - 1s 191ms/step - loss: 0.6630 - accuracy: 0.5152\n","Epoch 13/100\n","3/3 [==============================] - 1s 197ms/step - loss: 0.6524 - accuracy: 0.5394\n","Epoch 14/100\n","3/3 [==============================] - 1s 159ms/step - loss: 0.6445 - accuracy: 0.5576\n","Epoch 15/100\n","3/3 [==============================] - 1s 187ms/step - loss: 0.6277 - accuracy: 0.5879\n","Epoch 16/100\n","3/3 [==============================] - 1s 156ms/step - loss: 0.6220 - accuracy: 0.6121\n","Epoch 17/100\n","3/3 [==============================] - 1s 144ms/step - loss: 0.6138 - accuracy: 0.6242\n","Epoch 18/100\n","3/3 [==============================] - 1s 151ms/step - loss: 0.6074 - accuracy: 0.6485\n","Epoch 19/100\n","3/3 [==============================] - 1s 190ms/step - loss: 0.5998 - accuracy: 0.6788\n","Epoch 20/100\n","3/3 [==============================] - 1s 151ms/step - loss: 0.5980 - accuracy: 0.6848\n","Epoch 21/100\n","3/3 [==============================] - 1s 197ms/step - loss: 0.5887 - accuracy: 0.6848\n","Epoch 22/100\n","3/3 [==============================] - 1s 146ms/step - loss: 0.5860 - accuracy: 0.7212\n","Epoch 23/100\n","3/3 [==============================] - 1s 153ms/step - loss: 0.5804 - accuracy: 0.7212\n","Epoch 24/100\n","3/3 [==============================] - 1s 151ms/step - loss: 0.5752 - accuracy: 0.7394\n","Epoch 25/100\n","3/3 [==============================] - 1s 149ms/step - loss: 0.5721 - accuracy: 0.7576\n","Epoch 26/100\n","3/3 [==============================] - 1s 160ms/step - loss: 0.5753 - accuracy: 0.7697\n","Epoch 27/100\n","3/3 [==============================] - 1s 151ms/step - loss: 0.5628 - accuracy: 0.7758\n","Epoch 28/100\n","3/3 [==============================] - 1s 159ms/step - loss: 0.5612 - accuracy: 0.8000\n","Epoch 29/100\n","3/3 [==============================] - 1s 150ms/step - loss: 0.5570 - accuracy: 0.8121\n","Epoch 30/100\n","3/3 [==============================] - 1s 152ms/step - loss: 0.5495 - accuracy: 0.8182\n","Epoch 31/100\n","3/3 [==============================] - 1s 152ms/step - loss: 0.5495 - accuracy: 0.8303\n","Epoch 32/100\n","3/3 [==============================] - 1s 198ms/step - loss: 0.5403 - accuracy: 0.8606\n","Epoch 33/100\n","3/3 [==============================] - 1s 146ms/step - loss: 0.5366 - accuracy: 0.8424\n","Epoch 34/100\n","3/3 [==============================] - 1s 190ms/step - loss: 0.5347 - accuracy: 0.8485\n","Epoch 35/100\n","3/3 [==============================] - 1s 153ms/step - loss: 0.5368 - accuracy: 0.8485\n","Epoch 36/100\n","3/3 [==============================] - 1s 164ms/step - loss: 0.5500 - accuracy: 0.8061\n","Epoch 37/100\n","3/3 [==============================] - 1s 160ms/step - loss: 0.5193 - accuracy: 0.8667\n","Epoch 38/100\n","3/3 [==============================] - 1s 195ms/step - loss: 0.5163 - accuracy: 0.8788\n","Epoch 39/100\n","3/3 [==============================] - 1s 199ms/step - loss: 0.5124 - accuracy: 0.8606\n","Epoch 40/100\n","3/3 [==============================] - 1s 156ms/step - loss: 0.5058 - accuracy: 0.8848\n","Epoch 41/100\n","3/3 [==============================] - 1s 161ms/step - loss: 0.5090 - accuracy: 0.8788\n","Epoch 42/100\n","3/3 [==============================] - 1s 150ms/step - loss: 0.4996 - accuracy: 0.8848\n","Epoch 43/100\n","3/3 [==============================] - 1s 189ms/step - loss: 0.4967 - accuracy: 0.8545\n","Epoch 44/100\n","3/3 [==============================] - 1s 153ms/step - loss: 0.4864 - accuracy: 0.8970\n","Epoch 45/100\n","3/3 [==============================] - 1s 151ms/step - loss: 0.4808 - accuracy: 0.9030\n","Epoch 46/100\n","3/3 [==============================] - 1s 202ms/step - loss: 0.4952 - accuracy: 0.8727\n","Epoch 47/100\n","3/3 [==============================] - 1s 203ms/step - loss: 0.4725 - accuracy: 0.9030\n","Epoch 48/100\n","3/3 [==============================] - 1s 195ms/step - loss: 0.4671 - accuracy: 0.9212\n","Epoch 49/100\n","3/3 [==============================] - 1s 151ms/step - loss: 0.4678 - accuracy: 0.9091\n","Epoch 50/100\n","3/3 [==============================] - 1s 195ms/step - loss: 0.4720 - accuracy: 0.9152\n","Epoch 51/100\n","3/3 [==============================] - 1s 160ms/step - loss: 0.4640 - accuracy: 0.9030\n","Epoch 52/100\n","3/3 [==============================] - 1s 147ms/step - loss: 0.4433 - accuracy: 0.9030\n","Epoch 53/100\n","3/3 [==============================] - 1s 192ms/step - loss: 0.4454 - accuracy: 0.9152\n","Epoch 54/100\n","3/3 [==============================] - 1s 202ms/step - loss: 0.4397 - accuracy: 0.8970\n","Epoch 55/100\n","3/3 [==============================] - 1s 153ms/step - loss: 0.4387 - accuracy: 0.9030\n","Epoch 56/100\n","3/3 [==============================] - 1s 150ms/step - loss: 0.4277 - accuracy: 0.9212\n","Epoch 57/100\n","3/3 [==============================] - 1s 157ms/step - loss: 0.4280 - accuracy: 0.9273\n","Epoch 58/100\n","3/3 [==============================] - 1s 145ms/step - loss: 0.4263 - accuracy: 0.9273\n","Epoch 59/100\n","3/3 [==============================] - 1s 155ms/step - loss: 0.4205 - accuracy: 0.9030\n","Epoch 60/100\n","3/3 [==============================] - 1s 143ms/step - loss: 0.4071 - accuracy: 0.9152\n","Epoch 61/100\n","3/3 [==============================] - 1s 146ms/step - loss: 0.4042 - accuracy: 0.9394\n","Epoch 62/100\n","3/3 [==============================] - 1s 152ms/step - loss: 0.4100 - accuracy: 0.9212\n","Epoch 63/100\n","3/3 [==============================] - 1s 159ms/step - loss: 0.3973 - accuracy: 0.9394\n","Epoch 64/100\n","3/3 [==============================] - 1s 144ms/step - loss: 0.3902 - accuracy: 0.9394\n","Epoch 65/100\n","3/3 [==============================] - 1s 153ms/step - loss: 0.3888 - accuracy: 0.9455\n","Epoch 66/100\n","3/3 [==============================] - 1s 157ms/step - loss: 0.3869 - accuracy: 0.9394\n","Epoch 67/100\n","3/3 [==============================] - 1s 197ms/step - loss: 0.3713 - accuracy: 0.9455\n","Epoch 68/100\n","3/3 [==============================] - 1s 189ms/step - loss: 0.3786 - accuracy: 0.9212\n","Epoch 69/100\n","3/3 [==============================] - 1s 193ms/step - loss: 0.3730 - accuracy: 0.9273\n","Epoch 70/100\n","3/3 [==============================] - 1s 146ms/step - loss: 0.3592 - accuracy: 0.9394\n","Epoch 71/100\n","3/3 [==============================] - 1s 144ms/step - loss: 0.3723 - accuracy: 0.9455\n","Epoch 72/100\n","3/3 [==============================] - 1s 197ms/step - loss: 0.3581 - accuracy: 0.9455\n","Epoch 73/100\n","3/3 [==============================] - 1s 150ms/step - loss: 0.3899 - accuracy: 0.8909\n","Epoch 74/100\n","3/3 [==============================] - 1s 144ms/step - loss: 0.3462 - accuracy: 0.9394\n","Epoch 75/100\n","3/3 [==============================] - 1s 154ms/step - loss: 0.3361 - accuracy: 0.9515\n","Epoch 76/100\n","3/3 [==============================] - 1s 161ms/step - loss: 0.3512 - accuracy: 0.9394\n","Epoch 77/100\n","3/3 [==============================] - 1s 145ms/step - loss: 0.3439 - accuracy: 0.9455\n","Epoch 78/100\n","3/3 [==============================] - 1s 192ms/step - loss: 0.3303 - accuracy: 0.9394\n","Epoch 79/100\n","3/3 [==============================] - 1s 144ms/step - loss: 0.3241 - accuracy: 0.9576\n","Epoch 80/100\n","3/3 [==============================] - 1s 160ms/step - loss: 0.3132 - accuracy: 0.9636\n","Epoch 81/100\n","3/3 [==============================] - 1s 149ms/step - loss: 0.3107 - accuracy: 0.9576\n","Epoch 82/100\n","3/3 [==============================] - 1s 158ms/step - loss: 0.3239 - accuracy: 0.9515\n","Epoch 83/100\n","3/3 [==============================] - 1s 141ms/step - loss: 0.3188 - accuracy: 0.9455\n","Epoch 84/100\n","3/3 [==============================] - 1s 158ms/step - loss: 0.2965 - accuracy: 0.9636\n","Epoch 85/100\n","3/3 [==============================] - 1s 200ms/step - loss: 0.2982 - accuracy: 0.9636\n","Epoch 86/100\n","3/3 [==============================] - 1s 195ms/step - loss: 0.3100 - accuracy: 0.9697\n","Epoch 87/100\n","3/3 [==============================] - 1s 200ms/step - loss: 0.2908 - accuracy: 0.9758\n","Epoch 88/100\n","3/3 [==============================] - 1s 194ms/step - loss: 0.2875 - accuracy: 0.9636\n","Epoch 89/100\n","3/3 [==============================] - 1s 194ms/step - loss: 0.2854 - accuracy: 0.9697\n","Epoch 90/100\n","3/3 [==============================] - 1s 149ms/step - loss: 0.2831 - accuracy: 0.9697\n","Epoch 91/100\n","3/3 [==============================] - 1s 139ms/step - loss: 0.2731 - accuracy: 0.9758\n","Epoch 92/100\n","3/3 [==============================] - 1s 195ms/step - loss: 0.2708 - accuracy: 0.9879\n","Epoch 93/100\n","3/3 [==============================] - 1s 198ms/step - loss: 0.2779 - accuracy: 0.9576\n","Epoch 94/100\n","3/3 [==============================] - 1s 146ms/step - loss: 0.2714 - accuracy: 0.9636\n","Epoch 95/100\n","3/3 [==============================] - 1s 146ms/step - loss: 0.2547 - accuracy: 0.9758\n","Epoch 96/100\n","3/3 [==============================] - 1s 193ms/step - loss: 0.2859 - accuracy: 0.9394\n","Epoch 97/100\n","3/3 [==============================] - 1s 144ms/step - loss: 0.2448 - accuracy: 0.9758\n","Epoch 98/100\n","3/3 [==============================] - 1s 161ms/step - loss: 0.2385 - accuracy: 0.9758\n","Epoch 99/100\n","3/3 [==============================] - 1s 164ms/step - loss: 0.2505 - accuracy: 0.9758\n","Epoch 100/100\n","3/3 [==============================] - 1s 148ms/step - loss: 0.2335 - accuracy: 0.9758\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fc89a06cfd0>"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"svBRt1UBfFud","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638333891646,"user_tz":-540,"elapsed":457,"user":{"displayName":"HyunJae Na","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01248657443637565537"}},"outputId":"60772a0e-b16f-46b6-b11c-d7d97697d9b8"},"source":["score = model.evaluate_generator(test_data)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n","  \"\"\"Entry point for launching an IPython kernel.\n"]},{"output_type":"stream","name":"stdout","text":["Test loss: 0.5066385269165039\n","Test accuracy: 0.7428571581840515\n"]}]},{"cell_type":"code","metadata":{"id":"6-sd-HI5D2Zt"},"source":[""],"execution_count":null,"outputs":[]}]}