{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5.inception_v3_FineTuned_model_project.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"oyc4aqeDfBsq"},"source":["* 출처 : https://keras.io/ko/applications/\n"]},{"cell_type":"code","metadata":{"id":"Zag6rlkFlnW-"},"source":["# %%bash\n","# [ ! -f flower_photos_300x200_small_train_test2.zip ]&& wget https://raw.githubusercontent.com/Finfra/AI_Vision/master/data/flower_photos_300x200_small_train_test2.zip\n","\n","# rm -rf __MACOSX\n","# rm -rf flowers\n","# unzip -q flower_photos_300x200_small_train_test2.zip\n","# mv flower_photos_300x200_small_train_test2 flowers\n","\n","# cd flowers\n","\n","\n","# find .|grep .DS_Store|xargs rm -f\n","# find .|head -n 10\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aBH1bUWKXdB5"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4geQTUGBXgjJ","executionInfo":{"status":"ok","timestamp":1638334884253,"user_tz":-540,"elapsed":21009,"user":{"displayName":"HyunJae Na","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01248657443637565537"}},"outputId":"4450eb0c-5de8-4cd5-87fa-6cb7e52c9484"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1POOskuwXnwE","executionInfo":{"status":"ok","timestamp":1638334913933,"user_tz":-540,"elapsed":345,"user":{"displayName":"HyunJae Na","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01248657443637565537"}},"outputId":"5f115db7-10a5-44fb-a740-4b2305a59256"},"source":["!ls /content/drive/MyDrive/202111_ObjectDection_Kitri/Day2_SourceCode/DogAndCat"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["test  train\n"]}]},{"cell_type":"code","metadata":{"id":"P8CuInzImA_i","executionInfo":{"status":"ok","timestamp":1638335016544,"user_tz":-540,"elapsed":370,"user":{"displayName":"HyunJae Na","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01248657443637565537"}}},"source":["from os import listdir\n","from os.path import isfile, join, splitext\n","import cv2\n","def getFolder(thePath,isFile=True):\n","    return [f for f in listdir(thePath) if isFile == isfile(join(thePath, f)) ]\n","\n","def convert(thePath,to_w,to_h):\n","    ext=splitext(\".jpg\")[0]\n","    if ext in ('.jpg','.png'):\n","      img = cv2.imread(thePath)\n","      if (to_h,to_w,3) != img.shape :\n","        img = cv2.resize(img,(to_w,to_h))\n","        print(img.shape[0],img.shape[1],'to',to_w,to_h , thePath , )\n","        cv2.imwrite(thePath,img)\n","      # else:\n","      #   print(thePath,\"is not changed (same)\")\n","\n","def convertAll(tPath,to_w,to_h):\n","  for folder in getFolder(tPath,False):\n","    print('-------------------')\n","    print(join(tPath,folder))\n","    convertAll(join(tPath,folder),to_w,to_h)\n","  for files in getFolder(tPath,True):\n","      convert(join(tPath,files),to_w,to_h)\n","\n","\n","tPath='/content/drive/MyDrive/202111_ObjectDection_Kitri/Day2_SourceCode/DogAndCat'\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DKBf13FRlUrr","executionInfo":{"status":"ok","timestamp":1638335075127,"user_tz":-540,"elapsed":401,"user":{"displayName":"HyunJae Na","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01248657443637565537"}},"outputId":"53f8107e-ac3b-4c6e-b220-c2d9f220ed1b"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","w=224\n","h=224\n","color=3\n","\n","convertAll(tPath,w,h)\n","\n","\n","\n","# load and iterate training dataset\n","datagen = ImageDataGenerator()\n","train_data = datagen.flow_from_directory(directory='/content/drive/MyDrive/202111_ObjectDection_Kitri/Day2_SourceCode/DogAndCat/train/', class_mode='categorical', batch_size=64,target_size=(h, w))\n","# load and iterate test dataset\n","test_data = datagen.flow_from_directory(directory='/content/drive/MyDrive/202111_ObjectDection_Kitri/Day2_SourceCode/DogAndCat/test/',  class_mode='categorical', batch_size=64,target_size=(h,w))\n","\n"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["-------------------\n","/content/drive/MyDrive/202111_ObjectDection_Kitri/Day2_SourceCode/DogAndCat/train\n","-------------------\n","/content/drive/MyDrive/202111_ObjectDection_Kitri/Day2_SourceCode/DogAndCat/train/cat\n","-------------------\n","/content/drive/MyDrive/202111_ObjectDection_Kitri/Day2_SourceCode/DogAndCat/train/dog\n","-------------------\n","/content/drive/MyDrive/202111_ObjectDection_Kitri/Day2_SourceCode/DogAndCat/test\n","-------------------\n","/content/drive/MyDrive/202111_ObjectDection_Kitri/Day2_SourceCode/DogAndCat/test/cat\n","-------------------\n","/content/drive/MyDrive/202111_ObjectDection_Kitri/Day2_SourceCode/DogAndCat/test/dog\n","Found 16 images belonging to 2 classes.\n","Found 10 images belonging to 2 classes.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eCcMiRiMnPRY","executionInfo":{"status":"ok","timestamp":1638335405411,"user_tz":-540,"elapsed":393,"user":{"displayName":"HyunJae Na","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01248657443637565537"}},"outputId":"70c263f5-f6f6-4a6e-ca6a-deb1626b0211"},"source":["for image_batch, label_batch in train_data:\n","  print(\"Image batch shape: \", image_batch.shape)\n","  print(\"Label batch shape: \", label_batch.shape)\n","  label_set_count=label_batch.shape[1]\n","  break\n"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Image batch shape:  (16, 224, 224, 3)\n","Label batch shape:  (16, 2)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4dSSUhcfmJyU","executionInfo":{"status":"ok","timestamp":1638335435508,"user_tz":-540,"elapsed":24955,"user":{"displayName":"HyunJae Na","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01248657443637565537"}},"outputId":"862142a7-c668-45c3-d3b8-2faae9e481a2"},"source":["from keras.applications.inception_v3 import InceptionV3\n","from keras.preprocessing import image\n","from keras.models import Model\n","from keras.layers import Dense, GlobalAveragePooling2D\n","from keras import backend as K\n","\n","# 선행학습된 기준모델을 만듭니다\n","base_model = InceptionV3(weights='imagenet', include_top=False)\n","\n","# 글로벌 공간 평균값 풀링 레이어를 더합니다\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","# 완전 연결 레이어를 더합니다\n","x = Dense(1024, activation='relu')(x)\n","# 로지스틱 레이어를 더합니다 -- 200가지 클래스가 있다고 가정합니다\n","predictions = Dense(label_set_count, activation='softmax')(x)\n","\n","# 다음은 학습할 모델입니다\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","# 첫째로: (난수로 초기값이 설정된) 가장 상위 레이어들만 학습시킵니다\n","# 다시 말해서 모든 InceptionV3 콘볼루션 레이어를 고정합니다\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# 모델을 컴파일합니다 (*꼭* 레이어를 학습불가 상태로 세팅하고난 *후*에 컴파일합니다)\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","\n","\n","# 모델을 새로운 데이터에 대해 몇 세대간 학습합니다\n","model.fit_generator(train_data, \n","                    validation_data=test_data, \n","                    validation_steps=8,\n","                    epochs=50\n",")"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87916544/87910968 [==============================] - 0s 0us/step\n","87924736/87910968 [==============================] - 0s 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","1/1 [==============================] - ETA: 0s - loss: 25.5352 - accuracy: 0.5000WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 8 batches). You may need to use the repeat() function when building your dataset.\n","1/1 [==============================] - 14s 14s/step - loss: 25.5352 - accuracy: 0.5000 - val_loss: 623.8452 - val_accuracy: 0.5000\n","Epoch 2/50\n","1/1 [==============================] - 0s 93ms/step - loss: 662.5739 - accuracy: 0.5000\n","Epoch 3/50\n","1/1 [==============================] - 0s 92ms/step - loss: 148.6446 - accuracy: 0.5000\n","Epoch 4/50\n","1/1 [==============================] - 0s 93ms/step - loss: 46.9118 - accuracy: 0.5000\n","Epoch 5/50\n","1/1 [==============================] - 0s 94ms/step - loss: 63.4815 - accuracy: 0.5000\n","Epoch 6/50\n","1/1 [==============================] - 0s 89ms/step - loss: 24.7806 - accuracy: 0.5000\n","Epoch 7/50\n","1/1 [==============================] - 0s 90ms/step - loss: 40.5879 - accuracy: 0.5000\n","Epoch 8/50\n","1/1 [==============================] - 0s 100ms/step - loss: 13.3070 - accuracy: 0.6250\n","Epoch 9/50\n","1/1 [==============================] - 0s 89ms/step - loss: 13.7716 - accuracy: 0.6250\n","Epoch 10/50\n","1/1 [==============================] - 0s 90ms/step - loss: 10.5764 - accuracy: 0.6875\n","Epoch 11/50\n","1/1 [==============================] - 0s 90ms/step - loss: 9.5416 - accuracy: 0.6875\n","Epoch 12/50\n","1/1 [==============================] - 0s 97ms/step - loss: 6.1748 - accuracy: 0.7500\n","Epoch 13/50\n","1/1 [==============================] - 0s 91ms/step - loss: 8.0686 - accuracy: 0.7500\n","Epoch 14/50\n","1/1 [==============================] - 0s 91ms/step - loss: 2.4104 - accuracy: 0.8750\n","Epoch 15/50\n","1/1 [==============================] - 0s 95ms/step - loss: 1.6644 - accuracy: 0.9375\n","Epoch 16/50\n","1/1 [==============================] - 0s 92ms/step - loss: 0.3868 - accuracy: 0.9375\n","Epoch 17/50\n","1/1 [==============================] - 0s 90ms/step - loss: 0.7184 - accuracy: 0.9375\n","Epoch 18/50\n","1/1 [==============================] - 0s 97ms/step - loss: 0.5987 - accuracy: 0.9375\n","Epoch 19/50\n","1/1 [==============================] - 0s 89ms/step - loss: 9.7140e-05 - accuracy: 1.0000\n","Epoch 20/50\n","1/1 [==============================] - 0s 91ms/step - loss: 9.0139e-05 - accuracy: 1.0000\n","Epoch 21/50\n","1/1 [==============================] - 0s 90ms/step - loss: 8.3778e-05 - accuracy: 1.0000\n","Epoch 22/50\n","1/1 [==============================] - 0s 90ms/step - loss: 7.7989e-05 - accuracy: 1.0000\n","Epoch 23/50\n","1/1 [==============================] - 0s 108ms/step - loss: 7.2705e-05 - accuracy: 1.0000\n","Epoch 24/50\n","1/1 [==============================] - 0s 92ms/step - loss: 6.7861e-05 - accuracy: 1.0000\n","Epoch 25/50\n","1/1 [==============================] - 0s 100ms/step - loss: 6.3417e-05 - accuracy: 1.0000\n","Epoch 26/50\n","1/1 [==============================] - 0s 98ms/step - loss: 5.9331e-05 - accuracy: 1.0000\n","Epoch 27/50\n","1/1 [==============================] - 0s 92ms/step - loss: 5.5557e-05 - accuracy: 1.0000\n","Epoch 28/50\n","1/1 [==============================] - 0s 95ms/step - loss: 5.2073e-05 - accuracy: 1.0000\n","Epoch 29/50\n","1/1 [==============================] - 0s 91ms/step - loss: 4.8849e-05 - accuracy: 1.0000\n","Epoch 30/50\n","1/1 [==============================] - 0s 94ms/step - loss: 4.5864e-05 - accuracy: 1.0000\n","Epoch 31/50\n","1/1 [==============================] - 0s 93ms/step - loss: 4.3094e-05 - accuracy: 1.0000\n","Epoch 32/50\n","1/1 [==============================] - 0s 90ms/step - loss: 4.0518e-05 - accuracy: 1.0000\n","Epoch 33/50\n","1/1 [==============================] - 0s 92ms/step - loss: 3.8113e-05 - accuracy: 1.0000\n","Epoch 34/50\n","1/1 [==============================] - 0s 91ms/step - loss: 3.5879e-05 - accuracy: 1.0000\n","Epoch 35/50\n","1/1 [==============================] - 0s 93ms/step - loss: 3.3794e-05 - accuracy: 1.0000\n","Epoch 36/50\n","1/1 [==============================] - 0s 91ms/step - loss: 3.1851e-05 - accuracy: 1.0000\n","Epoch 37/50\n","1/1 [==============================] - 0s 93ms/step - loss: 3.0034e-05 - accuracy: 1.0000\n","Epoch 38/50\n","1/1 [==============================] - 0s 93ms/step - loss: 2.8328e-05 - accuracy: 1.0000\n","Epoch 39/50\n","1/1 [==============================] - 0s 95ms/step - loss: 2.6735e-05 - accuracy: 1.0000\n","Epoch 40/50\n","1/1 [==============================] - 0s 92ms/step - loss: 2.5253e-05 - accuracy: 1.0000\n","Epoch 41/50\n","1/1 [==============================] - 0s 98ms/step - loss: 2.3860e-05 - accuracy: 1.0000\n","Epoch 42/50\n","1/1 [==============================] - 0s 100ms/step - loss: 2.2549e-05 - accuracy: 1.0000\n","Epoch 43/50\n","1/1 [==============================] - 0s 92ms/step - loss: 2.1320e-05 - accuracy: 1.0000\n","Epoch 44/50\n","1/1 [==============================] - 0s 97ms/step - loss: 2.0166e-05 - accuracy: 1.0000\n","Epoch 45/50\n","1/1 [==============================] - 0s 92ms/step - loss: 1.9086e-05 - accuracy: 1.0000\n","Epoch 46/50\n","1/1 [==============================] - 0s 97ms/step - loss: 1.8065e-05 - accuracy: 1.0000\n","Epoch 47/50\n","1/1 [==============================] - 0s 95ms/step - loss: 1.7112e-05 - accuracy: 1.0000\n","Epoch 48/50\n","1/1 [==============================] - 0s 89ms/step - loss: 1.6210e-05 - accuracy: 1.0000\n","Epoch 49/50\n","1/1 [==============================] - 0s 91ms/step - loss: 1.5369e-05 - accuracy: 1.0000\n","Epoch 50/50\n","1/1 [==============================] - 0s 93ms/step - loss: 1.4564e-05 - accuracy: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f0b60498d10>"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tnO4HTLlp3L0","executionInfo":{"status":"ok","timestamp":1638335473101,"user_tz":-540,"elapsed":488,"user":{"displayName":"HyunJae Na","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01248657443637565537"}},"outputId":"4fefd25d-61d7-42b5-f652-d4a598a76d14"},"source":["score = model.evaluate_generator(test_data)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss: 13.611994743347168\n","Test accuracy: 0.6000000238418579\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n","  \"\"\"Entry point for launching an IPython kernel.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"slHsjoM6lWfb","executionInfo":{"status":"ok","timestamp":1638335481774,"user_tz":-540,"elapsed":370,"user":{"displayName":"HyunJae Na","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01248657443637565537"}},"outputId":"255d58d6-1e23-42f9-8af4-6a5f7d78838a"},"source":["# 이 시점에서 상위 레이어들은 충분히 학습이 되었기에,\n","# inception V3의 콘볼루션 레이어에 대한 파인튜닝을 시작합니다 \n","# 가장 밑 N개의 레이어를 고정하고 나머지 상위 레이어를 학습시킵니다\n","\n","# 레이어 이름과 레이어 인덱스를 시각화하여\n","# 얼마나 많은 레이어를 고정시켜야 하는지 확인합니다:\n","for i, layer in enumerate(base_model.layers):\n","   print(i, layer.name)\n","\n"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["0 input_1\n","1 conv2d\n","2 batch_normalization\n","3 activation\n","4 conv2d_1\n","5 batch_normalization_1\n","6 activation_1\n","7 conv2d_2\n","8 batch_normalization_2\n","9 activation_2\n","10 max_pooling2d\n","11 conv2d_3\n","12 batch_normalization_3\n","13 activation_3\n","14 conv2d_4\n","15 batch_normalization_4\n","16 activation_4\n","17 max_pooling2d_1\n","18 conv2d_8\n","19 batch_normalization_8\n","20 activation_8\n","21 conv2d_6\n","22 conv2d_9\n","23 batch_normalization_6\n","24 batch_normalization_9\n","25 activation_6\n","26 activation_9\n","27 average_pooling2d\n","28 conv2d_5\n","29 conv2d_7\n","30 conv2d_10\n","31 conv2d_11\n","32 batch_normalization_5\n","33 batch_normalization_7\n","34 batch_normalization_10\n","35 batch_normalization_11\n","36 activation_5\n","37 activation_7\n","38 activation_10\n","39 activation_11\n","40 mixed0\n","41 conv2d_15\n","42 batch_normalization_15\n","43 activation_15\n","44 conv2d_13\n","45 conv2d_16\n","46 batch_normalization_13\n","47 batch_normalization_16\n","48 activation_13\n","49 activation_16\n","50 average_pooling2d_1\n","51 conv2d_12\n","52 conv2d_14\n","53 conv2d_17\n","54 conv2d_18\n","55 batch_normalization_12\n","56 batch_normalization_14\n","57 batch_normalization_17\n","58 batch_normalization_18\n","59 activation_12\n","60 activation_14\n","61 activation_17\n","62 activation_18\n","63 mixed1\n","64 conv2d_22\n","65 batch_normalization_22\n","66 activation_22\n","67 conv2d_20\n","68 conv2d_23\n","69 batch_normalization_20\n","70 batch_normalization_23\n","71 activation_20\n","72 activation_23\n","73 average_pooling2d_2\n","74 conv2d_19\n","75 conv2d_21\n","76 conv2d_24\n","77 conv2d_25\n","78 batch_normalization_19\n","79 batch_normalization_21\n","80 batch_normalization_24\n","81 batch_normalization_25\n","82 activation_19\n","83 activation_21\n","84 activation_24\n","85 activation_25\n","86 mixed2\n","87 conv2d_27\n","88 batch_normalization_27\n","89 activation_27\n","90 conv2d_28\n","91 batch_normalization_28\n","92 activation_28\n","93 conv2d_26\n","94 conv2d_29\n","95 batch_normalization_26\n","96 batch_normalization_29\n","97 activation_26\n","98 activation_29\n","99 max_pooling2d_2\n","100 mixed3\n","101 conv2d_34\n","102 batch_normalization_34\n","103 activation_34\n","104 conv2d_35\n","105 batch_normalization_35\n","106 activation_35\n","107 conv2d_31\n","108 conv2d_36\n","109 batch_normalization_31\n","110 batch_normalization_36\n","111 activation_31\n","112 activation_36\n","113 conv2d_32\n","114 conv2d_37\n","115 batch_normalization_32\n","116 batch_normalization_37\n","117 activation_32\n","118 activation_37\n","119 average_pooling2d_3\n","120 conv2d_30\n","121 conv2d_33\n","122 conv2d_38\n","123 conv2d_39\n","124 batch_normalization_30\n","125 batch_normalization_33\n","126 batch_normalization_38\n","127 batch_normalization_39\n","128 activation_30\n","129 activation_33\n","130 activation_38\n","131 activation_39\n","132 mixed4\n","133 conv2d_44\n","134 batch_normalization_44\n","135 activation_44\n","136 conv2d_45\n","137 batch_normalization_45\n","138 activation_45\n","139 conv2d_41\n","140 conv2d_46\n","141 batch_normalization_41\n","142 batch_normalization_46\n","143 activation_41\n","144 activation_46\n","145 conv2d_42\n","146 conv2d_47\n","147 batch_normalization_42\n","148 batch_normalization_47\n","149 activation_42\n","150 activation_47\n","151 average_pooling2d_4\n","152 conv2d_40\n","153 conv2d_43\n","154 conv2d_48\n","155 conv2d_49\n","156 batch_normalization_40\n","157 batch_normalization_43\n","158 batch_normalization_48\n","159 batch_normalization_49\n","160 activation_40\n","161 activation_43\n","162 activation_48\n","163 activation_49\n","164 mixed5\n","165 conv2d_54\n","166 batch_normalization_54\n","167 activation_54\n","168 conv2d_55\n","169 batch_normalization_55\n","170 activation_55\n","171 conv2d_51\n","172 conv2d_56\n","173 batch_normalization_51\n","174 batch_normalization_56\n","175 activation_51\n","176 activation_56\n","177 conv2d_52\n","178 conv2d_57\n","179 batch_normalization_52\n","180 batch_normalization_57\n","181 activation_52\n","182 activation_57\n","183 average_pooling2d_5\n","184 conv2d_50\n","185 conv2d_53\n","186 conv2d_58\n","187 conv2d_59\n","188 batch_normalization_50\n","189 batch_normalization_53\n","190 batch_normalization_58\n","191 batch_normalization_59\n","192 activation_50\n","193 activation_53\n","194 activation_58\n","195 activation_59\n","196 mixed6\n","197 conv2d_64\n","198 batch_normalization_64\n","199 activation_64\n","200 conv2d_65\n","201 batch_normalization_65\n","202 activation_65\n","203 conv2d_61\n","204 conv2d_66\n","205 batch_normalization_61\n","206 batch_normalization_66\n","207 activation_61\n","208 activation_66\n","209 conv2d_62\n","210 conv2d_67\n","211 batch_normalization_62\n","212 batch_normalization_67\n","213 activation_62\n","214 activation_67\n","215 average_pooling2d_6\n","216 conv2d_60\n","217 conv2d_63\n","218 conv2d_68\n","219 conv2d_69\n","220 batch_normalization_60\n","221 batch_normalization_63\n","222 batch_normalization_68\n","223 batch_normalization_69\n","224 activation_60\n","225 activation_63\n","226 activation_68\n","227 activation_69\n","228 mixed7\n","229 conv2d_72\n","230 batch_normalization_72\n","231 activation_72\n","232 conv2d_73\n","233 batch_normalization_73\n","234 activation_73\n","235 conv2d_70\n","236 conv2d_74\n","237 batch_normalization_70\n","238 batch_normalization_74\n","239 activation_70\n","240 activation_74\n","241 conv2d_71\n","242 conv2d_75\n","243 batch_normalization_71\n","244 batch_normalization_75\n","245 activation_71\n","246 activation_75\n","247 max_pooling2d_3\n","248 mixed8\n","249 conv2d_80\n","250 batch_normalization_80\n","251 activation_80\n","252 conv2d_77\n","253 conv2d_81\n","254 batch_normalization_77\n","255 batch_normalization_81\n","256 activation_77\n","257 activation_81\n","258 conv2d_78\n","259 conv2d_79\n","260 conv2d_82\n","261 conv2d_83\n","262 average_pooling2d_7\n","263 conv2d_76\n","264 batch_normalization_78\n","265 batch_normalization_79\n","266 batch_normalization_82\n","267 batch_normalization_83\n","268 conv2d_84\n","269 batch_normalization_76\n","270 activation_78\n","271 activation_79\n","272 activation_82\n","273 activation_83\n","274 batch_normalization_84\n","275 activation_76\n","276 mixed9_0\n","277 concatenate\n","278 activation_84\n","279 mixed9\n","280 conv2d_89\n","281 batch_normalization_89\n","282 activation_89\n","283 conv2d_86\n","284 conv2d_90\n","285 batch_normalization_86\n","286 batch_normalization_90\n","287 activation_86\n","288 activation_90\n","289 conv2d_87\n","290 conv2d_88\n","291 conv2d_91\n","292 conv2d_92\n","293 average_pooling2d_8\n","294 conv2d_85\n","295 batch_normalization_87\n","296 batch_normalization_88\n","297 batch_normalization_91\n","298 batch_normalization_92\n","299 conv2d_93\n","300 batch_normalization_85\n","301 activation_87\n","302 activation_88\n","303 activation_91\n","304 activation_92\n","305 batch_normalization_93\n","306 activation_85\n","307 mixed9_1\n","308 concatenate_1\n","309 activation_93\n","310 mixed10\n"]}]},{"cell_type":"code","metadata":{"id":"WIggcooulXez","executionInfo":{"status":"ok","timestamp":1638335486524,"user_tz":-540,"elapsed":379,"user":{"displayName":"HyunJae Na","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01248657443637565537"}}},"source":["# 가장 상위 2개의 inception 블록을 학습하기로 고릅니다,\n","# 다시 말하면 첫 249개의 레이어는 고정시키고 나머지는 고정하지 않습니다:\n","for layer in model.layers[:249]:\n","   layer.trainable = False\n","for layer in model.layers[249:]:\n","   layer.trainable = True\n","\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_2XmZ3q0lYrF","executionInfo":{"status":"ok","timestamp":1638335505758,"user_tz":-540,"elapsed":17828,"user":{"displayName":"HyunJae Na","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01248657443637565537"}},"outputId":"c25fbc3a-866e-402e-e534-cb7b05e6c393"},"source":["# 이러한 수정사항이 효과를 내려면 모델을 다시 컴파일해야 합니다\n","# 낮은 학습 속도로 세팅된 SGD를 사용합니다\n","from tensorflow.keras.optimizers import SGD\n","model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","# 다시 한 번 모델을 학습시킵니다\n","# (이번엔 상위 2개의 inception 블록을 상위의 밀집 레이어들과 함께 파인튜닝합니다)\n","model.fit_generator(train_data, \n","                    validation_data=test_data, \n","                    validation_steps=8,\n","                    epochs=100\n",")"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(SGD, self).__init__(name, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1/1 [==============================] - ETA: 0s - loss: 0.7498 - accuracy: 0.5625WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 8 batches). You may need to use the repeat() function when building your dataset.\n","1/1 [==============================] - 6s 6s/step - loss: 0.7498 - accuracy: 0.5625 - val_loss: 2.4999 - val_accuracy: 0.5000\n","Epoch 2/100\n","1/1 [==============================] - 0s 98ms/step - loss: 0.7426 - accuracy: 0.5625\n","Epoch 3/100\n","1/1 [==============================] - 0s 95ms/step - loss: 0.7292 - accuracy: 0.5625\n","Epoch 4/100\n","1/1 [==============================] - 0s 102ms/step - loss: 0.7105 - accuracy: 0.5625\n","Epoch 5/100\n","1/1 [==============================] - 0s 101ms/step - loss: 0.6876 - accuracy: 0.5625\n","Epoch 6/100\n","1/1 [==============================] - 0s 102ms/step - loss: 0.6616 - accuracy: 0.6250\n","Epoch 7/100\n","1/1 [==============================] - 0s 106ms/step - loss: 0.6336 - accuracy: 0.6250\n","Epoch 8/100\n","1/1 [==============================] - 0s 98ms/step - loss: 0.6042 - accuracy: 0.6250\n","Epoch 9/100\n","1/1 [==============================] - 0s 101ms/step - loss: 0.5744 - accuracy: 0.6875\n","Epoch 10/100\n","1/1 [==============================] - 0s 95ms/step - loss: 0.5445 - accuracy: 0.7500\n","Epoch 11/100\n","1/1 [==============================] - 0s 95ms/step - loss: 0.5153 - accuracy: 0.7500\n","Epoch 12/100\n","1/1 [==============================] - 0s 103ms/step - loss: 0.4873 - accuracy: 0.8125\n","Epoch 13/100\n","1/1 [==============================] - 0s 98ms/step - loss: 0.4610 - accuracy: 0.8125\n","Epoch 14/100\n","1/1 [==============================] - 0s 94ms/step - loss: 0.4359 - accuracy: 0.8750\n","Epoch 15/100\n","1/1 [==============================] - 0s 94ms/step - loss: 0.4127 - accuracy: 0.8750\n","Epoch 16/100\n","1/1 [==============================] - 0s 109ms/step - loss: 0.3913 - accuracy: 0.8750\n","Epoch 17/100\n","1/1 [==============================] - 0s 98ms/step - loss: 0.3713 - accuracy: 0.8750\n","Epoch 18/100\n","1/1 [==============================] - 0s 97ms/step - loss: 0.3529 - accuracy: 0.8750\n","Epoch 19/100\n","1/1 [==============================] - 0s 95ms/step - loss: 0.3359 - accuracy: 0.9375\n","Epoch 20/100\n","1/1 [==============================] - 0s 100ms/step - loss: 0.3202 - accuracy: 1.0000\n","Epoch 21/100\n","1/1 [==============================] - 0s 104ms/step - loss: 0.3059 - accuracy: 1.0000\n","Epoch 22/100\n","1/1 [==============================] - 0s 99ms/step - loss: 0.2927 - accuracy: 1.0000\n","Epoch 23/100\n","1/1 [==============================] - 0s 95ms/step - loss: 0.2806 - accuracy: 1.0000\n","Epoch 24/100\n","1/1 [==============================] - 0s 98ms/step - loss: 0.2695 - accuracy: 1.0000\n","Epoch 25/100\n","1/1 [==============================] - 0s 98ms/step - loss: 0.2593 - accuracy: 1.0000\n","Epoch 26/100\n","1/1 [==============================] - 0s 97ms/step - loss: 0.2500 - accuracy: 1.0000\n","Epoch 27/100\n","1/1 [==============================] - 0s 96ms/step - loss: 0.2412 - accuracy: 1.0000\n","Epoch 28/100\n","1/1 [==============================] - 0s 97ms/step - loss: 0.2331 - accuracy: 1.0000\n","Epoch 29/100\n","1/1 [==============================] - 0s 96ms/step - loss: 0.2255 - accuracy: 1.0000\n","Epoch 30/100\n","1/1 [==============================] - 0s 102ms/step - loss: 0.2184 - accuracy: 1.0000\n","Epoch 31/100\n","1/1 [==============================] - 0s 96ms/step - loss: 0.2117 - accuracy: 1.0000\n","Epoch 32/100\n","1/1 [==============================] - 0s 93ms/step - loss: 0.2055 - accuracy: 1.0000\n","Epoch 33/100\n","1/1 [==============================] - 0s 100ms/step - loss: 0.1997 - accuracy: 1.0000\n","Epoch 34/100\n","1/1 [==============================] - 0s 100ms/step - loss: 0.1942 - accuracy: 1.0000\n","Epoch 35/100\n","1/1 [==============================] - 0s 108ms/step - loss: 0.1891 - accuracy: 1.0000\n","Epoch 36/100\n","1/1 [==============================] - 0s 101ms/step - loss: 0.1842 - accuracy: 1.0000\n","Epoch 37/100\n","1/1 [==============================] - 0s 95ms/step - loss: 0.1796 - accuracy: 1.0000\n","Epoch 38/100\n","1/1 [==============================] - 0s 96ms/step - loss: 0.1752 - accuracy: 1.0000\n","Epoch 39/100\n","1/1 [==============================] - 0s 99ms/step - loss: 0.1711 - accuracy: 1.0000\n","Epoch 40/100\n","1/1 [==============================] - 0s 95ms/step - loss: 0.1671 - accuracy: 1.0000\n","Epoch 41/100\n","1/1 [==============================] - 0s 94ms/step - loss: 0.1633 - accuracy: 1.0000\n","Epoch 42/100\n","1/1 [==============================] - 0s 99ms/step - loss: 0.1597 - accuracy: 1.0000\n","Epoch 43/100\n","1/1 [==============================] - 0s 97ms/step - loss: 0.1562 - accuracy: 1.0000\n","Epoch 44/100\n","1/1 [==============================] - 0s 94ms/step - loss: 0.1529 - accuracy: 1.0000\n","Epoch 45/100\n","1/1 [==============================] - 0s 95ms/step - loss: 0.1497 - accuracy: 1.0000\n","Epoch 46/100\n","1/1 [==============================] - 0s 101ms/step - loss: 0.1467 - accuracy: 1.0000\n","Epoch 47/100\n","1/1 [==============================] - 0s 98ms/step - loss: 0.1438 - accuracy: 1.0000\n","Epoch 48/100\n","1/1 [==============================] - 0s 95ms/step - loss: 0.1411 - accuracy: 1.0000\n","Epoch 49/100\n","1/1 [==============================] - 0s 98ms/step - loss: 0.1384 - accuracy: 1.0000\n","Epoch 50/100\n","1/1 [==============================] - 0s 97ms/step - loss: 0.1358 - accuracy: 1.0000\n","Epoch 51/100\n","1/1 [==============================] - 0s 101ms/step - loss: 0.1334 - accuracy: 1.0000\n","Epoch 52/100\n","1/1 [==============================] - 0s 95ms/step - loss: 0.1310 - accuracy: 1.0000\n","Epoch 53/100\n","1/1 [==============================] - 0s 97ms/step - loss: 0.1287 - accuracy: 1.0000\n","Epoch 54/100\n","1/1 [==============================] - 0s 97ms/step - loss: 0.1265 - accuracy: 1.0000\n","Epoch 55/100\n","1/1 [==============================] - 0s 97ms/step - loss: 0.1244 - accuracy: 1.0000\n","Epoch 56/100\n","1/1 [==============================] - 0s 96ms/step - loss: 0.1223 - accuracy: 1.0000\n","Epoch 57/100\n","1/1 [==============================] - 0s 98ms/step - loss: 0.1203 - accuracy: 1.0000\n","Epoch 58/100\n","1/1 [==============================] - 0s 99ms/step - loss: 0.1184 - accuracy: 1.0000\n","Epoch 59/100\n","1/1 [==============================] - 0s 94ms/step - loss: 0.1165 - accuracy: 1.0000\n","Epoch 60/100\n","1/1 [==============================] - 0s 103ms/step - loss: 0.1148 - accuracy: 1.0000\n","Epoch 61/100\n","1/1 [==============================] - 0s 96ms/step - loss: 0.1130 - accuracy: 1.0000\n","Epoch 62/100\n","1/1 [==============================] - 0s 100ms/step - loss: 0.1113 - accuracy: 1.0000\n","Epoch 63/100\n","1/1 [==============================] - 0s 99ms/step - loss: 0.1097 - accuracy: 1.0000\n","Epoch 64/100\n","1/1 [==============================] - 0s 98ms/step - loss: 0.1081 - accuracy: 1.0000\n","Epoch 65/100\n","1/1 [==============================] - 0s 99ms/step - loss: 0.1065 - accuracy: 1.0000\n","Epoch 66/100\n","1/1 [==============================] - 0s 96ms/step - loss: 0.1050 - accuracy: 1.0000\n","Epoch 67/100\n","1/1 [==============================] - 0s 99ms/step - loss: 0.1036 - accuracy: 1.0000\n","Epoch 68/100\n","1/1 [==============================] - 0s 97ms/step - loss: 0.1022 - accuracy: 1.0000\n","Epoch 69/100\n","1/1 [==============================] - 0s 95ms/step - loss: 0.1008 - accuracy: 1.0000\n","Epoch 70/100\n","1/1 [==============================] - 0s 97ms/step - loss: 0.0994 - accuracy: 1.0000\n","Epoch 71/100\n","1/1 [==============================] - 0s 98ms/step - loss: 0.0981 - accuracy: 1.0000\n","Epoch 72/100\n","1/1 [==============================] - 0s 100ms/step - loss: 0.0968 - accuracy: 1.0000\n","Epoch 73/100\n","1/1 [==============================] - 0s 97ms/step - loss: 0.0956 - accuracy: 1.0000\n","Epoch 74/100\n","1/1 [==============================] - 0s 100ms/step - loss: 0.0943 - accuracy: 1.0000\n","Epoch 75/100\n","1/1 [==============================] - 0s 94ms/step - loss: 0.0932 - accuracy: 1.0000\n","Epoch 76/100\n","1/1 [==============================] - 0s 95ms/step - loss: 0.0920 - accuracy: 1.0000\n","Epoch 77/100\n","1/1 [==============================] - 0s 96ms/step - loss: 0.0909 - accuracy: 1.0000\n","Epoch 78/100\n","1/1 [==============================] - 0s 96ms/step - loss: 0.0898 - accuracy: 1.0000\n","Epoch 79/100\n","1/1 [==============================] - 0s 97ms/step - loss: 0.0887 - accuracy: 1.0000\n","Epoch 80/100\n","1/1 [==============================] - 0s 98ms/step - loss: 0.0877 - accuracy: 1.0000\n","Epoch 81/100\n","1/1 [==============================] - 0s 95ms/step - loss: 0.0866 - accuracy: 1.0000\n","Epoch 82/100\n","1/1 [==============================] - 0s 98ms/step - loss: 0.0856 - accuracy: 1.0000\n","Epoch 83/100\n","1/1 [==============================] - 0s 111ms/step - loss: 0.0846 - accuracy: 1.0000\n","Epoch 84/100\n","1/1 [==============================] - 0s 103ms/step - loss: 0.0837 - accuracy: 1.0000\n","Epoch 85/100\n","1/1 [==============================] - 0s 100ms/step - loss: 0.0827 - accuracy: 1.0000\n","Epoch 86/100\n","1/1 [==============================] - 0s 107ms/step - loss: 0.0818 - accuracy: 1.0000\n","Epoch 87/100\n","1/1 [==============================] - 0s 104ms/step - loss: 0.0809 - accuracy: 1.0000\n","Epoch 88/100\n","1/1 [==============================] - 0s 101ms/step - loss: 0.0800 - accuracy: 1.0000\n","Epoch 89/100\n","1/1 [==============================] - 0s 96ms/step - loss: 0.0792 - accuracy: 1.0000\n","Epoch 90/100\n","1/1 [==============================] - 0s 111ms/step - loss: 0.0783 - accuracy: 1.0000\n","Epoch 91/100\n","1/1 [==============================] - 0s 111ms/step - loss: 0.0775 - accuracy: 1.0000\n","Epoch 92/100\n","1/1 [==============================] - 0s 105ms/step - loss: 0.0766 - accuracy: 1.0000\n","Epoch 93/100\n","1/1 [==============================] - 0s 103ms/step - loss: 0.0758 - accuracy: 1.0000\n","Epoch 94/100\n","1/1 [==============================] - 0s 113ms/step - loss: 0.0750 - accuracy: 1.0000\n","Epoch 95/100\n","1/1 [==============================] - 0s 102ms/step - loss: 0.0743 - accuracy: 1.0000\n","Epoch 96/100\n","1/1 [==============================] - 0s 106ms/step - loss: 0.0735 - accuracy: 1.0000\n","Epoch 97/100\n","1/1 [==============================] - 0s 103ms/step - loss: 0.0728 - accuracy: 1.0000\n","Epoch 98/100\n","1/1 [==============================] - 0s 101ms/step - loss: 0.0720 - accuracy: 1.0000\n","Epoch 99/100\n","1/1 [==============================] - 0s 102ms/step - loss: 0.0713 - accuracy: 1.0000\n","Epoch 100/100\n","1/1 [==============================] - 0s 99ms/step - loss: 0.0706 - accuracy: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f0a621a0190>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"svBRt1UBfFud","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638335510897,"user_tz":-540,"elapsed":358,"user":{"displayName":"HyunJae Na","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01248657443637565537"}},"outputId":"2691b641-d803-43ad-f9dd-69e95cdf8111"},"source":["score = model.evaluate_generator(test_data)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss: 0.665062427520752\n","Test accuracy: 0.6000000238418579\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n","  \"\"\"Entry point for launching an IPython kernel.\n"]}]},{"cell_type":"code","metadata":{"id":"6-sd-HI5D2Zt"},"source":[""],"execution_count":null,"outputs":[]}]}