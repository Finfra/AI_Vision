{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"inception_v3_FineTuned_model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPklktI5KN7dl4Yok2l/m+8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"oyc4aqeDfBsq"},"source":["* 출처 : https://keras.io/ko/applications/\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zag6rlkFlnW-","executionInfo":{"status":"ok","timestamp":1606883582829,"user_tz":-540,"elapsed":707,"user":{"displayName":"남중구","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdjUdzM516IqW5OZZ8t6jU96Fd8d5gitHsvgLBeA=s64","userId":"04014122822541888792"}},"outputId":"21a4c423-bb30-432f-fb63-2361bd362176"},"source":["%%bash\n","[ ! -f flower_photos_300x200_small_train_test2.zip ]&& wget https://raw.githubusercontent.com/Finfra/AI_Vision/master/data/flower_photos_300x200_small_train_test2.zip\n","\n","rm -rf __MACOSX\n","rm -rf flowers\n","unzip -q flower_photos_300x200_small_train_test2.zip\n","mv flower_photos_300x200_small_train_test2 flowers\n","\n","cd flowers\n","\n","\n","find .|grep .DS_Store|xargs rm -f\n","find .|head -n 10\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":[".\n","./test\n","./test/tulip\n","./test/tulip/13529687904_3d60abb479_n.jpg\n","./test/tulip/13530690445_9f1f5cf43a_n.jpg\n","./test/tulip/12025042086_78bafc0eb6_n.jpg\n","./test/tulip/13513851673_9d813dc7b0.jpg\n","./test/tulip/13514136074_ab1b827e4f.jpg\n","./test/tulip/13910737760_c71c8b6ff2.jpg\n","./test/tulip/12024561754_ce9667e4dc_n.jpg\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P8CuInzImA_i","executionInfo":{"status":"ok","timestamp":1606883102405,"user_tz":-540,"elapsed":2005,"user":{"displayName":"남중구","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdjUdzM516IqW5OZZ8t6jU96Fd8d5gitHsvgLBeA=s64","userId":"04014122822541888792"}}},"source":["from os import listdir\n","from os.path import isfile, join, splitext\n","import cv2\n","def getFolder(thePath,isFile=True):\n","    return [f for f in listdir(thePath) if isFile == isfile(join(thePath, f)) ]\n","\n","def convert(thePath,to_w,to_h):\n","    ext=splitext(\".jpg\")[0]\n","    if ext in ('.jpg','.png'):\n","      img = cv2.imread(thePath)\n","      if (to_h,to_w,3) != img.shape :\n","        img = cv2.resize(img,(to_w,to_h))\n","        print(img.shape[0],img.shape[1],'to',to_w,to_h , thePath , )\n","        cv2.imwrite(thePath,img)\n","      # else:\n","      #   print(thePath,\"is not changed (same)\")\n","\n","def convertAll(tPath,to_w,to_h):\n","  for folder in getFolder(tPath,False):\n","    print('-------------------')\n","    print(join(tPath,folder))\n","    convertAll(join(tPath,folder),to_w,to_h)\n","  for files in getFolder(tPath,True):\n","      convert(join(tPath,files),to_w,to_h)\n","\n","\n","tPath='/content/flowers/'\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DKBf13FRlUrr","executionInfo":{"status":"ok","timestamp":1606883103611,"user_tz":-540,"elapsed":3208,"user":{"displayName":"남중구","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdjUdzM516IqW5OZZ8t6jU96Fd8d5gitHsvgLBeA=s64","userId":"04014122822541888792"}},"outputId":"e81ad8d1-b577-4d6a-c7e9-f4db21e7abba"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","w=224\n","h=224\n","color=3\n","\n","convertAll(tPath,w,h)\n","\n","\n","\n","# load and iterate training dataset\n","datagen = ImageDataGenerator()\n","train_data = datagen.flow_from_directory(directory='flowers/train/', class_mode='categorical', batch_size=64,target_size=(h, w))\n","# load and iterate test dataset\n","test_data = datagen.flow_from_directory(directory='flowers/test/',  class_mode='categorical', batch_size=64,target_size=(h,w))\n","\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["-------------------\n","/content/flowers/test\n","-------------------\n","/content/flowers/test/tulip\n","224 224 to 224 224 /content/flowers/test/tulip/13529687904_3d60abb479_n.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/13530690445_9f1f5cf43a_n.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/12025042086_78bafc0eb6_n.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/13513851673_9d813dc7b0.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/13514136074_ab1b827e4f.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/13910737760_c71c8b6ff2.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/12024561754_ce9667e4dc_n.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/13910028149_6c9d5485ef.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/8838347159_746d14e6c1_m.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/13910131718_731353d84c_n.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/13472393854_b2530f7029_n.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/8723767533_9145dec4bd_n.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/13562271714_d534531374.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/14053292975_fdc1093571_n.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/9870557734_88eb3b9e3b_n.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/8768645961_8f1e097170_n.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/8717900362_2aa508e9e5.jpg\n","224 224 to 224 224 /content/flowers/test/tulip/13910719110_1b21d1fc81.jpg\n","-------------------\n","/content/flowers/test/daisy\n","224 224 to 224 224 /content/flowers/test/daisy/16401288243_36112bd52f_m.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/20580471306_ab5a011b15_n.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/18635898912_eb8e058ef0.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/14471433500_cdaa22e3ea_m.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/20773528301_008fcbc5a1_n.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/21626652132_97e1318bb8_m.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/15784493690_b1858cdb2b_n.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/19280272025_57de24e940_m.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/16819071290_471d99e166_m.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/16527403771_2391f137c4_n.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/14600779226_7bbc288d40_m.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/14221836990_90374e6b34.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/14221848160_7f0a37c395.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/19178753159_a471bf4b6b.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/19544831049_0d738d4872_m.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/16161045294_70c76ce846_n.jpg\n","224 224 to 224 224 /content/flowers/test/daisy/14485782498_fb342ec301.jpg\n","-------------------\n","/content/flowers/train\n","-------------------\n","/content/flowers/train/tulip\n","224 224 to 224 224 /content/flowers/train/tulip/17862445825_f7031d6f26.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/8687675254_c93f50d8b0_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/17282288501_e8738c9cfb_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/5552198702_35856ed8ec.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/6998661030_46cbb7892a.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/17408197905_829c4d7940_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/8454719295_4276c0e9c5_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/4599815420_8ee42c2382.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/4300258119_b03f2f956e.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/8681825637_837a63513a_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14487762578_baba13d16a_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/8713390684_041148dd3e_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/6958343928_7e596da4ed_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/6958243974_8851425ddb_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14064731501_ea14b58161.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/4558912791_084e440365_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/8713388322_e5ae26263b_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/7145978709_2d1596f462.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/11746276_de3dec8201.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/17309951996_552d632cbb_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14487705209_ea723109e1_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14067778605_0285b7cc3a.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/2481015475_b71a12917d.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/5813495998_64be1b8ab6_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/2333321040_3960b9d67e_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/3601085193_de1195d3d7_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/4571353297_5634177744_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/2229804138_db9cba3443_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/18245124970_e68fd3f3c3.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14275234071_6e6f473356.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/15632065904_0d9caf174b.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14097328354_4f1469a170.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/2425067141_b27043a800_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/8713357842_9964a93473_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/3626132563_d955973447_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/3457017604_90e4de7480_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/3614805920_7a6610aa4b_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/16506668270_b823935dc3.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/8623173256_3f0eb4c506.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/17202535346_ab828e779b.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/7094415739_6b29e5215c_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/6931489544_2f35025f7b_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/2436998042_4906ea07af.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/16717320956_d4b00807f2.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/4550091966_7f3e0f8802_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/8673416556_639f5c88f1_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/7047408023_6e98fd1e3f.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/7166550328_de0d73cfa9.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/142235017_07816937c6.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14491997336_36ba524713.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/8713387500_6a9138b41b_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/130685245_dcdd23836f_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/4442928974_9672d630b2_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14651385476_7ccb20e594_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14266093711_66d18a1e44_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/16282277874_b92776b194.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/17189526216_fa24dd541a_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/17908793211_ff0f1f81d3_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14674071872_2df55466d5_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/7448453762_aea8739f1b.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/7166554924_432aaae4b2_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/3454461550_64d6e726bf_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/17844723633_da85357fe3.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/3502251824_3be758edc6_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/8689672277_b289909f97_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/112428919_f0c5ad7d9d_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/17907238905_1ae121f8d9_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/17199496791_3caaf5e278_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/5810456385_b44358a0ae.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/7166567320_0a2beb6d42.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14097745904_436c4ba1b4_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/2249756775_02e693beda_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/17159349572_c0c51599f7_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/17324469461_2b318aff8d_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14122029097_3e3285ca5c_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/7447655334_e8f805ab95_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/3909355648_42cb3a5e09_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/14127532150_112823a8f6.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/15147473067_7c5498eb0e_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/130684941_d1abfa3be6_m.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/7166618384_850905fc63_n.jpg\n","224 224 to 224 224 /content/flowers/train/tulip/16303377824_6e9128b4bd.jpg\n","-------------------\n","/content/flowers/train/daisy\n","224 224 to 224 224 /content/flowers/train/daisy/3704305945_a80e60e2f6_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/1286274236_1d7ac84efb_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/7227973870_806d9d3e42_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/4286053334_a75541f20b_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/2331133004_582772d58f_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/391364010_4b0942d400_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5876455546_32049e5585.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/11834945233_a53b7a92ac_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/105806915_a9c13e2106_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/2556503265_63ae6b9e0e_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3713290261_8a66de23ab.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/9120905231_329598304e.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5794835_d15905c7c8_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3474942718_c418dae6f1.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/1285423653_18926dc2c8_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5883162120_dc7274af76_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/9922116524_ab4a2533fe_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/1656856503_447e5b0f03.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/2641979584_2b21c3fe29_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/9515186037_3be48fe68f.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/476857510_d2b30175de_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5110107234_12ddc0206b_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3546455114_cd2dea5e02.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/2561371688_c80a4fe957_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/2349640101_212c275aa7.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5869147563_66fb88119d.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5626895440_97a0ec04c2_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/4561871220_47f420ca59_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5881907044_92a85a05c8_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/154332674_453cea64f4.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5110109540_beed4ed162_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/512177035_70afc925c8.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5110105726_53eb7a93be_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/7669550908_bc5a11276f_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5673728_71b8cb57eb.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3963330924_6c6a3fa7be_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/7702332000_3f21ef4571_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/144603918_b9de002f60_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3084924076_4d5c5711af_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3975010332_3209f9f447_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/2538504987_fe524b92a8_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/1355787476_32e9f2a30b.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/9175280426_40ecc395b8_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/9054268881_19792c5203_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/8964198962_6d8593b533.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/2551708158_1f10e81e11.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/162362897_1d21b70621_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/4890424315_6a59696357_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/7066602021_2647457985_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/4923279674_e7f8e70794_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5586977262_6b24412805_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/7629784968_b953501902_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/14073784469_ffb12f3387_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/483886997_27ee798327.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5997702776_c7bc37aa6b_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/2454280135_ac3aa75cdc_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/2365428551_39f83f10bf_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/2488902131_3417698611_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/695778683_890c46ebac.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/4544110929_a7de65d65f_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3780380240_ef9ec1b737_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3637428148_a1dcccafa9_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/6776075110_1ea7a09dd4_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/7538403124_f2fc48750a.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/43474673_7bb4465a86.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/517054467_d82d323c33_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5885826924_38fdc6bcaa_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/5948835387_5a98d39eff_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/538920244_59899a78f8_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3717746329_53f515c6a6_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/12701063955_4840594ea6_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/367020749_3c9a652d75.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/14219214466_3ca6104eae_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3598615130_578ed30e5f.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/813445367_187ecf080a_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/799964360_7e07a227ea_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/2632216904_274aa17433.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3625257860_33efeef614_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/9204730092_a7f2182347.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/8694909523_3ca25d449d_n.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/6148728633_27afc47b0c_m.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/3379332157_04724f6480.jpg\n","224 224 to 224 224 /content/flowers/train/daisy/11870378973_2ec1919f12.jpg\n","Found 165 images belonging to 2 classes.\n","Found 35 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eCcMiRiMnPRY","executionInfo":{"status":"ok","timestamp":1606883103611,"user_tz":-540,"elapsed":3200,"user":{"displayName":"남중구","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdjUdzM516IqW5OZZ8t6jU96Fd8d5gitHsvgLBeA=s64","userId":"04014122822541888792"}},"outputId":"eae25937-aae1-4d2b-c5ff-344dfd640ccb"},"source":["for image_batch, label_batch in train_data:\n","  print(\"Image batch shape: \", image_batch.shape)\n","  print(\"Label batch shape: \", label_batch.shape)\n","  label_set_count=label_batch.shape[1]\n","  break\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Image batch shape:  (64, 224, 224, 3)\n","Label batch shape:  (64, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4dSSUhcfmJyU","executionInfo":{"status":"ok","timestamp":1606883141160,"user_tz":-540,"elapsed":40742,"user":{"displayName":"남중구","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdjUdzM516IqW5OZZ8t6jU96Fd8d5gitHsvgLBeA=s64","userId":"04014122822541888792"}},"outputId":"fcf97241-9b52-46eb-bc57-20e15511e153"},"source":["from keras.applications.inception_v3 import InceptionV3\n","from keras.preprocessing import image\n","from keras.models import Model\n","from keras.layers import Dense, GlobalAveragePooling2D\n","from keras import backend as K\n","\n","# 선행학습된 기준모델을 만듭니다\n","base_model = InceptionV3(weights='imagenet', include_top=False)\n","\n","# 글로벌 공간 평균값 풀링 레이어를 더합니다\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","# 완전 연결 레이어를 더합니다\n","x = Dense(1024, activation='relu')(x)\n","# 로지스틱 레이어를 더합니다 -- 200가지 클래스가 있다고 가정합니다\n","predictions = Dense(label_set_count, activation='softmax')(x)\n","\n","# 다음은 학습할 모델입니다\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","# 첫째로: (난수로 초기값이 설정된) 가장 상위 레이어들만 학습시킵니다\n","# 다시 말해서 모든 InceptionV3 콘볼루션 레이어를 고정합니다\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# 모델을 컴파일합니다 (*꼭* 레이어를 학습불가 상태로 세팅하고난 *후*에 컴파일합니다)\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","\n","\n","# 모델을 새로운 데이터에 대해 몇 세대간 학습합니다\n","model.fit_generator(train_data, \n","                    validation_data=test_data, \n","                    validation_steps=8,\n","                    epochs=50\n",")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-6-71f8733409f4>:35: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use Model.fit, which supports generators.\n","Epoch 1/50\n","3/3 [==============================] - ETA: 0s - loss: 240.6480 - accuracy: 0.4970WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 8 batches). You may need to use the repeat() function when building your dataset.\n","3/3 [==============================] - 3s 931ms/step - loss: 240.6480 - accuracy: 0.4970 - val_loss: 105.1169 - val_accuracy: 0.5143\n","Epoch 2/50\n","3/3 [==============================] - 0s 90ms/step - loss: 48.5352 - accuracy: 0.5697\n","Epoch 3/50\n","3/3 [==============================] - 0s 78ms/step - loss: 36.7007 - accuracy: 0.5273\n","Epoch 4/50\n","3/3 [==============================] - 0s 114ms/step - loss: 19.1036 - accuracy: 0.5758\n","Epoch 5/50\n","3/3 [==============================] - 0s 112ms/step - loss: 18.5319 - accuracy: 0.5939\n","Epoch 6/50\n","3/3 [==============================] - 0s 80ms/step - loss: 15.7887 - accuracy: 0.5879\n","Epoch 7/50\n","3/3 [==============================] - 0s 94ms/step - loss: 14.5532 - accuracy: 0.5455\n","Epoch 8/50\n","3/3 [==============================] - 0s 115ms/step - loss: 9.8058 - accuracy: 0.6606\n","Epoch 9/50\n","3/3 [==============================] - 0s 92ms/step - loss: 10.5522 - accuracy: 0.6242\n","Epoch 10/50\n","3/3 [==============================] - 0s 83ms/step - loss: 8.1055 - accuracy: 0.6667\n","Epoch 11/50\n","3/3 [==============================] - 0s 89ms/step - loss: 15.8829 - accuracy: 0.5091\n","Epoch 12/50\n","3/3 [==============================] - 0s 114ms/step - loss: 8.1228 - accuracy: 0.6303\n","Epoch 13/50\n","3/3 [==============================] - 0s 82ms/step - loss: 11.7690 - accuracy: 0.5758\n","Epoch 14/50\n","3/3 [==============================] - 0s 115ms/step - loss: 2.3036 - accuracy: 0.8000\n","Epoch 15/50\n","3/3 [==============================] - 0s 112ms/step - loss: 11.9094 - accuracy: 0.5455\n","Epoch 16/50\n","3/3 [==============================] - 0s 90ms/step - loss: 7.7846 - accuracy: 0.6303\n","Epoch 17/50\n","3/3 [==============================] - 0s 113ms/step - loss: 11.9053 - accuracy: 0.5455\n","Epoch 18/50\n","3/3 [==============================] - 0s 89ms/step - loss: 5.3663 - accuracy: 0.6848\n","Epoch 19/50\n","3/3 [==============================] - 0s 113ms/step - loss: 2.0069 - accuracy: 0.8303\n","Epoch 20/50\n","3/3 [==============================] - 0s 111ms/step - loss: 8.9830 - accuracy: 0.5152\n","Epoch 21/50\n","3/3 [==============================] - 0s 91ms/step - loss: 6.4576 - accuracy: 0.6727\n","Epoch 22/50\n","3/3 [==============================] - 0s 81ms/step - loss: 3.8434 - accuracy: 0.6727\n","Epoch 23/50\n","3/3 [==============================] - 0s 83ms/step - loss: 5.9587 - accuracy: 0.6424\n","Epoch 24/50\n","3/3 [==============================] - 0s 112ms/step - loss: 2.3130 - accuracy: 0.7697\n","Epoch 25/50\n","3/3 [==============================] - 0s 91ms/step - loss: 4.4220 - accuracy: 0.7030\n","Epoch 26/50\n","3/3 [==============================] - 0s 82ms/step - loss: 4.9808 - accuracy: 0.6424\n","Epoch 27/50\n","3/3 [==============================] - 0s 83ms/step - loss: 4.5672 - accuracy: 0.6788\n","Epoch 28/50\n","3/3 [==============================] - 0s 89ms/step - loss: 1.1913 - accuracy: 0.8061\n","Epoch 29/50\n","3/3 [==============================] - 0s 115ms/step - loss: 2.1817 - accuracy: 0.7758\n","Epoch 30/50\n","3/3 [==============================] - 0s 89ms/step - loss: 8.1956 - accuracy: 0.5636\n","Epoch 31/50\n","3/3 [==============================] - 0s 89ms/step - loss: 3.0328 - accuracy: 0.7212\n","Epoch 32/50\n","3/3 [==============================] - 0s 89ms/step - loss: 3.9527 - accuracy: 0.6303\n","Epoch 33/50\n","3/3 [==============================] - 0s 114ms/step - loss: 2.4495 - accuracy: 0.7818\n","Epoch 34/50\n","3/3 [==============================] - 0s 91ms/step - loss: 0.4962 - accuracy: 0.8667\n","Epoch 35/50\n","3/3 [==============================] - 0s 90ms/step - loss: 1.1176 - accuracy: 0.8242\n","Epoch 36/50\n","3/3 [==============================] - 0s 91ms/step - loss: 6.2701 - accuracy: 0.6000\n","Epoch 37/50\n","3/3 [==============================] - 0s 90ms/step - loss: 0.6266 - accuracy: 0.8848\n","Epoch 38/50\n","3/3 [==============================] - 0s 81ms/step - loss: 0.3916 - accuracy: 0.9212\n","Epoch 39/50\n","3/3 [==============================] - 0s 115ms/step - loss: 0.2699 - accuracy: 0.9030\n","Epoch 40/50\n","3/3 [==============================] - 0s 89ms/step - loss: 0.5097 - accuracy: 0.8788\n","Epoch 41/50\n","3/3 [==============================] - 0s 89ms/step - loss: 6.5906 - accuracy: 0.5939\n","Epoch 42/50\n","3/3 [==============================] - 0s 89ms/step - loss: 6.1429 - accuracy: 0.5636\n","Epoch 43/50\n","3/3 [==============================] - 0s 114ms/step - loss: 0.4504 - accuracy: 0.9091\n","Epoch 44/50\n","3/3 [==============================] - 0s 89ms/step - loss: 0.2103 - accuracy: 0.9273\n","Epoch 45/50\n","3/3 [==============================] - 0s 88ms/step - loss: 0.1959 - accuracy: 0.9455\n","Epoch 46/50\n","3/3 [==============================] - 0s 115ms/step - loss: 0.3866 - accuracy: 0.8970\n","Epoch 47/50\n","3/3 [==============================] - 0s 113ms/step - loss: 5.7838 - accuracy: 0.5758\n","Epoch 48/50\n","3/3 [==============================] - 0s 89ms/step - loss: 4.8747 - accuracy: 0.7273\n","Epoch 49/50\n","3/3 [==============================] - 0s 113ms/step - loss: 0.5556 - accuracy: 0.8606\n","Epoch 50/50\n","3/3 [==============================] - 0s 89ms/step - loss: 0.2156 - accuracy: 0.9273\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f3251f5e048>"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tnO4HTLlp3L0","executionInfo":{"status":"ok","timestamp":1606883141544,"user_tz":-540,"elapsed":41119,"user":{"displayName":"남중구","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdjUdzM516IqW5OZZ8t6jU96Fd8d5gitHsvgLBeA=s64","userId":"04014122822541888792"}},"outputId":"dd8bd24b-1c26-462d-96c2-5eb1fa9cdee2"},"source":["score = model.evaluate_generator(test_data)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-7-815428d1b02e>:1: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use Model.evaluate, which supports generators.\n","Test loss: 1.8776918649673462\n","Test accuracy: 0.6571428775787354\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"slHsjoM6lWfb","executionInfo":{"status":"ok","timestamp":1606883141544,"user_tz":-540,"elapsed":41111,"user":{"displayName":"남중구","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdjUdzM516IqW5OZZ8t6jU96Fd8d5gitHsvgLBeA=s64","userId":"04014122822541888792"}},"outputId":"4901e653-ea46-47bd-8cc5-bfaed73dc8fc"},"source":["# 이 시점에서 상위 레이어들은 충분히 학습이 되었기에,\n","# inception V3의 콘볼루션 레이어에 대한 파인튜닝을 시작합니다 \n","# 가장 밑 N개의 레이어를 고정하고 나머지 상위 레이어를 학습시킵니다\n","\n","# 레이어 이름과 레이어 인덱스를 시각화하여\n","# 얼마나 많은 레이어를 고정시켜야 하는지 확인합니다:\n","for i, layer in enumerate(base_model.layers):\n","   print(i, layer.name)\n","\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["0 input_1\n","1 conv2d\n","2 batch_normalization\n","3 activation\n","4 conv2d_1\n","5 batch_normalization_1\n","6 activation_1\n","7 conv2d_2\n","8 batch_normalization_2\n","9 activation_2\n","10 max_pooling2d\n","11 conv2d_3\n","12 batch_normalization_3\n","13 activation_3\n","14 conv2d_4\n","15 batch_normalization_4\n","16 activation_4\n","17 max_pooling2d_1\n","18 conv2d_8\n","19 batch_normalization_8\n","20 activation_8\n","21 conv2d_6\n","22 conv2d_9\n","23 batch_normalization_6\n","24 batch_normalization_9\n","25 activation_6\n","26 activation_9\n","27 average_pooling2d\n","28 conv2d_5\n","29 conv2d_7\n","30 conv2d_10\n","31 conv2d_11\n","32 batch_normalization_5\n","33 batch_normalization_7\n","34 batch_normalization_10\n","35 batch_normalization_11\n","36 activation_5\n","37 activation_7\n","38 activation_10\n","39 activation_11\n","40 mixed0\n","41 conv2d_15\n","42 batch_normalization_15\n","43 activation_15\n","44 conv2d_13\n","45 conv2d_16\n","46 batch_normalization_13\n","47 batch_normalization_16\n","48 activation_13\n","49 activation_16\n","50 average_pooling2d_1\n","51 conv2d_12\n","52 conv2d_14\n","53 conv2d_17\n","54 conv2d_18\n","55 batch_normalization_12\n","56 batch_normalization_14\n","57 batch_normalization_17\n","58 batch_normalization_18\n","59 activation_12\n","60 activation_14\n","61 activation_17\n","62 activation_18\n","63 mixed1\n","64 conv2d_22\n","65 batch_normalization_22\n","66 activation_22\n","67 conv2d_20\n","68 conv2d_23\n","69 batch_normalization_20\n","70 batch_normalization_23\n","71 activation_20\n","72 activation_23\n","73 average_pooling2d_2\n","74 conv2d_19\n","75 conv2d_21\n","76 conv2d_24\n","77 conv2d_25\n","78 batch_normalization_19\n","79 batch_normalization_21\n","80 batch_normalization_24\n","81 batch_normalization_25\n","82 activation_19\n","83 activation_21\n","84 activation_24\n","85 activation_25\n","86 mixed2\n","87 conv2d_27\n","88 batch_normalization_27\n","89 activation_27\n","90 conv2d_28\n","91 batch_normalization_28\n","92 activation_28\n","93 conv2d_26\n","94 conv2d_29\n","95 batch_normalization_26\n","96 batch_normalization_29\n","97 activation_26\n","98 activation_29\n","99 max_pooling2d_2\n","100 mixed3\n","101 conv2d_34\n","102 batch_normalization_34\n","103 activation_34\n","104 conv2d_35\n","105 batch_normalization_35\n","106 activation_35\n","107 conv2d_31\n","108 conv2d_36\n","109 batch_normalization_31\n","110 batch_normalization_36\n","111 activation_31\n","112 activation_36\n","113 conv2d_32\n","114 conv2d_37\n","115 batch_normalization_32\n","116 batch_normalization_37\n","117 activation_32\n","118 activation_37\n","119 average_pooling2d_3\n","120 conv2d_30\n","121 conv2d_33\n","122 conv2d_38\n","123 conv2d_39\n","124 batch_normalization_30\n","125 batch_normalization_33\n","126 batch_normalization_38\n","127 batch_normalization_39\n","128 activation_30\n","129 activation_33\n","130 activation_38\n","131 activation_39\n","132 mixed4\n","133 conv2d_44\n","134 batch_normalization_44\n","135 activation_44\n","136 conv2d_45\n","137 batch_normalization_45\n","138 activation_45\n","139 conv2d_41\n","140 conv2d_46\n","141 batch_normalization_41\n","142 batch_normalization_46\n","143 activation_41\n","144 activation_46\n","145 conv2d_42\n","146 conv2d_47\n","147 batch_normalization_42\n","148 batch_normalization_47\n","149 activation_42\n","150 activation_47\n","151 average_pooling2d_4\n","152 conv2d_40\n","153 conv2d_43\n","154 conv2d_48\n","155 conv2d_49\n","156 batch_normalization_40\n","157 batch_normalization_43\n","158 batch_normalization_48\n","159 batch_normalization_49\n","160 activation_40\n","161 activation_43\n","162 activation_48\n","163 activation_49\n","164 mixed5\n","165 conv2d_54\n","166 batch_normalization_54\n","167 activation_54\n","168 conv2d_55\n","169 batch_normalization_55\n","170 activation_55\n","171 conv2d_51\n","172 conv2d_56\n","173 batch_normalization_51\n","174 batch_normalization_56\n","175 activation_51\n","176 activation_56\n","177 conv2d_52\n","178 conv2d_57\n","179 batch_normalization_52\n","180 batch_normalization_57\n","181 activation_52\n","182 activation_57\n","183 average_pooling2d_5\n","184 conv2d_50\n","185 conv2d_53\n","186 conv2d_58\n","187 conv2d_59\n","188 batch_normalization_50\n","189 batch_normalization_53\n","190 batch_normalization_58\n","191 batch_normalization_59\n","192 activation_50\n","193 activation_53\n","194 activation_58\n","195 activation_59\n","196 mixed6\n","197 conv2d_64\n","198 batch_normalization_64\n","199 activation_64\n","200 conv2d_65\n","201 batch_normalization_65\n","202 activation_65\n","203 conv2d_61\n","204 conv2d_66\n","205 batch_normalization_61\n","206 batch_normalization_66\n","207 activation_61\n","208 activation_66\n","209 conv2d_62\n","210 conv2d_67\n","211 batch_normalization_62\n","212 batch_normalization_67\n","213 activation_62\n","214 activation_67\n","215 average_pooling2d_6\n","216 conv2d_60\n","217 conv2d_63\n","218 conv2d_68\n","219 conv2d_69\n","220 batch_normalization_60\n","221 batch_normalization_63\n","222 batch_normalization_68\n","223 batch_normalization_69\n","224 activation_60\n","225 activation_63\n","226 activation_68\n","227 activation_69\n","228 mixed7\n","229 conv2d_72\n","230 batch_normalization_72\n","231 activation_72\n","232 conv2d_73\n","233 batch_normalization_73\n","234 activation_73\n","235 conv2d_70\n","236 conv2d_74\n","237 batch_normalization_70\n","238 batch_normalization_74\n","239 activation_70\n","240 activation_74\n","241 conv2d_71\n","242 conv2d_75\n","243 batch_normalization_71\n","244 batch_normalization_75\n","245 activation_71\n","246 activation_75\n","247 max_pooling2d_3\n","248 mixed8\n","249 conv2d_80\n","250 batch_normalization_80\n","251 activation_80\n","252 conv2d_77\n","253 conv2d_81\n","254 batch_normalization_77\n","255 batch_normalization_81\n","256 activation_77\n","257 activation_81\n","258 conv2d_78\n","259 conv2d_79\n","260 conv2d_82\n","261 conv2d_83\n","262 average_pooling2d_7\n","263 conv2d_76\n","264 batch_normalization_78\n","265 batch_normalization_79\n","266 batch_normalization_82\n","267 batch_normalization_83\n","268 conv2d_84\n","269 batch_normalization_76\n","270 activation_78\n","271 activation_79\n","272 activation_82\n","273 activation_83\n","274 batch_normalization_84\n","275 activation_76\n","276 mixed9_0\n","277 concatenate\n","278 activation_84\n","279 mixed9\n","280 conv2d_89\n","281 batch_normalization_89\n","282 activation_89\n","283 conv2d_86\n","284 conv2d_90\n","285 batch_normalization_86\n","286 batch_normalization_90\n","287 activation_86\n","288 activation_90\n","289 conv2d_87\n","290 conv2d_88\n","291 conv2d_91\n","292 conv2d_92\n","293 average_pooling2d_8\n","294 conv2d_85\n","295 batch_normalization_87\n","296 batch_normalization_88\n","297 batch_normalization_91\n","298 batch_normalization_92\n","299 conv2d_93\n","300 batch_normalization_85\n","301 activation_87\n","302 activation_88\n","303 activation_91\n","304 activation_92\n","305 batch_normalization_93\n","306 activation_85\n","307 mixed9_1\n","308 concatenate_1\n","309 activation_93\n","310 mixed10\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WIggcooulXez","executionInfo":{"status":"ok","timestamp":1606883141545,"user_tz":-540,"elapsed":41104,"user":{"displayName":"남중구","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdjUdzM516IqW5OZZ8t6jU96Fd8d5gitHsvgLBeA=s64","userId":"04014122822541888792"}}},"source":["# 가장 상위 2개의 inception 블록을 학습하기로 고릅니다,\n","# 다시 말하면 첫 249개의 레이어는 고정시키고 나머지는 고정하지 않습니다:\n","for layer in model.layers[:249]:\n","   layer.trainable = False\n","for layer in model.layers[249:]:\n","   layer.trainable = True\n","\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_2XmZ3q0lYrF","executionInfo":{"status":"ok","timestamp":1606883203716,"user_tz":-540,"elapsed":103272,"user":{"displayName":"남중구","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdjUdzM516IqW5OZZ8t6jU96Fd8d5gitHsvgLBeA=s64","userId":"04014122822541888792"}},"outputId":"0a69f1dd-9431-4f7e-9c87-0bc1b2ff96ac"},"source":["# 이러한 수정사항이 효과를 내려면 모델을 다시 컴파일해야 합니다\n","# 낮은 학습 속도로 세팅된 SGD를 사용합니다\n","from keras.optimizers import SGD\n","model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","# 다시 한 번 모델을 학습시킵니다\n","# (이번엔 상위 2개의 inception 블록을 상위의 밀집 레이어들과 함께 파인튜닝합니다)\n","model.fit_generator(train_data, \n","                    validation_data=test_data, \n","                    validation_steps=8,\n","                    epochs=100\n",")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","3/3 [==============================] - ETA: 0s - loss: 0.9464 - accuracy: 0.4970WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 8 batches). You may need to use the repeat() function when building your dataset.\n","3/3 [==============================] - 2s 646ms/step - loss: 0.9464 - accuracy: 0.4970 - val_loss: 0.9147 - val_accuracy: 0.6000\n","Epoch 2/100\n","3/3 [==============================] - 0s 97ms/step - loss: 0.9422 - accuracy: 0.4970\n","Epoch 3/100\n","3/3 [==============================] - 0s 131ms/step - loss: 0.8941 - accuracy: 0.4970\n","Epoch 4/100\n","3/3 [==============================] - 0s 130ms/step - loss: 0.8567 - accuracy: 0.4970\n","Epoch 5/100\n","3/3 [==============================] - 0s 100ms/step - loss: 0.8300 - accuracy: 0.4970\n","Epoch 6/100\n","3/3 [==============================] - 0s 127ms/step - loss: 0.7823 - accuracy: 0.4970\n","Epoch 7/100\n","3/3 [==============================] - 0s 111ms/step - loss: 0.7545 - accuracy: 0.4970\n","Epoch 8/100\n","3/3 [==============================] - 0s 110ms/step - loss: 0.7263 - accuracy: 0.4970\n","Epoch 9/100\n","3/3 [==============================] - 0s 100ms/step - loss: 0.6996 - accuracy: 0.4970\n","Epoch 10/100\n","3/3 [==============================] - 0s 111ms/step - loss: 0.6832 - accuracy: 0.5030\n","Epoch 11/100\n","3/3 [==============================] - 0s 129ms/step - loss: 0.6661 - accuracy: 0.5152\n","Epoch 12/100\n","3/3 [==============================] - 0s 99ms/step - loss: 0.6552 - accuracy: 0.5333\n","Epoch 13/100\n","3/3 [==============================] - 0s 111ms/step - loss: 0.6454 - accuracy: 0.5818\n","Epoch 14/100\n","3/3 [==============================] - 0s 99ms/step - loss: 0.6464 - accuracy: 0.6000\n","Epoch 15/100\n","3/3 [==============================] - 0s 131ms/step - loss: 0.6342 - accuracy: 0.6424\n","Epoch 16/100\n","3/3 [==============================] - 0s 128ms/step - loss: 0.6318 - accuracy: 0.6727\n","Epoch 17/100\n","3/3 [==============================] - 0s 126ms/step - loss: 0.6276 - accuracy: 0.6848\n","Epoch 18/100\n","3/3 [==============================] - 0s 98ms/step - loss: 0.6289 - accuracy: 0.7152\n","Epoch 19/100\n","3/3 [==============================] - 0s 132ms/step - loss: 0.6246 - accuracy: 0.7394\n","Epoch 20/100\n","3/3 [==============================] - 0s 99ms/step - loss: 0.6199 - accuracy: 0.7515\n","Epoch 21/100\n","3/3 [==============================] - 0s 99ms/step - loss: 0.6182 - accuracy: 0.7697\n","Epoch 22/100\n","3/3 [==============================] - 0s 101ms/step - loss: 0.6104 - accuracy: 0.7576\n","Epoch 23/100\n","3/3 [==============================] - 0s 117ms/step - loss: 0.6058 - accuracy: 0.8121\n","Epoch 24/100\n","3/3 [==============================] - 0s 98ms/step - loss: 0.6076 - accuracy: 0.8242\n","Epoch 25/100\n","3/3 [==============================] - 0s 112ms/step - loss: 0.6073 - accuracy: 0.7818\n","Epoch 26/100\n","3/3 [==============================] - 0s 99ms/step - loss: 0.5970 - accuracy: 0.8303\n","Epoch 27/100\n","3/3 [==============================] - 0s 111ms/step - loss: 0.5917 - accuracy: 0.8303\n","Epoch 28/100\n","3/3 [==============================] - 0s 100ms/step - loss: 0.5913 - accuracy: 0.8364\n","Epoch 29/100\n","3/3 [==============================] - 0s 125ms/step - loss: 0.5871 - accuracy: 0.8364\n","Epoch 30/100\n","3/3 [==============================] - 0s 112ms/step - loss: 0.5850 - accuracy: 0.8303\n","Epoch 31/100\n","3/3 [==============================] - 0s 100ms/step - loss: 0.5861 - accuracy: 0.8424\n","Epoch 32/100\n","3/3 [==============================] - 0s 113ms/step - loss: 0.5834 - accuracy: 0.8364\n","Epoch 33/100\n","3/3 [==============================] - 0s 111ms/step - loss: 0.5759 - accuracy: 0.8364\n","Epoch 34/100\n","3/3 [==============================] - 0s 129ms/step - loss: 0.5708 - accuracy: 0.8485\n","Epoch 35/100\n","3/3 [==============================] - 0s 113ms/step - loss: 0.5676 - accuracy: 0.8485\n","Epoch 36/100\n","3/3 [==============================] - 0s 113ms/step - loss: 0.5752 - accuracy: 0.8424\n","Epoch 37/100\n","3/3 [==============================] - 0s 101ms/step - loss: 0.5676 - accuracy: 0.8485\n","Epoch 38/100\n","3/3 [==============================] - 0s 111ms/step - loss: 0.5556 - accuracy: 0.8667\n","Epoch 39/100\n","3/3 [==============================] - 0s 112ms/step - loss: 0.5568 - accuracy: 0.8545\n","Epoch 40/100\n","3/3 [==============================] - 0s 111ms/step - loss: 0.5507 - accuracy: 0.8545\n","Epoch 41/100\n","3/3 [==============================] - 0s 112ms/step - loss: 0.5437 - accuracy: 0.8848\n","Epoch 42/100\n","3/3 [==============================] - 0s 113ms/step - loss: 0.5457 - accuracy: 0.8788\n","Epoch 43/100\n","3/3 [==============================] - 0s 101ms/step - loss: 0.5410 - accuracy: 0.8667\n","Epoch 44/100\n","3/3 [==============================] - 0s 102ms/step - loss: 0.5354 - accuracy: 0.8909\n","Epoch 45/100\n","3/3 [==============================] - 0s 111ms/step - loss: 0.5379 - accuracy: 0.8606\n","Epoch 46/100\n","3/3 [==============================] - 0s 100ms/step - loss: 0.5284 - accuracy: 0.8727\n","Epoch 47/100\n","3/3 [==============================] - 0s 110ms/step - loss: 0.5336 - accuracy: 0.8727\n","Epoch 48/100\n","3/3 [==============================] - 0s 126ms/step - loss: 0.5171 - accuracy: 0.8788\n","Epoch 49/100\n","3/3 [==============================] - 0s 112ms/step - loss: 0.5149 - accuracy: 0.8788\n","Epoch 50/100\n","3/3 [==============================] - 0s 102ms/step - loss: 0.5172 - accuracy: 0.8727\n","Epoch 51/100\n","3/3 [==============================] - 0s 101ms/step - loss: 0.5134 - accuracy: 0.8727\n","Epoch 52/100\n","3/3 [==============================] - 0s 128ms/step - loss: 0.5042 - accuracy: 0.8848\n","Epoch 53/100\n","3/3 [==============================] - 0s 129ms/step - loss: 0.5045 - accuracy: 0.8970\n","Epoch 54/100\n","3/3 [==============================] - 0s 99ms/step - loss: 0.4926 - accuracy: 0.8848\n","Epoch 55/100\n","3/3 [==============================] - 0s 132ms/step - loss: 0.4914 - accuracy: 0.8848\n","Epoch 56/100\n","3/3 [==============================] - 0s 131ms/step - loss: 0.4885 - accuracy: 0.8848\n","Epoch 57/100\n","3/3 [==============================] - 0s 104ms/step - loss: 0.4862 - accuracy: 0.8909\n","Epoch 58/100\n","3/3 [==============================] - 0s 112ms/step - loss: 0.4898 - accuracy: 0.8909\n","Epoch 59/100\n","3/3 [==============================] - 0s 100ms/step - loss: 0.4770 - accuracy: 0.8970\n","Epoch 60/100\n","3/3 [==============================] - 0s 100ms/step - loss: 0.4707 - accuracy: 0.8909\n","Epoch 61/100\n","3/3 [==============================] - 0s 112ms/step - loss: 0.4673 - accuracy: 0.9030\n","Epoch 62/100\n","3/3 [==============================] - 0s 130ms/step - loss: 0.4620 - accuracy: 0.9091\n","Epoch 63/100\n","3/3 [==============================] - 0s 112ms/step - loss: 0.4560 - accuracy: 0.8909\n","Epoch 64/100\n","3/3 [==============================] - 0s 112ms/step - loss: 0.4637 - accuracy: 0.9030\n","Epoch 65/100\n","3/3 [==============================] - 0s 112ms/step - loss: 0.4495 - accuracy: 0.9212\n","Epoch 66/100\n","3/3 [==============================] - 0s 112ms/step - loss: 0.4441 - accuracy: 0.8909\n","Epoch 67/100\n","3/3 [==============================] - 0s 110ms/step - loss: 0.4479 - accuracy: 0.8970\n","Epoch 68/100\n","3/3 [==============================] - 0s 130ms/step - loss: 0.4418 - accuracy: 0.9152\n","Epoch 69/100\n","3/3 [==============================] - 0s 100ms/step - loss: 0.4353 - accuracy: 0.9030\n","Epoch 70/100\n","3/3 [==============================] - 0s 102ms/step - loss: 0.4245 - accuracy: 0.9333\n","Epoch 71/100\n","3/3 [==============================] - 0s 99ms/step - loss: 0.4310 - accuracy: 0.9152\n","Epoch 72/100\n","3/3 [==============================] - 0s 99ms/step - loss: 0.4264 - accuracy: 0.9152\n","Epoch 73/100\n","3/3 [==============================] - 0s 112ms/step - loss: 0.4148 - accuracy: 0.9394\n","Epoch 74/100\n","3/3 [==============================] - 0s 98ms/step - loss: 0.4146 - accuracy: 0.9091\n","Epoch 75/100\n","3/3 [==============================] - 0s 112ms/step - loss: 0.4054 - accuracy: 0.9273\n","Epoch 76/100\n","3/3 [==============================] - 0s 109ms/step - loss: 0.4112 - accuracy: 0.9212\n","Epoch 77/100\n","3/3 [==============================] - 0s 98ms/step - loss: 0.4235 - accuracy: 0.8970\n","Epoch 78/100\n","3/3 [==============================] - 0s 111ms/step - loss: 0.3932 - accuracy: 0.9212\n","Epoch 79/100\n","3/3 [==============================] - 0s 98ms/step - loss: 0.3929 - accuracy: 0.9212\n","Epoch 80/100\n","3/3 [==============================] - 0s 128ms/step - loss: 0.3829 - accuracy: 0.9212\n","Epoch 81/100\n","3/3 [==============================] - 0s 110ms/step - loss: 0.3846 - accuracy: 0.9273\n","Epoch 82/100\n","3/3 [==============================] - 0s 100ms/step - loss: 0.3776 - accuracy: 0.9394\n","Epoch 83/100\n","3/3 [==============================] - 0s 98ms/step - loss: 0.3813 - accuracy: 0.9394\n","Epoch 84/100\n","3/3 [==============================] - 0s 100ms/step - loss: 0.3695 - accuracy: 0.9333\n","Epoch 85/100\n","3/3 [==============================] - 0s 111ms/step - loss: 0.3721 - accuracy: 0.9273\n","Epoch 86/100\n","3/3 [==============================] - 0s 111ms/step - loss: 0.3694 - accuracy: 0.9455\n","Epoch 87/100\n","3/3 [==============================] - 0s 100ms/step - loss: 0.3596 - accuracy: 0.9394\n","Epoch 88/100\n","3/3 [==============================] - 0s 110ms/step - loss: 0.3549 - accuracy: 0.9515\n","Epoch 89/100\n","3/3 [==============================] - 0s 99ms/step - loss: 0.3534 - accuracy: 0.9333\n","Epoch 90/100\n","3/3 [==============================] - 0s 127ms/step - loss: 0.3521 - accuracy: 0.9394\n","Epoch 91/100\n","3/3 [==============================] - 0s 126ms/step - loss: 0.3362 - accuracy: 0.9394\n","Epoch 92/100\n","3/3 [==============================] - 0s 98ms/step - loss: 0.3415 - accuracy: 0.9455\n","Epoch 93/100\n","3/3 [==============================] - 0s 129ms/step - loss: 0.3288 - accuracy: 0.9455\n","Epoch 94/100\n","3/3 [==============================] - 0s 110ms/step - loss: 0.3446 - accuracy: 0.9333\n","Epoch 95/100\n","3/3 [==============================] - 0s 128ms/step - loss: 0.3266 - accuracy: 0.9576\n","Epoch 96/100\n","3/3 [==============================] - 0s 101ms/step - loss: 0.3220 - accuracy: 0.9576\n","Epoch 97/100\n","3/3 [==============================] - 0s 109ms/step - loss: 0.3127 - accuracy: 0.9697\n","Epoch 98/100\n","3/3 [==============================] - 0s 100ms/step - loss: 0.3123 - accuracy: 0.9576\n","Epoch 99/100\n","3/3 [==============================] - 0s 127ms/step - loss: 0.3189 - accuracy: 0.9576\n","Epoch 100/100\n","3/3 [==============================] - 0s 98ms/step - loss: 0.3075 - accuracy: 0.9515\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f326022df28>"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"svBRt1UBfFud","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606883204221,"user_tz":-540,"elapsed":103770,"user":{"displayName":"남중구","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdjUdzM516IqW5OZZ8t6jU96Fd8d5gitHsvgLBeA=s64","userId":"04014122822541888792"}},"outputId":"b34668ae-8f9e-4cf1-8bf8-cc2a3b44c7ae"},"source":["score = model.evaluate_generator(test_data)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Test loss: 0.5125764608383179\n","Test accuracy: 0.6571428775787354\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6-sd-HI5D2Zt","executionInfo":{"status":"ok","timestamp":1606883204221,"user_tz":-540,"elapsed":103767,"user":{"displayName":"남중구","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdjUdzM516IqW5OZZ8t6jU96Fd8d5gitHsvgLBeA=s64","userId":"04014122822541888792"}}},"source":[""],"execution_count":11,"outputs":[]}]}